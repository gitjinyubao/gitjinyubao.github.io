<!DOCTYPE html>












  


<html class="theme-next gemini use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer@1.7.0/dist/APlayer.min.css">
<script src="https://cdn.jsdelivr.net/npm/aplayer@1.7.0/dist/APlayer.min.js"></script>


  <script>
  (function(i,s,o,g,r,a,m){i["DaoVoiceObject"]=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;a.charset="utf-8";m.parentNode.insertBefore(a,m)})(window,document,"script",('https:' == document.location.protocol ? 'https:' : 'http:') + "//widget.daovoice.io/widget/0f81ff2f.js","daovoice")
  daovoice('init', {
      app_id: "3484a04a"
    });
  daovoice('update');
  </script>






















  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Noto Serif SC:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext">
  






<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2">

<link rel="stylesheet" href="/css/main.css?v=7.1.1">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.1.1">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.1.1">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.1.1">


  <link rel="mask-icon" href="/images/logo.svg?v=7.1.1" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.1.1',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false,"dimmer":false},
    back2top: true,
    back2top_sidebar: false,
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  



  <meta name="description" content="生活源于奋斗">
<meta name="keywords" content="life,java,centos,technology,Internet,movie,read">
<meta property="og:type" content="website">
<meta property="og:title" content="JinYuBao">
<meta property="og:url" content="https://www.zengmanhua.cn/index.html">
<meta property="og:site_name" content="JinYuBao">
<meta property="og:description" content="生活源于奋斗">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="JinYuBao">
<meta name="twitter:description" content="生活源于奋斗">



  <link rel="alternate" href="/atom.xml" title="JinYuBao" type="application/atom+xml">



  
  
  <link rel="canonical" href="https://www.zengmanhua.cn/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>JinYuBao</title>
  






  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?4b71d0039cde751d335fa8488a614ead";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>







  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">JinYuBao</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">生活源于奋斗</p>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home menu-item-active">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-about">

    
    
    
      
    

    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>关于</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-读书">

    
    
    
      
    

    

    <a href="/books" rel="section"><i class="menu-item-icon fa fa-fw fa-book"></i> <br>读书</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-电影">

    
    
    
      
    

    

    <a href="/movies" rel="section"><i class="menu-item-icon fa fa-fw fa-film"></i> <br>电影</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-音乐">

    
    
    
      
    

    

    <a href="/music" rel="section"><i class="menu-item-icon fa fa-fw fa-music"></i> <br>音乐</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-sitemap">

    
    
    
      
    

    

    <a href="/sitemap.xml" rel="section"><i class="menu-item-icon fa fa-fw fa-sitemap"></i> <br>站点地图</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-commonweal">

    
    
    
      
    

    

    <a href="/404/" rel="section"><i class="menu-item-icon fa fa-fw fa-heartbeat"></i> <br>公益 404</a>

  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>搜索</a>
        </li>
      
    </ul>
  

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.zengmanhua.cn/2019/06/14/集群/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jin Yu Bao">
      <meta itemprop="description" content="生活源于奋斗">
      <meta itemprop="image" content="http://prl6c63q7.bkt.clouddn.com/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JinYuBao">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/06/14/集群/" class="post-title-link" itemprop="url">集群</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-06-14 16:11:34" itemprop="dateCreated datePublished" datetime="2019-06-14T16:11:34+08:00">2019-06-14</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/technology/" itemprop="url" rel="index"><span itemprop="name">技术</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2019/06/14/集群/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/06/14/集群/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在前面的文章中，已经介绍了Redis的几种高可用技术：持久化、主从复制和哨兵，但这些方案仍有不足，其中最主要的问题是存储能力受单机限制，以及无法实现写操作的负载均衡。</p>
<p>Redis集群解决了上述问题，实现了较为完善的高可用方案。本文将详细介绍集群，主要内容包括：<strong>集群的作用；集群的搭建方法及设计方案；集群的基本原理；客户端访问集群的方法；以及其他实践中需要的集群知识（集群扩容、故障转移、参数优化等）</strong>。</p>
<h1 id="一、集群的作用"><a href="#一、集群的作用" class="headerlink" title="一、集群的作用"></a>一、集群的作用</h1><p>集群，即Redis Cluster，是Redis 3.0开始引入的分布式存储方案。</p>
<p>集群由多个节点(Node)组成，Redis的数据分布在这些节点中。集群中的节点分为主节点和从节点：只有主节点负责读写请求和集群信息的维护；从节点只进行主节点数据和状态信息的复制。</p>
<p>集群的作用，可以归纳为两点：</p>
<p>1、数据分区：数据分区(或称数据分片)是集群最核心的功能。</p>
<p>集群将数据分散到多个节点，一方面突破了Redis单机内存大小的限制，存储容量大大增加；另一方面每个主节点都可以对外提供读服务和写服务，大大提高了集群的响应能力。</p>
<p>Redis单机内存大小受限问题，在介绍持久化和主从复制时都有提及；例如，如果单机内存太大，bgsave和bgrewriteaof的fork操作可能导致主进程阻塞，主从环境下主机切换时可能导致从节点长时间无法提供服务，全量复制阶段主节点的复制缓冲区可能溢出……。</p>
<p>2、高可用：集群支持主从复制和主节点的自动故障转移（与哨兵类似）；当任一节点发生故障时，集群仍然可以对外提供服务。</p>
<p>本文内容基于Redis 3.0.6。</p>
<h1 id="二、集群的搭建"><a href="#二、集群的搭建" class="headerlink" title="二、集群的搭建"></a>二、集群的搭建</h1><p>这一部分我们将搭建一个简单的集群：共6个节点，3主3从。方便起见：所有节点在同一台服务器上，以端口号进行区分；配置从简。3个主节点端口号：7000/7001/7002，对应的从节点端口号：8000/8001/8002。</p>
<p>集群的搭建有两种方式：（1）手动执行Redis命令，一步步完成搭建；（2）使用Ruby脚本搭建。二者搭建的原理是一样的，只是Ruby脚本将Redis命令进行了打包封装；在实际应用中推荐使用脚本方式，简单快捷不容易出错。下面分别介绍这两种方式。</p>
<ol>
<li>执行Redis命令搭建集群</li>
</ol>
<hr>
<p>集群的搭建可以分为四步：（1）启动节点：将节点以集群模式启动，此时节点是独立的，并没有建立联系；（2）节点握手：让独立的节点连成一个网络；（3）分配槽：将16384个槽分配给主节点；（4）指定主从关系：为从节点指定主节点。</p>
<p>实际上，前三步完成后集群便可以对外提供服务；但指定从节点后，集群才能够提供真正高可用的服务。</p>
<h3 id="（1）启动节点"><a href="#（1）启动节点" class="headerlink" title="（1）启动节点"></a>（1）启动节点</h3><p>集群节点的启动仍然是使用redis-server命令，但需要使用集群模式启动。下面是7000节点的配置文件（只列出了节点正常工作关键配置，其他配置(如开启AOF)可以参照单机节点进行）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#redis-7000.conf</span><br><span class="line">port 7000</span><br><span class="line">cluster-enabled yes</span><br><span class="line">cluster-config-file &quot;node-7000.conf&quot;</span><br><span class="line">logfile &quot;log-7000.log&quot;</span><br><span class="line">dbfilename &quot;dump-7000.rdb&quot;</span><br><span class="line">daemonize yes</span><br></pre></td></tr></table></figure>
<p>其中的cluster-enabled和cluster-config-file是与集群相关的配置。</p>
<p><strong>cluster-enabled<br>yes：</strong>Redis实例可以分为单机模式(standalone)和集群模式(cluster)；cluster-enabled<br>yes可以启动集群模式。在单机模式下启动的Redis实例，如果执行info<br>server命令，可以发现redis_mode一项为standalone，如下图所示：</p>
<p><img src="http://47.103.200.134/image/77a78bad7ca628acc6e5bd3c26364717.png" alt="https://img2018.cnblogs.com/blog/1174710/201810/1174710-20181025213203453-1672239326.png"></p>
<p>集群模式下的节点，其redis_mode为cluster，如下图所示：</p>
<p><img src="http://47.103.200.134/image/70fc7ba5b5ce386b259cd0bb4b5e1c96.png" alt="https://img2018.cnblogs.com/blog/1174710/201810/1174710-20181025213226977-1673187418.png"></p>
<p><strong>cluster-config-file：</strong>该参数指定了<strong>集群配置文件</strong>的位置。每个节点在运行过程中，会维护一份集群配置文件；每当集群信息发生变化时（如增减节点），集群内所有节点会将最新信息更新到该配置文件；当节点重启后，会重新读取该配置文件，获取集群信息，可以方便的重新加入到集群中。<strong>也就是说，当Redis节点以集群模式启动时，会首先寻找是否有集群配置文件，如果有则使用文件中的配置启动，如果没有，则初始化配置并将配置保存到文件中。</strong>集群配置文件由Redis节点维护，不需要人工修改。</p>
<p>编辑好配置文件后，使用redis-server命令启动该节点：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-server redis-7000.conf</span><br></pre></td></tr></table></figure>
<p>节点启动以后，通过cluster nodes命令可以查看节点的情况，如下图所示。</p>
<p><img src="http://47.103.200.134/image/e37718a27c07a808bda9a7c2b78595ec.png" alt="https://img2018.cnblogs.com/blog/1174710/201810/1174710-20181025213238228-783273487.png"></p>
<p>其中返回值第一项表示节点id，由40个16进制字符串组成，节点id与 <a href="https://www.cnblogs.com/kismetv/p/9236731.html" target="_blank" rel="noopener">主从复制</a> 一文中提到的runId不同：Redis每次启动runId都会重新创建，但是节点id只在集群初始化时创建一次，然后保存到集群配置文件中，以后节点重新启动时会直接在集群配置文件中读取。</p>
<p>其他节点使用相同办法启动，不再赘述。需要特别注意，在启动节点阶段，节点是没有主从关系的，因此从节点不需要加slaveof配置。</p>
<h3 id="（2）节点握手"><a href="#（2）节点握手" class="headerlink" title="（2）节点握手"></a>（2）节点握手</h3><p>节点启动以后是相互独立的，并不知道其他节点存在；需要进行节点握手，将独立的节点组成一个网络。</p>
<p>节点握手使用cluster meet {ip} {port}命令实现，例如在7000节点中执行cluster meet<br>192.168.72.128<br>7001，可以完成7000节点和7001节点的握手；注意ip使用的是局域网ip而不是localhost或127.0.0.1，是为了其他机器上的节点或客户端也可以访问。此时再使用cluster<br>nodes查看：</p>
<p><img src="http://47.103.200.134/image/d1852b9eeb0e6c4cf616cb1f4feb0339.png" alt="https://img2018.cnblogs.com/blog/1174710/201810/1174710-20181025213248787-1104897657.png"></p>
<p>在7001节点下也可以类似查看：</p>
<p><img src="http://47.103.200.134/image/0d88fd4467dd36dab8f08b9b56ec34e7.png" alt="https://img2018.cnblogs.com/blog/1174710/201810/1174710-20181025213257512-1895545248.png"></p>
<p>同理，在7000节点中使用cluster meet命令，可以将所有节点加入到集群，完成节点握手：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cluster meet 192.168.72.128 7002</span><br><span class="line">cluster meet 192.168.72.128 8000</span><br><span class="line">cluster meet 192.168.72.128 8001</span><br><span class="line">cluster meet 192.168.72.128 8002</span><br></pre></td></tr></table></figure>
<p>执行完上述命令后，可以看到7000节点已经感知到了所有其他节点：</p>
<p><img src="http://47.103.200.134/image/65caa674137b05e3f044617f0935c6ab.png" alt="https://img2018.cnblogs.com/blog/1174710/201810/1174710-20181025213308598-555523704.png"></p>
<p>通过节点之间的通信，每个节点都可以感知到所有其他节点，以8000节点为例：</p>
<p><img src="http://47.103.200.134/image/a21e5f63423c0dd20f50b55958286643.png" alt="https://img2018.cnblogs.com/blog/1174710/201810/1174710-20181025213317081-1709672712.png"></p>
<h3 id="（3）分配槽"><a href="#（3）分配槽" class="headerlink" title="（3）分配槽"></a>（3）分配槽</h3><p>在Redis集群中，借助槽实现数据分区，具体原理后文会介绍。<strong>集群有16384个槽，槽是数据管理和迁移的基本单位。当数据库中的16384个槽都分配了节点时，集群处于上线状态（ok）；如果有任意一个槽没有分配节点，则集群处于下线状态（fail）。</strong></p>
<p>cluster info命令可以查看集群状态，分配槽之前状态为fail：</p>
<p><img src="http://47.103.200.134/image/78d5fd729a9906a71cff40536061230d.png" alt="https://img2018.cnblogs.com/blog/1174710/201810/1174710-20181025213325361-1692650567.png"></p>
<p>分配槽使用cluster addslots命令，执行下面的命令将槽（编号0-16383）全部分配完毕：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -p 7000 cluster addslots &#123;0..5461&#125;</span><br><span class="line">redis-cli -p 7001 cluster addslots &#123;5462..10922&#125;</span><br><span class="line">redis-cli -p 7002 cluster addslots &#123;10923..16383&#125;</span><br></pre></td></tr></table></figure>
<p>此时查看集群状态，显示所有槽分配完毕，集群进入上线状态：</p>
<p><img src="http://47.103.200.134/image/c3d517762c96d3d8ed22878f832c61c0.png" alt="https://img2018.cnblogs.com/blog/1174710/201810/1174710-20181025213333346-336188917.png"></p>
<h3 id="（4）指定主从关系"><a href="#（4）指定主从关系" class="headerlink" title="（4）指定主从关系"></a>（4）指定主从关系</h3><p>集群中指定主从关系不再使用slaveof命令，而是使用cluster<br>replicate命令；参数使用节点id。</p>
<p>通过cluster<br>nodes获得几个主节点的节点id后，执行下面的命令为每个从节点指定主节点：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -p 8000 cluster replicate be816eba968bc16c884b963d768c945e86ac51ae</span><br><span class="line">redis-cli -p 8001 cluster replicate 788b361563acb175ce8232569347812a12f1fdb4</span><br><span class="line">redis-cli -p 8002 cluster replicate a26f1624a3da3e5197dde267de683d61bb2dcbf1</span><br></pre></td></tr></table></figure>
<p>此时执行cluster nodes查看各个节点的状态，可以看到主从关系已经建立。</p>
<p><img src="http://47.103.200.134/image/e227b1eb481e505303b93b46904a1af4.png" alt="https://img2018.cnblogs.com/blog/1174710/201810/1174710-20181025213342728-2087888776.png"></p>
<p>至此，集群搭建完毕。</p>
<ol start="2">
<li>使用Ruby脚本搭建集群</li>
</ol>
<hr>
<p>在{REDIS_HOME}/src目录下可以看到redis-trib.rb文件，这是一个Ruby脚本，可以实现自动化的集群搭建。</p>
<p>（1）安装Ruby环境</p>
<p>以Ubuntu为例，如下操作即可安装Ruby环境：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">apt-get install ruby #安装ruby环境</span><br><span class="line">gem install redis #gem是ruby的包管理工具，该命令可以安装ruby-redis依赖</span><br></pre></td></tr></table></figure>
<p>（2）启动节点</p>
<p>与第一种方法中的“启动节点”完全相同。</p>
<p>（3）搭建集群</p>
<p>redis-trib.rb脚本提供了众多命令，其中create用于搭建集群，使用方法如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./redis-trib.rb create --replicas 1 192.168.72.128:7000 192.168.72.128:7001 192.168.72.128:7002 192.168.72.128:8000 192.168.72.128:8001 192.168.72.128:8002</span><br></pre></td></tr></table></figure>
<p>其中：–replicas=1表示每个主节点有1个从节点；后面的多个{ip:port}表示节点地址，前面的做主节点，后面的做从节点。使用redis-trib.rb搭建集群时，要求节点不能包含任何槽和数据。</p>
<p>执行创建命令后，脚本会给出创建集群的计划，如下图所示；计划包括哪些是主节点，哪些是从节点，以及如何分配槽。</p>
<p><img src="http://47.103.200.134/image/618c5d7c3247762d27b97d8cfe1a0fd3.png" alt="https://img2018.cnblogs.com/blog/1174710/201810/1174710-20181025213358890-801049832.png"></p>
<p>输入yes确认执行计划，脚本便开始按照计划执行，如下图所示。</p>
<p><img src="http://47.103.200.134/image/4a407426a6951bcc6b479263c6676b7d.png" alt="https://img2018.cnblogs.com/blog/1174710/201810/1174710-20181025213408605-1599814511.png"></p>
<p>至此，集群搭建完毕。</p>
<ol start="3">
<li>集群方案设计</li>
</ol>
<hr>
<p>设计集群方案时，至少要考虑以下因素：</p>
<p>（1）高可用要求：根据故障转移的原理，至少需要3个主节点才能完成故障转移，且3个主节点不应在同一台物理机上；每个主节点至少需要1个从节点，且主从节点不应在一台物理机上；因此高可用集群至少包含6个节点。</p>
<p>（2）数据量和访问量：估算应用需要的数据量和总访问量(考虑业务发展，留有冗余)，结合每个主节点的容量和能承受的访问量(可以通过benchmark得到较准确估计)，计算需要的主节点数量。</p>
<p>（3）节点数量限制：Redis官方给出的节点数量限制为1000，主要是考虑节点间通信带来的消耗。在实际应用中应尽量避免大集群；如果节点数量不足以满足应用对Redis数据量和访问量的要求，可以考虑：(1)业务分割，大集群分为多个小集群；(2)减少不必要的数据；(3)调整数据过期策略等。</p>
<p>（4）适度冗余：Redis可以在不影响集群服务的情况下增加节点，因此节点数量适当冗余即可，不用太大。</p>
<h1 id="三、集群的基本原理"><a href="#三、集群的基本原理" class="headerlink" title="三、集群的基本原理"></a>三、集群的基本原理</h1><p>上一章介绍了集群的搭建方法和设计方案，下面将进一步深入，介绍集群的原理。<strong>集群最核心的功能是数据分区，因此首先介绍数据的分区规则；然后介绍集群实现的细节：通信机制和数据结构；最后以cluster<br>meet(节点握手)、cluster<br>addslots(槽分配)为例，说明节点是如何利用上述数据结构和通信机制实现集群命令的。</strong></p>
<ol>
<li>数据分区方案</li>
</ol>
<hr>
<p>数据分区有顺序分区、哈希分区等，其中哈希分区由于其天然的随机性，使用广泛；集群的分区方案便是哈希分区的一种。</p>
<p>哈希分区的基本思路是：对数据的特征值（如key）进行哈希，然后根据哈希值决定数据落在哪个节点。常见的哈希分区包括：哈希取余分区、一致性哈希分区、带虚拟节点的一致性哈希分区等。</p>
<p>衡量数据分区方法好坏的标准有很多，其中比较重要的两个因素是(1)数据分布是否均匀(2)增加或删减节点对数据分布的影响。由于哈希的随机性，哈希分区基本可以保证数据分布均匀；因此在比较哈希分区方案时，重点要看增减节点对数据分布的影响。</p>
<p>（1）哈希取余分区</p>
<p>哈希取余分区思路非常简单：计算key的hash值，然后对节点数量进行取余，从而决定数据映射到哪个节点上。该方案最大的问题是，当新增或删减节点时，节点数量发生变化，系统中所有的数据都需要重新计算映射关系，引发大规模数据迁移。</p>
<p>（2）一致性哈希分区</p>
<p>一致性哈希算法将整个哈希值空间组织成一个虚拟的圆环，如下图所示，范围为0-2\^32-1；对于每个数据，根据key计算hash值，确定数据在环上的位置，然后从此位置沿环顺时针行走，找到的第一台服务器就是其应该映射到的服务器。</p>
<p><img src="http://47.103.200.134/image/976c226ba3a113d95415f7c9afdb9101.png" alt="https://img2018.cnblogs.com/blog/1174710/201810/1174710-20181025213424713-1246878063.png"></p>
<p>图片来源：<a href="https://www.cnblogs.com/lpfuture/p/5796398.html" target="_blank" rel="noopener">https://www.cnblogs.com/lpfuture/p/5796398.html</a></p>
<p>与哈希取余分区相比，一致性哈希分区将增减节点的影响限制在相邻节点。以上图为例，如果在node1和node2之间增加node5，则只有node2中的一部分数据会迁移到node5；如果去掉node2，则原node2中的数据只会迁移到node4中，只有node4会受影响。</p>
<p>一致性哈希分区的主要问题在于，当节点数量较少时，增加或删减节点，对单个节点的影响可能很大，造成数据的严重不平衡。还是以上图为例，如果去掉node2，node4中的数据由总数据的1/4左右变为1/2左右，与其他节点相比负载过高。</p>
<p>（3）带虚拟节点的一致性哈希分区</p>
<p>该方案在一致性哈希分区的基础上，引入了虚拟节点的概念。<strong>Redis集群使用的便是该方案，其中的虚拟节点称为槽（slot）。</strong>槽是介于数据和实际节点之间的虚拟概念；每个实际节点包含一定数量的槽，每个槽包含哈希值在一定范围内的数据。引入槽以后，数据的映射关系由数据hash->实际节点，变成了数据hash->槽->实际节点。</p>
<p><strong>在使用了槽的一致性哈希分区中，槽是数据管理和迁移的基本单位。槽解耦了数据和实际节点之间的关系，增加或删除节点对系统的影响很小。</strong>仍以上图为例，系统中有4个实际节点，假设为其分配16个槽(0-15)；<br>槽0-3位于node1，4-7位于node2，以此类推。如果此时删除node2，只需要将槽4-7重新分配即可，例如槽4-5分配给node1，槽6分配给node3，槽7分配给node4；可以看出删除node2后，数据在其他节点的分布仍然较为均衡。</p>
<p>槽的数量一般远小于2\^32，远大于实际节点的数量；在Redis集群中，槽的数量为16384。</p>
<p>下面这张图很好的总结了Redis集群将数据映射到实际节点的过程：</p>
<p><img src="http://47.103.200.134/image/e1cf6c1f549891059351823b5b5c639d.png" alt="https://img2018.cnblogs.com/blog/1174710/201810/1174710-20181025213453407-302249562.png"></p>
<p>图片来源：<a href="https://blog.csdn.net/yejingtao703/article/details/78484151" target="_blank" rel="noopener">https://blog.csdn.net/yejingtao703/article/details/78484151</a></p>
<p>（1）Redis对数据的特征值（一般是key）计算哈希值，使用的算法是CRC16。</p>
<p>（2）根据哈希值，计算数据属于哪个槽。</p>
<p>（3）根据槽与节点的映射关系，计算数据属于哪个节点。</p>
<ol start="2">
<li>节点通信机制</li>
</ol>
<hr>
<p>集群要作为一个整体工作，离不开节点之间的通信。</p>
<h3 id="两个端口"><a href="#两个端口" class="headerlink" title="两个端口"></a>两个端口</h3><p>在哨兵系统中，节点分为数据节点和哨兵节点：前者存储数据，后者实现额外的控制功能。在集群中，没有数据节点与非数据节点之分：所有的节点都存储数据，也都参与集群状态的维护。为此，集群中的每个节点，都提供了两个TCP端口：</p>
<ul>
<li><p>普通端口：即我们在前面指定的端口(7000等)。普通端口主要用于为客户端提供服务（与单机节点类似）；但在节点间数据迁移时也会使用。</p>
</li>
<li><p>集群端口：端口号是普通端口+10000（10000是固定值，无法改变），如7000节点的集群端口为17000。集群端口只用于节点之间的通信，如搭建集群、增减节点、故障转移等操作时节点间的通信；不要使用客户端连接集群接口。为了保证集群可以正常工作，在配置防火墙时，要同时开启普通端口和集群端口。</p>
</li>
</ul>
<h3 id="Gossip协议"><a href="#Gossip协议" class="headerlink" title="Gossip协议"></a>Gossip协议</h3><p>节点间通信，按照通信协议可以分为几种类型：单对单、广播、Gossip协议等。重点是广播和Gossip的对比。</p>
<p>广播是指向集群内所有节点发送消息；优点是集群的收敛速度快(集群收敛是指集群内所有节点获得的集群信息是一致的)，缺点是每条消息都要发送给所有节点，CPU、带宽等消耗较大。</p>
<p>Gossip协议的特点是：在节点数量有限的网络中，每个节点都“随机”的与部分节点通信（并不是真正的随机，而是根据特定的规则选择通信的节点），经过一番杂乱无章的通信，每个节点的状态很快会达到一致。Gossip协议的优点有负载(比广播)低、去中心化、容错性高(因为通信有冗余)等；缺点主要是集群的收敛速度慢。</p>
<h3 id="消息类型"><a href="#消息类型" class="headerlink" title="消息类型"></a>消息类型</h3><p>集群中的节点采用固定频率（每秒10次）的定时任务进行通信相关的工作：判断是否需要发送消息及消息类型、确定接收节点、发送消息等。如果集群状态发生了变化，如增减节点、槽状态变更，通过节点间的通信，所有节点会很快得知整个集群的状态，使集群收敛。</p>
<p>节点间发送的消息主要分为5种：meet消息、ping消息、pong消息、fail消息、publish消息。不同的消息类型，通信协议、发送的频率和时机、接收节点的选择等是不同的。</p>
<ul>
<li><p>MEET消息：在节点握手阶段，当节点收到客户端的CLUSTER<br>MEET命令时，会向新加入的节点发送MEET消息，请求新节点加入到当前集群；新节点收到MEET消息后会回复一个PONG消息。</p>
</li>
<li><p>PING消息：集群里每个节点每秒钟会选择部分节点发送PING消息，接收者收到消息后会回复一个PONG消息。PING消息的内容是自身节点和部分其他节点的状态信息；作用是彼此交换信息，以及检测节点是否在线。PING消息使用Gossip协议发送，接收节点的选择兼顾了收敛速度和带宽成本，具体规则如下：(1)随机找5个节点，在其中选择最久没有通信的1个节点(2)扫描节点列表，选择最近一次收到PONG消息时间大于cluster_node_timeout/2的所有节点，防止这些节点长时间未更新。</p>
</li>
<li><p>PONG消息：PONG消息封装了自身状态数据。可以分为两种：第一种是在接到MEET/PING消息后回复的PONG消息；第二种是指节点向集群广播PONG消息，这样其他节点可以获知该节点的最新信息，例如故障恢复后新的主节点会广播PONG消息。</p>
</li>
<li><p>FAIL消息：当一个主节点判断另一个主节点进入FAIL状态时，会向集群广播这一FAIL消息；接收节点会将这一FAIL消息保存起来，便于后续的判断。</p>
</li>
<li><p>PUBLISH消息：节点收到PUBLISH命令后，会先执行该命令，然后向集群广播这一消息，接收节点也会执行该PUBLISH命令。</p>
</li>
</ul>
<ol start="3">
<li>数据结构</li>
</ol>
<hr>
<p>节点需要专门的数据结构来存储集群的状态。所谓集群的状态，是一个比较大的概念，包括：集群是否处于上线状态、集群中有哪些节点、节点是否可达、节点的主从状态、槽的分布……</p>
<p>节点为了存储集群状态而提供的数据结构中，最关键的是clusterNode和clusterState结构：前者记录了一个节点的状态，后者记录了集群作为一个整体的状态。</p>
<h3 id="clusterNode"><a href="#clusterNode" class="headerlink" title="clusterNode"></a>clusterNode</h3><p>clusterNode结构保存了一个节点的当前状态，包括创建时间、节点id、ip和端口号等。每个节点都会用一个clusterNode结构记录自己的状态，并为集群内所有其他节点都创建一个clusterNode结构来记录节点状态。</p>
<p>下面列举了clusterNode的部分字段，并说明了字段的含义和作用：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">typedef struct clusterNode &#123;</span><br><span class="line">    //节点创建时间</span><br><span class="line">    mstime_t ctime;</span><br><span class="line"> </span><br><span class="line">    //节点id</span><br><span class="line">    char name[REDIS_CLUSTER_NAMELEN];</span><br><span class="line"> </span><br><span class="line">    //节点的ip和端口号</span><br><span class="line">    char ip[REDIS_IP_STR_LEN];</span><br><span class="line">    int port;</span><br><span class="line"> </span><br><span class="line">    //节点标识：整型，每个bit都代表了不同状态，如节点的主从状态、是否在线、是否在握手等</span><br><span class="line">    int flags;</span><br><span class="line"> </span><br><span class="line">    //配置纪元：故障转移时起作用，类似于哨兵的配置纪元</span><br><span class="line">    uint64_t configEpoch;</span><br><span class="line"> </span><br><span class="line">    //槽在该节点中的分布：占用16384/8个字节，16384个比特；每个比特对应一个槽：比特值为1，则该比特对应的槽在节点中；比特值为0，则该比特对应的槽不在节点中</span><br><span class="line">    unsigned char slots[16384/8];</span><br><span class="line"> </span><br><span class="line">    //节点中槽的数量</span><br><span class="line">    int numslots;</span><br><span class="line"> </span><br><span class="line">    …………</span><br><span class="line"> </span><br><span class="line">&#125; clusterNode;</span><br></pre></td></tr></table></figure></p>
<p>除了上述字段，clusterNode还包含节点连接、主从复制、故障发现和转移需要的信息等。</p>
<h3 id="clusterState"><a href="#clusterState" class="headerlink" title="clusterState"></a>clusterState</h3><p>clusterState结构保存了在当前节点视角下，集群所处的状态。主要字段包括：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">typedef struct clusterState &#123;</span><br><span class="line"> </span><br><span class="line">    //自身节点</span><br><span class="line">    clusterNode *myself;</span><br><span class="line"> </span><br><span class="line">    //配置纪元</span><br><span class="line">    uint64_t currentEpoch;</span><br><span class="line"> </span><br><span class="line">    //集群状态：在线还是下线</span><br><span class="line">    int state;</span><br><span class="line"> </span><br><span class="line">    //集群中至少包含一个槽的节点数量</span><br><span class="line">    int size;</span><br><span class="line"> </span><br><span class="line">    //哈希表，节点名称-&gt;clusterNode节点指针</span><br><span class="line">    dict *nodes;</span><br><span class="line">  </span><br><span class="line">    //槽分布信息：数组的每个元素都是一个指向clusterNode结构的指针；如果槽还没有分配给任何节点，则为NULL</span><br><span class="line">    clusterNode *slots[16384];</span><br><span class="line"> </span><br><span class="line">    …………</span><br><span class="line">     </span><br><span class="line">&#125; clusterState;</span><br></pre></td></tr></table></figure></p>
<p>除此之外，clusterState还包括故障转移、槽迁移等需要的信息。</p>
<ol start="4">
<li>集群命令的实现</li>
</ol>
<hr>
<p>这一部分将以cluster meet(节点握手)、cluster<br>addslots(槽分配)为例，说明节点是如何利用上述数据结构和通信机制实现集群命令的。</p>
<h3 id="cluster-meet"><a href="#cluster-meet" class="headerlink" title="cluster meet"></a>cluster meet</h3><p>假设要向A节点发送cluster<br>meet命令，将B节点加入到A所在的集群，则A节点收到命令后，执行的操作如下：</p>
<p>1)  A为B创建一个clusterNode结构，并将其添加到clusterState的nodes字典中</p>
<p>2)  A向B发送MEET消息</p>
<p>3)<br> B收到MEET消息后，会为A创建一个clusterNode结构，并将其添加到clusterState的nodes字典中</p>
<p>4)  B回复A一个PONG消息</p>
<p>5)  A收到B的PONG消息后，便知道B已经成功接收自己的MEET消息</p>
<p>6)  然后，A向B返回一个PING消息</p>
<p>7)  B收到A的PING消息后，便知道A已经成功接收自己的PONG消息，握手完成</p>
<p>8)<br> 之后，A通过Gossip协议将B的信息广播给集群内其他节点，其他节点也会与B握手；一段时间后，集群收敛，B成为集群内的一个普通节点</p>
<p>通过上述过程可以发现，集群中两个节点的握手过程与TCP类似，都是三次握手：A向B发送MEET；B向A发送PONG；A向B发送PING。</p>
<h3 id="cluster-addslots"><a href="#cluster-addslots" class="headerlink" title="cluster addslots"></a>cluster addslots</h3><p>集群中槽的分配信息，存储在clusterNode的slots数组和clusterState的slots数组中，两个数组的结构前面已做介绍；二者的区别在于：前者存储的是该节点中分配了哪些槽，后者存储的是集群中所有槽分别分布在哪个节点。</p>
<p>cluster addslots命令接收一个槽或多个槽作为参数，例如在A节点上执行cluster<br>addslots {0..10}命令，是将编号为0-10的槽分配给A节点，具体执行过程如下：</p>
<p>1)<br> 遍历输入槽，检查它们是否都没有分配，如果有一个槽已分配，命令执行失败；方法是检查输入槽在clusterState.slots[]中对应的值是否为NULL。</p>
<p>2)<br> 遍历输入槽，将其分配给节点A；方法是修改clusterNode.slots[]中对应的比特为1，以及clusterState.slots[]中对应的指针指向A节点</p>
<p>3)<br> A节点执行完成后，通过节点通信机制通知其他节点，所有节点都会知道0-10的槽分配给了A节点</p>
<h1 id="四、客户端访问集群"><a href="#四、客户端访问集群" class="headerlink" title="四、客户端访问集群"></a>四、客户端访问集群</h1><p>在集群中，数据分布在不同的节点中，客户端通过某节点访问数据时，数据可能不在该节点中；下面介绍集群是如何处理这个问题的。</p>
<ol>
<li>redis-cli</li>
</ol>
<hr>
<p>当节点收到redis-cli发来的命令(如set/get)时，过程如下：</p>
<p>（1）计算key属于哪个槽：CRC16(key) &amp; 16383</p>
<p>集群提供的cluster keyslot命令也是使用上述公式实现，如：</p>
<p><img src="http://47.103.200.134/image/844b80084885262858739fa8c0bb6a0f.png" alt="https://img2018.cnblogs.com/blog/1174710/201810/1174710-20181025213526293-2135260770.png"></p>
<p>（2）判断key所在的槽是否在当前节点：假设key位于第i个槽，clusterState.slots[i]则指向了槽所在的节点，如果clusterState.slots[i]==clusterState.myself，说明槽在当前节点，可以直接在当前节点执行命令；否则，说明槽不在当前节点，则查询槽所在节点的地址(clusterState.slots[i].ip/port)，并将其包装到MOVED错误中返回给redis-cli。</p>
<p>（3）redis-cli收到MOVED错误后，根据返回的ip和port重新发送请求。</p>
<p>下面的例子展示了redis-cli和集群的互动过程：在7000节点中操作key1，但key1所在的槽9189在节点7001中，因此节点返回MOVED错误(包含7001节点的ip和port)给redis-cli，redis-cli重新向7001发起请求。</p>
<p><img src="http://47.103.200.134/image/f12f73af9f6c98530b089473e3e01a2b.png" alt="https://img2018.cnblogs.com/blog/1174710/201810/1174710-20181025213538657-1442189386.png"></p>
<p>上例中，redis-cli通过-c指定了集群模式，如果没有指定，redis-cli无法处理MOVED错误：</p>
<p><img src="http://47.103.200.134/image/dd802a80ca4530202023a95e6f1b84ff.png" alt="https://img2018.cnblogs.com/blog/1174710/201810/1174710-20181025213547148-375130837.png"></p>
<ol start="2">
<li>Smart客户端</li>
</ol>
<hr>
<p>redis-cli这一类客户端称为Dummy客户端，因为它们在执行命令前不知道数据在哪个节点，需要借助MOVED错误重新定向。与Dummy客户端相对应的是Smart客户端。</p>
<p>Smart客户端（以Java的JedisCluster为例）的基本原理：</p>
<p>（1）JedisCluster初始化时，在内部维护slot->node的缓存，方法是连接任一节点，执行cluster<br>slots命令，该命令返回如下所示：</p>
<p><img src="http://47.103.200.134/image/7085ddf98fedd42ced43776dab827940.png" alt="https://img2018.cnblogs.com/blog/1174710/201810/1174710-20181025213555809-1623036683.png"></p>
<p>（2）此外，JedisCluster为每个节点创建连接池(即JedisPool)。</p>
<p>（3）当执行命令时，JedisCluster根据key->slot->node选择需要连接的节点，发送命令。如果成功，则命令执行完毕。如果执行失败，则会随机选择其他节点进行重试，并在出现MOVED错误时，使用cluster<br>slots重新同步slot->node的映射关系。</p>
<p>下面代码演示了如何使用JedisCluster访问集群(未考虑资源释放、异常处理等)：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">public static void test() &#123;</span><br><span class="line">   Set&lt;HostAndPort&gt; nodes = new HashSet&lt;&gt;();</span><br><span class="line">   nodes.add(new HostAndPort(&quot;192.168.72.128&quot;, 7000));</span><br><span class="line">   nodes.add(new HostAndPort(&quot;192.168.72.128&quot;, 7001));</span><br><span class="line">   nodes.add(new HostAndPort(&quot;192.168.72.128&quot;, 7002));</span><br><span class="line">   nodes.add(new HostAndPort(&quot;192.168.72.128&quot;, 8000));</span><br><span class="line">   nodes.add(new HostAndPort(&quot;192.168.72.128&quot;, 8001));</span><br><span class="line">   nodes.add(new HostAndPort(&quot;192.168.72.128&quot;, 8002));</span><br><span class="line">   JedisCluster cluster = new JedisCluster(nodes);</span><br><span class="line">   System.out.println(cluster.get(&quot;key1&quot;));</span><br><span class="line">   cluster.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注意事项如下：</p>
<p>（1）JedisCluster中已经包含所有节点的连接池，因此JedisCluster要使用单例。</p>
<p>（2）客户端维护了slot->node映射关系以及为每个节点创建了连接池，当节点数量较多时，应注意客户端内存资源和连接资源的消耗。</p>
<p>（3）Jedis较新版本针对JedisCluster做了一些性能方面的优化，如cluster<br>slots缓存更新和锁阻塞等方面的优化，应尽量使用2.8.2及以上版本的Jedis。</p>
<h1 id="五、实践须知"><a href="#五、实践须知" class="headerlink" title="五、实践须知"></a>五、实践须知</h1><p>前面介绍了集群正常运行和访问的方法和原理，下面是一些重要的补充内容。</p>
<ol>
<li>集群伸缩</li>
</ol>
<hr>
<p>实践中常常需要对集群进行伸缩，如访问量增大时的扩容操作。Redis集群可以在不影响对外服务的情况下实现伸缩；<strong>伸缩的核心是槽迁移：修改槽与节点的对应关系，实现槽(即数据)在节点之间的移动。</strong>例如，如果槽均匀分布在集群的3个节点中，此时增加一个节点，则需要从3个节点中分别拿出一部分槽给新节点，从而实现槽在4个节点中的均匀分布。</p>
<h3 id="增加节点"><a href="#增加节点" class="headerlink" title="增加节点"></a>增加节点</h3><p>假设要增加7003和8003节点，其中8003是7003的从节点；步骤如下：</p>
<p>（1）启动节点：方法参见集群搭建</p>
<p>（2）节点握手：可以使用cluster<br>meet命令，但在生产环境中建议使用redis-trib.rb的add-node工具，其原理也是cluster<br>meet，但它会先检查新节点是否已加入其它集群或者存在数据，避免加入到集群后带来混乱。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">redis-trib.rb add-node 192.168.72.128:7003 192.168.72.128 7000</span><br><span class="line">redis-trib.rb add-node 192.168.72.128:8003 192.168.72.128 7000</span><br></pre></td></tr></table></figure>
<p>（3）迁移槽：推荐使用redis-trib.rb的reshard工具实现。reshard自动化程度很高，只需要输入redis-trib.rb<br>reshard ip:port<br>(ip和port可以是集群中的任一节点)，然后按照提示输入以下信息，槽迁移会自动完成：</p>
<ul>
<li><p>待迁移的槽数量：16384个槽均分给4个节点，每个节点4096个槽，因此待迁移槽数量为4096</p>
<ul>
<li><p>目标节点id：7003节点的id</p>
</li>
<li><p>源节点的id：7000/7001/7002节点的id</p>
</li>
</ul>
</li>
</ul>
<p>（4）指定主从关系：方法参见集群搭建</p>
<h3 id="减少节点"><a href="#减少节点" class="headerlink" title="减少节点"></a>减少节点</h3><p>假设要下线7000/8000节点，可以分为两步：</p>
<p>（1）迁移槽：使用reshard将7000节点中的槽均匀迁移到7001/7002/7003节点</p>
<p>（2）下线节点：使用redis-trib.rb<br>del-node工具；应先下线从节点再下线主节点，因为若主节点先下线，从节点会被指向其他主节点，造成不必要的全量复制。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">redis-trib.rb del-node 192.168.72.128:7001 &#123;节点8000的id&#125;</span><br><span class="line">redis-trib.rb del-node 192.168.72.128:7001 &#123;节点7000的id&#125;</span><br></pre></td></tr></table></figure>
<h3 id="ASK错误"><a href="#ASK错误" class="headerlink" title="ASK错误"></a>ASK错误</h3><p>集群伸缩的核心是槽迁移。在槽迁移过程中，如果客户端向源节点发送命令，源节点执行流程如下：</p>
<p><img src="http://47.103.200.134/image/baf7a97aa79286f383b625793aad7253.png" alt="https://img2018.cnblogs.com/blog/1174710/201810/1174710-20181025213612837-648236990.png"></p>
<p>图片来源：《Redis设计与实现》</p>
<p>客户端收到ASK错误后，从中读取目标节点的地址信息，并向目标节点重新发送请求，就像收到MOVED错误时一样。但是二者有很大区别：ASK错误说明数据正在迁移，不知道何时迁移完成，因此重定向是临时的，SMART客户端不会刷新slots缓存；MOVED错误重定向则是(相对)永久的，SMART客户端会刷新slots缓存。</p>
<ol start="2">
<li>故障转移</li>
</ol>
<hr>
<p>在 <a href="https://www.cnblogs.com/kismetv/p/9609938.html#t42" target="_blank" rel="noopener">哨兵</a> 一文中，介绍了哨兵实现故障发现和故障转移的原理。虽然细节上有很大不同，但集群的实现与哨兵思路类似：通过定时任务发送PING消息检测其他节点状态；节点下线分为主观下线和客观下线；客观下线后选取从节点进行故障转移。</p>
<p>与哨兵一样，集群只实现了主节点的故障转移；从节点故障时只会被下线，不会进行故障转移。因此，使用集群时，应谨慎使用读写分离技术，因为从节点故障会导致读服务不可用，可用性变差。</p>
<p>这里不再详细介绍故障转移的细节，只对重要事项进行说明：</p>
<p><strong>节点数量：</strong>在故障转移阶段，需要由主节点投票选出哪个从节点成为新的主节点；从节点选举胜出需要的票数为N/2+1；其中N为主节点数量(包括故障主节点)，但故障主节点实际上不能投票。因此为了能够在故障发生时顺利选出从节点，集群中至少需要3个主节点(且部署在不同的物理机上)。</p>
<p><strong>故障转移时间：</strong>从主节点故障发生到完成转移，所需要的时间主要消耗在主观下线识别、主观下线传播、选举延迟等几个环节；具体时间与参数cluster-node-timeout有关，一般来说：</p>
<p>故障转移时间(毫秒) ≤ 1.5 * cluster-node-timeout + 1000</p>
<p>cluster-node-timeout的默认值为15000ms(15s)，因此故障转移时间会在20s量级。</p>
<ol start="3">
<li>集群的限制及应对方法</li>
</ol>
<hr>
<p>由于集群中的数据分布在不同节点中，导致一些功能受限，包括：</p>
<p>（1）key批量操作受限：例如mget、mset操作，只有当操作的key都位于一个槽时，才能进行。针对该问题，一种思路是在客户端记录槽与key的信息，每次针对特定槽执行mget/mset；另外一种思路是使用Hash<br>Tag，将在下一小节介绍。</p>
<p>（2）keys/flushall等操作：keys/flushall等操作可以在任一节点执行，但是结果只针对当前节点，例如keys操作只返回当前节点的所有键。针对该问题，可以在客户端使用cluster<br>nodes获取所有节点信息，并对其中的所有主节点执行keys/flushall等操作。</p>
<p>（3）事务/Lua脚本：集群支持事务及Lua脚本，但前提条件是所涉及的key必须在同一个节点。Hash<br>Tag可以解决该问题。</p>
<p>（4）数据库：单机Redis节点可以支持16个数据库，集群模式下只支持一个，即db0。</p>
<p>（5）复制结构：只支持一层复制结构，不支持嵌套。</p>
<ol start="4">
<li>Hash Tag</li>
</ol>
<hr>
<p>Hash Tag原理是：<strong>当一个key包含 {} 的时候，不对整个key做hash，而仅对<br>{} 包括的字符串做hash。</strong></p>
<p>Hash<br>Tag可以让不同的key拥有相同的hash值，从而分配在同一个槽里；这样针对不同key的批量操作(mget/mset等)，以及事务、Lua脚本等都可以支持。不过Hash<br>Tag可能会带来数据分配不均的问题，这时需要：(1)调整不同节点中槽的数量，使数据分布尽量均匀；(2)避免对热点数据使用Hash<br>Tag，导致请求分布不均。</p>
<p>下面是使用Hash Tag的一个例子；通过对product加Hash<br>Tag，可以将所有产品信息放到同一个槽中，便于操作。</p>
<p><img src="http://47.103.200.134/image/4e299cb0686e802d8bf4063734f09240.png" alt="https://img2018.cnblogs.com/blog/1174710/201810/1174710-20181025213630192-1534783794.png"></p>
<ol start="5">
<li>参数优化</li>
</ol>
<hr>
<h3 id="cluster-node-timeout"><a href="#cluster-node-timeout" class="headerlink" title="cluster_node_timeout"></a>cluster_node_timeout</h3><p>cluster_node_timeout参数在前面已经初步介绍；它的默认值是15s，影响包括：</p>
<p>（1）影响PING消息接收节点的选择：值越大对延迟容忍度越高，选择的接收节点越少，可以降低带宽，但会降低收敛速度；应根据带宽情况和应用要求进行调整。</p>
<p>（2）影响故障转移的判定和时间：值越大，越不容易误判，但完成转移消耗时间越长；应根据网络状况和应用要求进行调整。</p>
<h3 id="cluster-require-full-coverage"><a href="#cluster-require-full-coverage" class="headerlink" title="cluster-require-full-coverage"></a>cluster-require-full-coverage</h3><p>前面提到，只有当16384个槽全部分配完毕时，集群才能上线。这样做是为了保证集群的完整性，但同时也带来了新的问题：当主节点发生故障而故障转移尚未完成，原主节点中的槽不在任何节点中，此时会集群处于下线状态，无法响应客户端的请求。</p>
<p>cluster-require-full-coverage参数可以改变这一设定：如果设置为no，则当槽没有完全分配时，集群仍可以上线。参数默认值为yes，如果应用对可用性要求较高，可以修改为no，但需要自己保证槽全部分配。</p>
<ol start="6">
<li>redis-trib.rb</li>
</ol>
<hr>
<p>redis-trib.rb提供了众多实用工具：创建集群、增减节点、槽迁移、检查完整性、数据重新平衡等；通过help命令可以查看详细信息。在实践中如果能使用redis-trib.rb工具则尽量使用，不但方便快捷，还可以大大降低出错概率。</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>《Redis开发与运维》</p>
<p>《Redis设计与实现》</p>
<p><a href="https://redis.io/topics/cluster-tutorial" target="_blank" rel="noopener">https://redis.io/topics/cluster-tutorial</a></p>
<p><a href="https://redis.io/topics/cluster-spec" target="_blank" rel="noopener">https://redis.io/topics/cluster-spec</a></p>
<p><a href="https://mp.weixin.qq.com/s/d6hzmk31o7VBsMYaLdQ5mw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/d6hzmk31o7VBsMYaLdQ5mw</a></p>
<p><a href="https://www.cnblogs.com/lpfuture/p/5796398.html" target="_blank" rel="noopener">https://www.cnblogs.com/lpfuture/p/5796398.html</a></p>
<p><a href="http://www.zsythink.net/archives/1182/" target="_blank" rel="noopener">http://www.zsythink.net/archives/1182/</a></p>
<p><a href="https://www.cnblogs.com/xxdfly/p/5641719.html" target="_blank" rel="noopener">https://www.cnblogs.com/xxdfly/p/5641719.html</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.zengmanhua.cn/2019/06/14/哨兵/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jin Yu Bao">
      <meta itemprop="description" content="生活源于奋斗">
      <meta itemprop="image" content="http://prl6c63q7.bkt.clouddn.com/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JinYuBao">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/06/14/哨兵/" class="post-title-link" itemprop="url">哨兵</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-06-14 16:03:21" itemprop="dateCreated datePublished" datetime="2019-06-14T16:03:21+08:00">2019-06-14</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/technology/" itemprop="url" rel="index"><span itemprop="name">技术</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2019/06/14/哨兵/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/06/14/哨兵/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在 <a href>深入学习Redis（3）：主从复制</a> 中曾提到，Redis主从复制的作用有数据热备、负载均衡、故障恢复等；但主从复制存在的一个问题是故障恢复无法自动化。本文将要介绍的哨兵，它基于Redis主从复制，主要作用便是解决主节点故障恢复的自动化问题，进一步提高系统的高可用性。</p>
<p>文章主要内容如下：首先介绍哨兵的作用和架构；然后讲述哨兵系统的部署方法，以及通过客户端访问哨兵系统的方法；然后简要说明哨兵实现的基本原理；最后给出关于哨兵实践的一些建议。文章内容基于Redis<br>3.0版本。</p>
<h1 id="一、作用和架构"><a href="#一、作用和架构" class="headerlink" title="一、作用和架构"></a>一、作用和架构</h1><ol>
<li>作用</li>
</ol>
<hr>
<p>在介绍哨兵之前，首先从宏观角度回顾一下Redis实现高可用相关的技术。它们包括：持久化、复制、哨兵和集群，其主要作用和解决的问题是：</p>
<ul>
<li><p>持久化：持久化是最简单的高可用方法(有时甚至不被归为高可用的手段)，主要作用是数据备份，即将数据存储在硬盘，保证数据不会因进程退出而丢失。</p>
</li>
<li><p>复制：复制是高可用Redis的基础，哨兵和集群都是在复制基础上实现高可用的。复制主要实现了数据的多机备份，以及对于读操作的负载均衡和简单的故障恢复。缺陷：故障恢复无法自动化；写操作无法负载均衡；存储能力受到单机的限制。</p>
</li>
<li><p>哨兵：在复制的基础上，哨兵实现了自动化的故障恢复。缺陷：写操作无法负载均衡；存储能力受到单机的限制。</p>
</li>
<li><p>集群：通过集群，Redis解决了写操作无法负载均衡，以及存储能力受到单机限制的问题，实现了较为完善的高可用方案。</p>
</li>
</ul>
<p>下面说回哨兵。</p>
<p>Redis Sentinel，即Redis哨兵，在Redis<br>2.8版本开始引入。<strong>哨兵的核心功能是主节点的自动故障转移。</strong>下面是Redis官方文档对于哨兵功能的描述：</p>
<ul>
<li><p>监控（Monitoring）：哨兵会不断地检查主节点和从节点是否运作正常。</p>
</li>
<li><p>自动故障转移（Automatic<br>failover）：当主节点不能正常工作时，哨兵会开始自动故障转移操作，它会将失效主节点的其中一个从节点升级为新的主节点，并让其他从节点改为复制新的主节点。</p>
</li>
<li><p>配置提供者（Configuration<br>provider）：客户端在初始化时，通过连接哨兵来获得当前Redis服务的主节点地址。</p>
</li>
<li><p>通知（Notification）：哨兵可以将故障转移的结果发送给客户端。</p>
</li>
</ul>
<p>其中，监控和自动故障转移功能，使得哨兵可以及时发现主节点故障并完成转移；而配置提供者和通知功能，则需要在与客户端的交互中才能体现。</p>
<p>这里对“客户端”一词在文章中的用法做一个说明：在前面的文章中，只要通过API访问redis服务器，都会称作客户端，包括redis-cli、Java客户端Jedis等；为了便于区分说明，本文中的客户端并不包括redis-cli，而是比redis-cli更加复杂：redis-cli使用的是redis提供的底层接口，而客户端则对这些接口、功能进行了封装，以便充分利用哨兵的配置提供者和通知功能。</p>
<ol start="2">
<li>架构</li>
</ol>
<hr>
<p>典型的哨兵架构图如下所示：</p>
<p><img src="http://47.103.200.134/image/79f920fcf9cf0fdb62b50c3f5a6b5d5c.png" alt="https://images2018.cnblogs.com/blog/1174710/201809/1174710-20180908182924632-1069251418.png"></p>
<p>它由两部分组成，哨兵节点和数据节点：</p>
<ul>
<li><p>哨兵节点：哨兵系统由一个或多个哨兵节点组成，哨兵节点是特殊的redis节点，不存储数据。</p>
</li>
<li><p>数据节点：主节点和从节点都是数据节点。</p>
</li>
</ul>
<h1 id="二、部署"><a href="#二、部署" class="headerlink" title="二、部署"></a>二、部署</h1><p>这一部分将部署一个简单的哨兵系统，包含1个主节点、2个从节点和3个哨兵节点。方便起见：所有这些节点都部署在一台机器上（局域网IP：192.168.92.128），使用端口号区分；节点的配置尽可能简化。</p>
<ol>
<li>部署主从节点</li>
</ol>
<hr>
<p>哨兵系统中的主从节点，与普通的主从节点配置是一样的，并不需要做任何额外配置。下面分别是主节点（port=6379）和2个从节点（port=6380/6381）的配置文件，配置都比较简单，不再详述。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">#redis-6379.conf</span><br><span class="line">port 6379</span><br><span class="line">daemonize yes</span><br><span class="line">logfile &quot;6379.log&quot;</span><br><span class="line">dbfilename &quot;dump-6379.rdb&quot;</span><br><span class="line"> </span><br><span class="line">#redis-6380.conf</span><br><span class="line">port 6380</span><br><span class="line">daemonize yes</span><br><span class="line">logfile &quot;6380.log&quot;</span><br><span class="line">dbfilename &quot;dump-6380.rdb&quot;</span><br><span class="line">slaveof 192.168.92.128 6379</span><br><span class="line"> </span><br><span class="line">#redis-6381.conf</span><br><span class="line">port 6381</span><br><span class="line">daemonize yes</span><br><span class="line">logfile &quot;6381.log&quot;</span><br><span class="line">dbfilename &quot;dump-6381.rdb&quot;</span><br><span class="line">slaveof 192.168.92.128 6379</span><br></pre></td></tr></table></figure></p>
<p>配置完成后，依次启动主节点和从节点：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">redis-server redis-6379.conf</span><br><span class="line">redis-server redis-6380.conf</span><br><span class="line">redis-server redis-6381.conf</span><br></pre></td></tr></table></figure></p>
<p>节点启动后，连接主节点查看主从状态是否正常，如下图所示：</p>
<p><img src="http://47.103.200.134/image/4e6afd90c6aae93cd725279351071554.png" alt="https://images2018.cnblogs.com/blog/1174710/201809/1174710-20180908183301683-144536284.png"></p>
<ol start="2">
<li>部署哨兵节点</li>
</ol>
<hr>
<p>哨兵节点本质上是特殊的Redis节点。</p>
<p>3个哨兵节点的配置几乎是完全一样的，主要区别在于端口号的不同（26379/26380/26381），下面以26379节点为例介绍节点的配置和启动方式；配置部分尽量简化，更多配置会在后面介绍。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#sentinel-26379.conf</span><br><span class="line">port 26379</span><br><span class="line">daemonize yes</span><br><span class="line">logfile &quot;26379.log&quot;</span><br><span class="line">sentinel monitor mymaster 192.168.92.128 6379 2</span><br></pre></td></tr></table></figure></p>
<p>其中，sentinel monitor mymaster 192.168.92.128 6379 2<br>配置的含义是：该哨兵节点监控192.168.92.128:6379这个主节点，该主节点的名称是mymaster，最后的2的含义与主节点的故障判定有关：至少需要2个哨兵节点同意，才能判定主节点故障并进行故障转移。</p>
<p>哨兵节点的启动有两种方式，二者作用是完全相同的：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">redis-sentinel sentinel-26379.conf</span><br><span class="line">redis-server sentinel-26379.conf --sentinel</span><br></pre></td></tr></table></figure>
<p>按照上述方式配置和启动之后，整个哨兵系统就启动完毕了。可以通过redis-cli连接哨兵节点进行验证，如下图所示：可以看出26379哨兵节点已经在监控mymaster主节点(即192.168.92.128:6379)，并发现了其2个从节点和另外2个哨兵节点。</p>
<p><img src="http://47.103.200.134/image/42bdf3cb1224bf7ad64e56b06bb93f52.png" alt="https://images2018.cnblogs.com/blog/1174710/201809/1174710-20180908183617525-1093971812.png"></p>
<p>此时如果查看哨兵节点的配置文件，会发现一些变化，以26379为例：</p>
<p><img src="http://47.103.200.134/image/3853fb8d407e4d400582c11019dec7d4.png" alt="https://images2018.cnblogs.com/blog/1174710/201809/1174710-20180908183638920-415715616.png"></p>
<p>其中，dir只是显式声明了数据和日志所在的目录（在哨兵语境下只有日志）；known-slave和known-sentinel显示哨兵已经发现了从节点和其他哨兵；带有epoch的参数与配置纪元有关（配置纪元是一个从0开始的计数器，每进行一次领导者哨兵选举，都会+1；领导者哨兵选举是故障转移阶段的一个操作，在后文原理部分会介绍）。</p>
<ol start="3">
<li>演示故障转移</li>
</ol>
<hr>
<p>哨兵的4个作用中，配置提供者和通知需要客户端的配合，本文将在下一章介绍客户端访问哨兵系统的方法时详细介绍。这一小节将演示当主节点发生故障时，哨兵的监控和自动故障转移功能。</p>
<p>（1）首先，使用kill命令杀掉主节点：</p>
<p><img src="http://47.103.200.134/image/c852c4c824724004f77c5dbab5bd2bb4.png" alt="https://images2018.cnblogs.com/blog/1174710/201809/1174710-20180908183838785-441116675.png"></p>
<p>（2）如果此时立即在哨兵节点中使用info<br>Sentinel命令查看，会发现主节点还没有切换过来，因为哨兵发现主节点故障并转移，需要一段时间。</p>
<p><img src="http://47.103.200.134/image/76fb9896ce996b40b025095b3aff8fae.png" alt="https://images2018.cnblogs.com/blog/1174710/201809/1174710-20180908183852136-117673335.png"></p>
<p>（3）一段时间以后，再次在哨兵节点中执行info<br>Sentinel查看，发现主节点已经切换成6380节点。</p>
<p><img src="http://47.103.200.134/image/ced540af73512ed92e85e5d3abd17fbc.png" alt="https://images2018.cnblogs.com/blog/1174710/201809/1174710-20180908183951805-1759290657.png"></p>
<p>但是同时可以发现，哨兵节点认为新的主节点仍然有2个从节点，这是因为哨兵在将6380切换成主节点的同时，将6379节点置为其从节点；虽然6379从节点已经挂掉，但是由于哨兵并不会对从节点进行客观下线（其含义将在原理部分介绍），因此认为该从节点一直存在。当6379节点重新启动后，会自动变成6380节点的从节点。下面验证一下。</p>
<p>（4）重启6379节点：可以看到6379节点成为了6380节点的从节点。</p>
<p><img src="http://47.103.200.134/image/e70047aaa8fa31284af051c2aa4b5dd2.png" alt="https://images2018.cnblogs.com/blog/1174710/201809/1174710-20180908184001127-989060126.png"></p>
<p>（5）在故障转移阶段，哨兵和主从节点的配置文件都会被改写。</p>
<p>对于主从节点，主要是slaveof配置的变化：新的主节点没有了slaveof配置，其从节点则slaveof新的主节点。</p>
<p>对于哨兵节点，除了主从节点信息的变化，纪元(epoch)也会变化，下图中可以看到纪元相关的参数都+1了。</p>
<p><img src="http://47.103.200.134/image/90ba6790ecac35b5a59b847fbdbc479c.png" alt="https://images2018.cnblogs.com/blog/1174710/201809/1174710-20180908184011583-1016380070.png"></p>
<ol start="4">
<li>总结</li>
</ol>
<hr>
<p>哨兵系统的搭建过程，有几点需要注意：</p>
<p>（1）哨兵系统中的主从节点，与普通的主从节点并没有什么区别，故障发现和转移是由哨兵来控制和完成的。</p>
<p>（2）哨兵节点本质上是redis节点。</p>
<p>（3）每个哨兵节点，只需要配置监控主节点，便可以自动发现其他的哨兵节点和从节点。</p>
<p>（4）在哨兵节点启动和故障转移阶段，各个节点的配置文件会被重写(config rewrite)。</p>
<p>（5）本章的例子中，一个哨兵只监控了一个主节点；实际上，一个哨兵可以监控多个主节点，通过配置多条sentinel<br>monitor即可实现。</p>
<h1 id="三、客户端访问哨兵系统"><a href="#三、客户端访问哨兵系统" class="headerlink" title="三、客户端访问哨兵系统"></a>三、客户端访问哨兵系统</h1><p>上一小节演示了哨兵的两大作用：监控和自动故障转移，本小节则结合客户端演示哨兵的另外两个作用：配置提供者和通知。</p>
<ol>
<li>代码示例</li>
</ol>
<hr>
<p>在介绍客户端的原理之前，先以Java客户端Jedis为例，演示一下使用方法：下面代码可以连接我们刚刚搭建的哨兵系统，并进行各种读写操作（代码中只演示如何连接哨兵，异常处理、资源关闭等未考虑）。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">public static void testSentinel() throws Exception &#123;</span><br><span class="line">         String masterName = &quot;mymaster&quot;;</span><br><span class="line">         Set&lt;String&gt; sentinels = new HashSet&lt;&gt;();</span><br><span class="line">         sentinels.add(&quot;192.168.92.128:26379&quot;);</span><br><span class="line">         sentinels.add(&quot;192.168.92.128:26380&quot;);</span><br><span class="line">         sentinels.add(&quot;192.168.92.128:26381&quot;);</span><br><span class="line"> </span><br><span class="line">         JedisSentinelPool pool = new JedisSentinelPool(masterName, sentinels); //初始化过程做了很多工作</span><br><span class="line">         Jedis jedis = pool.getResource();</span><br><span class="line">         jedis.set(&quot;key1&quot;, &quot;value1&quot;);</span><br><span class="line">         pool.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>客户端原理</li>
</ol>
<hr>
<p>Jedis客户端对哨兵提供了很好的支持。如上述代码所示，我们只需要向Jedis提供哨兵节点集合和masterName，构造JedisSentinelPool对象；然后便可以像使用普通redis连接池一样来使用了：通过pool.getResource()获取连接，执行具体的命令。</p>
<p>在整个过程中，我们的代码不需要显式的指定主节点的地址，就可以连接到主节点；代码中对故障转移没有任何体现，就可以在哨兵完成故障转移后自动的切换主节点。之所以可以做到这一点，是因为在JedisSentinelPool的构造器中，进行了相关的工作；主要包括以下两点：</p>
<p>（1）<strong>遍历哨兵节点，获取主节点信息：</strong>遍历哨兵节点，通过其中一个哨兵节点+masterName获得主节点的信息；该功能是通过调用哨兵节点的sentinel<br>get-master-addr-by-name命令实现，该命令示例如下：</p>
<p><img src="http://47.103.200.134/image/7ce7624d07e42ab769b12cb9ee9b7d3a.png" alt="https://images2018.cnblogs.com/blog/1174710/201809/1174710-20180909002433892-5049302.png"></p>
<p>一旦获得主节点信息，停止遍历（因此一般来说遍历到第一个哨兵节点，循环就停止了）。</p>
<p>（2）<strong>增加对哨兵的监听：</strong>这样当发生故障转移时，客户端便可以收到哨兵的通知，从而完成主节点的切换。具体做法是：利用redis提供的发布订阅功能，为每一个哨兵节点开启一个单独的线程，订阅哨兵节点的+switch-master频道，当收到消息时，重新初始化连接池。</p>
<ol start="3">
<li>总结</li>
</ol>
<hr>
<p>通过客户端原理的介绍，可以加深对哨兵功能的理解：</p>
<p>（1）配置提供者：客户端可以通过哨兵节点+masterName获取主节点信息，在这里哨兵起到的作用就是配置提供者。</p>
<p><strong>需要注意的是，哨兵只是配置提供者，而不是代理</strong>。二者的区别在于：如果是配置提供者，客户端在通过哨兵获得主节点信息后，会直接建立到主节点的连接，后续的请求(如set/get)会直接发向主节点；如果是代理，客户端的每一次请求都会发向哨兵，哨兵再通过主节点处理请求。</p>
<p>举一个例子可以很好的理解哨兵的作用是配置提供者，而不是代理。在前面部署的哨兵系统中，将哨兵节点的配置文件进行如下修改：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sentinel monitor mymaster 192.168.92.128 6379 2</span><br><span class="line">改为</span><br><span class="line">sentinel monitor mymaster 127.0.0.1 6379 2</span><br></pre></td></tr></table></figure>
<p>然后，将前述客户端代码在局域网的另外一台机器上运行，会发现客户端无法连接主节点；这是因为哨兵作为配置提供者，客户端通过它查询到主节点的地址为127.0.0.1:6379，客户端会向127.0.0.1:6379建立redis连接，自然无法连接。如果哨兵是代理，这个问题就不会出现了。</p>
<p>（2）通知：哨兵节点在故障转移完成后，会将新的主节点信息发送给客户端，以便客户端及时切换主节点。</p>
<h1 id="四、基本原理"><a href="#四、基本原理" class="headerlink" title="四、基本原理"></a>四、基本原理</h1><p>前面介绍了哨兵部署、使用的基本方法，本部分介绍哨兵实现的基本原理。</p>
<ol>
<li>哨兵节点支持的命令</li>
</ol>
<hr>
<p>哨兵节点作为运行在特殊模式下的redis节点，其支持的命令与普通的redis节点不同。在运维中，我们可以通过这些命令查询或修改哨兵系统；不过更重要的是，哨兵系统要实现故障发现、故障转移等各种功能，离不开哨兵节点之间的通信，而通信的很大一部分是通过哨兵节点支持的命令来实现的。下面介绍哨兵节点支持的主要命令。</p>
<p>（1）基础查询：通过这些命令，可以查询哨兵系统的拓扑结构、节点信息、配置信息等。</p>
<ul>
<li><p>info sentinel：获取监控的所有主节点的基本信息</p>
</li>
<li><p>sentinel masters：获取监控的所有主节点的详细信息</p>
</li>
<li><p>sentinel master mymaster：获取监控的主节点mymaster的详细信息</p>
</li>
<li><p>sentinel slaves mymaster：获取监控的主节点mymaster的从节点的详细信息</p>
</li>
<li><p>sentinel sentinels mymaster：获取监控的主节点mymaster的哨兵节点的详细信息</p>
</li>
<li><p>sentinel get-master-addr-by-name<br>mymaster：获取监控的主节点mymaster的地址信息，前文已有介绍</p>
</li>
<li><p>sentinel<br>is-master-down-by-addr：哨兵节点之间可以通过该命令询问主节点是否下线，从而对是否客观下线做出判断</p>
</li>
</ul>
<p>（2）增加/移除对主节点的监控</p>
<p>sentinel monitor mymaster2 192.168.92.128 16379<br>2：与部署哨兵节点时配置文件中的sentinel monitor功能完全一样，不再详述</p>
<p>sentinel remove mymaster2：取消当前哨兵节点对主节点mymaster2的监控</p>
<p>（3）强制故障转移</p>
<p>sentinel failover<br>mymaster：该命令可以<strong>强制对mymaster执行故障转移，</strong>即便当前的主节点运行完好；例如，如果当前主节点所在机器即将报废，便可以提前通过failover命令进行故障转移。</p>
<ol start="2">
<li>基本原理</li>
</ol>
<hr>
<p>关于哨兵的原理，关键是了解以下几个概念。</p>
<p>（1）定时任务：每个哨兵节点维护了3个定时任务。定时任务的功能分别如下：通过向主从节点发送info命令获取最新的主从结构；通过发布订阅功能获取其他哨兵节点的信息；通过向其他节点发送ping命令进行心跳检测，判断是否下线。</p>
<p>（2）主观下线：在心跳检测的定时任务中，如果其他节点超过一定时间没有回复，哨兵节点就会将其进行主观下线。顾名思义，主观下线的意思是一个哨兵节点“主观地”判断下线；与主观下线相对应的是客观下线。</p>
<p>（3）客观下线：哨兵节点在对主节点进行主观下线后，会通过sentinel<br>is-master-down-by-addr命令询问其他哨兵节点该主节点的状态；如果判断主节点下线的哨兵数量达到一定数值，则对该主节点进行客观下线。</p>
<p><strong>需要特别注意的是，客观下线是主节点才有的概念；如果从节点和哨兵节点发生故障，被哨兵主观下线后，不会再有后续的客观下线和故障转移操作。</strong></p>
<p>（4）选举领导者哨兵节点：当主节点被判断客观下线以后，各个哨兵节点会进行协商，选举出一个领导者哨兵节点，并由该领导者节点对其进行故障转移操作。</p>
<p>监视该主节点的所有哨兵都有可能被选为领导者，选举使用的算法是Raft算法；Raft算法的基本思路是先到先得：即在一轮选举中，哨兵A向B发送成为领导者的申请，如果B没有同意过其他哨兵，则会同意A成为领导者。选举的具体过程这里不做详细描述，一般来说，哨兵选择的过程很快，谁先完成客观下线，一般就能成为领导者。</p>
<p>（5）故障转移：选举出的领导者哨兵，开始进行故障转移操作，该操作大体可以分为3个步骤：</p>
<ul>
<li><p>在从节点中选择新的主节点：选择的原则是，首先过滤掉不健康的从节点；然后选择优先级最高的从节点(由slave-priority指定)；如果优先级无法区分，则选择复制偏移量最大的从节点；如果仍无法区分，则选择runid最小的从节点。</p>
</li>
<li><p>更新主从状态：通过slaveof no<br>one命令，让选出来的从节点成为主节点；并通过slaveof命令让其他节点成为其从节点。</p>
</li>
<li><p>将已经下线的主节点(即6379)设置为新的主节点的从节点，当6379重新上线后，它会成为新的主节点的从节点。</p>
</li>
</ul>
<p>通过上述几个关键概念，可以基本了解哨兵的工作原理。为了更形象的说明，下图展示了领导者哨兵节点的日志，包括从节点启动到完成故障转移。</p>
<p><img src="http://47.103.200.134/image/10c00e6014dc9ff147d3fb0ded3ebfb8.png" alt="https://images2018.cnblogs.com/blog/1174710/201809/1174710-20180909004056625-1501495024.png"></p>
<h1 id="五、配置与实践建议"><a href="#五、配置与实践建议" class="headerlink" title="五、配置与实践建议"></a>五、配置与实践建议</h1><ol>
<li>配置</li>
</ol>
<hr>
<p>下面介绍与哨兵相关的几个配置。</p>
<p>（1） sentinel monitor {masterName} {masterIp} {masterPort} {quorum}</p>
<p>sentinel<br>monitor是哨兵最核心的配置，在前文讲述部署哨兵节点时已说明，其中：masterName指定了主节点名称，masterIp和masterPort指定了主节点地址，quorum是判断主节点客观下线的哨兵数量阈值：当判定主节点下线的哨兵数量达到quorum时，对主节点进行客观下线。建议取值为哨兵数量的一半加1。</p>
<p>（2） sentinel down-after-milliseconds {masterName} {time}</p>
<p>sentinel<br>down-after-milliseconds与主观下线的判断有关：哨兵使用ping命令对其他节点进行心跳检测，如果其他节点超过down-after-milliseconds配置的时间没有回复，哨兵就会将其进行主观下线。该配置对主节点、从节点和哨兵节点的主观下线判定都有效。</p>
<p>down-after-milliseconds的默认值是30000，即30s；可以根据不同的网络环境和应用要求来调整：值越大，对主观下线的判定会越宽松，好处是误判的可能性小，坏处是故障发现和故障转移的时间变长，客户端等待的时间也会变长。例如，如果应用对可用性要求较高，则可以将值适当调小，当故障发生时尽快完成转移；如果网络环境相对较差，可以适当提高该阈值，避免频繁误判。</p>
<p>（3） sentinel parallel-syncs {masterName} {number}</p>
<p>sentinel<br>parallel-syncs与故障转移之后从节点的复制有关：它规定了每次向新的主节点发起复制操作的从节点个数。例如，假设主节点切换完成之后，有3个从节点要向新的主节点发起复制；如果parallel-syncs=1，则从节点会一个一个开始复制；如果parallel-syncs=3，则3个从节点会一起开始复制。</p>
<p>parallel-syncs取值越大，从节点完成复制的时间越快，但是对主节点的网络负载、硬盘负载造成的压力也越大；应根据实际情况设置。例如，如果主节点的负载较低，而从节点对服务可用的要求较高，可以适量增加parallel-syncs取值。parallel-syncs的默认值是1。</p>
<p>（4） sentinel failover-timeout {masterName} {time}</p>
<p>sentinel<br>failover-timeout与故障转移超时的判断有关，但是该参数不是用来判断整个故障转移阶段的超时，而是其几个子阶段的超时，例如如果主节点晋升从节点时间超过timeout，或从节点向新的主节点发起复制操作的时间(不包括复制数据的时间)超过timeout，都会导致故障转移超时失败。</p>
<p>failover-timeout的默认值是180000，即180s；如果超时，则下一次该值会变为原来的2倍。</p>
<p>（5）除上述几个参数外，还有一些其他参数，如安全验证相关的参数，这里不做介绍。</p>
<ol start="2">
<li>实践建议</li>
</ol>
<hr>
<p>（1）哨兵节点的数量应不止一个，一方面增加哨兵节点的冗余，避免哨兵本身成为高可用的瓶颈；另一方面减少对下线的误判。此外，这些不同的哨兵节点应部署在不同的物理机上。</p>
<p>（2）哨兵节点的数量应该是奇数，便于哨兵通过投票做出“决策”：领导者选举的决策、客观下线的决策等。</p>
<p>（3）各个哨兵节点的配置应一致，包括硬件、参数等；此外，所有节点都应该使用ntp或类似服务，保证时间准确、一致。</p>
<p>（4）哨兵的配置提供者和通知客户端功能，需要客户端的支持才能实现，如前文所说的Jedis；如果开发者使用的库未提供相应支持，则可能需要开发者自己实现。</p>
<p>（5）当哨兵系统中的节点在docker（或其他可能进行端口映射的软件）中部署时，应特别注意端口映射可能会导致哨兵系统无法正常工作，因为哨兵的工作基于与其他节点的通信，而docker的端口映射可能导致哨兵无法连接到其他节点。例如，哨兵之间互相发现，依赖于它们对外宣称的IP和port，如果某个哨兵A部署在做了端口映射的docker中，那么其他哨兵使用A宣称的port无法连接到A。</p>
<h1 id="六、总结"><a href="#六、总结" class="headerlink" title="六、总结"></a>六、总结</h1><p>本文首先介绍了哨兵的作用：监控、故障转移、配置提供者和通知；然后讲述了哨兵系统的部署方法，以及通过客户端访问哨兵系统的方法；再然后简要说明了哨兵实现的基本原理；最后给出了关于哨兵实践的一些建议。</p>
<p>在主从复制的基础上，哨兵引入了主节点的自动故障转移，进一步提高了Redis的高可用性；但是哨兵的缺陷同样很明显：哨兵无法对从节点进行自动故障转移，在读写分离场景下，从节点故障会导致读服务不可用，需要我们对从节点做额外的监控、切换操作。</p>
<p>此外，哨兵仍然没有解决写操作无法负载均衡、及存储能力受到单机限制的问题；这些问题的解决需要使用集群，我将在后面的文章中介绍，欢迎关注。</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://redis.io/topics/sentinel" target="_blank" rel="noopener">https://redis.io/topics/sentinel</a></p>
<p><a href="http://www.redis.cn/" target="_blank" rel="noopener">http://www.redis.cn/</a></p>
<p>《Redis开发与运维》</p>
<p>《Redis设计与实现》</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.zengmanhua.cn/2019/06/14/主从复制/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jin Yu Bao">
      <meta itemprop="description" content="生活源于奋斗">
      <meta itemprop="image" content="http://prl6c63q7.bkt.clouddn.com/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JinYuBao">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/06/14/主从复制/" class="post-title-link" itemprop="url">主从复制</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-06-14 15:58:03" itemprop="dateCreated datePublished" datetime="2019-06-14T15:58:03+08:00">2019-06-14</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/technology/" itemprop="url" rel="index"><span itemprop="name">技术</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2019/06/14/主从复制/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/06/14/主从复制/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在前面的两篇文章中，分别介绍了<a href>Redis的内存模型</a>和<a href>Redis的持久化</a>。</p>
<p>在Redis的持久化中曾提到，Redis高可用的方案包括持久化、主从复制（及读写分离）、哨兵和集群。其中持久化侧重解决的是Redis数据的单机备份问题（从内存到硬盘的备份）；而主从复制则侧重解决数据的多机热备。此外，主从复制还可以实现负载均衡和故障恢复。</p>
<p>这篇文章中，将详细介绍Redis主从复制的方方面面，包括：如何使用主从复制、主从复制的原理（重点是全量复制和部分复制、以及心跳机制）、实际应用中需要注意的问题（如数据不一致问题、复制超时问题、复制缓冲区溢出问题）、主从复制相关的配置（重点是repl-timeout、client-output-buffer-limit<br>slave）等。</p>
<h1 id="一、主从复制概述"><a href="#一、主从复制概述" class="headerlink" title="一、主从复制概述"></a>一、主从复制概述</h1><p>主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(master)，后者称为从节点(slave)；数据的复制是单向的，只能由主节点到从节点。</p>
<p>默认情况下，每台Redis服务器都是主节点；且一个主节点可以有多个从节点(或没有从节点)，但一个从节点只能有一个主节点。</p>
<p><strong>主从复制的作用</strong></p>
<p>主从复制的作用主要包括：</p>
<ol>
<li><p>数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。</p>
</li>
<li><p>故障恢复：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余。</p>
</li>
<li><p>负载均衡：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务（即写Redis数据时应用连接主节点，读Redis数据时应用连接从节点），分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。</p>
</li>
<li><p>高可用基石：除了上述作用以外，主从复制还是哨兵和集群能够实施的基础，因此说主从复制是Redis高可用的基础。</p>
</li>
</ol>
<h1 id="二、如何使用主从复制"><a href="#二、如何使用主从复制" class="headerlink" title="二、如何使用主从复制"></a>二、如何使用主从复制</h1><p>为了更直观的理解主从复制，在介绍其内部原理之前，先说明我们需要如何操作才能开启主从复制。</p>
<ol>
<li>建立复制</li>
</ol>
<hr>
<p>需要注意，<strong>主从复制的开启，完全是在从节点发起的；不需要我们在主节点做任何事情。</strong></p>
<p>从节点开启主从复制，有3种方式：</p>
<p>（1）配置文件</p>
<p>在从服务器的配置文件中加入：slaveof \&lt;masterip> \&lt;masterport></p>
<p>（2）启动命令</p>
<p>redis-server启动命令后加入 –slaveof \&lt;masterip> \&lt;masterport></p>
<p>（3）客户端命令</p>
<p>Redis服务器启动后，直接通过客户端执行命令：slaveof \&lt;masterip><br>\&lt;masterport>，则该Redis实例成为从节点。</p>
<p>上述3种方式是等效的，下面以客户端命令的方式为例，看一下当执行了slaveof后，Redis主节点和从节点的变化。</p>
<ol start="2">
<li>实例</li>
</ol>
<hr>
<h3 id="准备工作：启动两个节点"><a href="#准备工作：启动两个节点" class="headerlink" title="准备工作：启动两个节点"></a>准备工作：启动两个节点</h3><p>方便起见，实验所使用的主从节点是在一台机器上的不同Redis实例，其中主节点监听6379端口，从节点监听6380端口；从节点监听的端口号可以在配置文件中修改：</p>
<p><img src="http://47.103.200.134/image/2c05f98a146461d594863666f1133ec2.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180628011219164-269585034.png"></p>
<p>启动后可以看到：</p>
<p><img src="http://47.103.200.134/image/b9947b1ad6d0d0b3dd88ead81d9bdba5.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180628011229205-1259881734.png"></p>
<p>两个Redis节点启动后（分别称为6379节点和6380节点），默认都是主节点。</p>
<h3 id="建立复制"><a href="#建立复制" class="headerlink" title="建立复制"></a>建立复制</h3><p>此时在6380节点执行slaveof命令，使之变为从节点：</p>
<p><img src="http://47.103.200.134/image/cd3339d596e93a609f01d46f250d7421.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180628011236215-1776355426.png"></p>
<h3 id="观察效果"><a href="#观察效果" class="headerlink" title="观察效果"></a>观察效果</h3><p>下面验证一下，在主从复制建立后，主节点的数据会复制到从节点中。</p>
<p>（1）首先在从节点查询一个不存在的key：</p>
<p><img src="http://47.103.200.134/image/7524d9a829cd3920b524db4786cb3ea9.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180628011248863-775666084.png"></p>
<p>（2）然后在主节点中增加这个key：</p>
<p><img src="http://47.103.200.134/image/4ee18160c887d90249c3d1a8696150f3.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180628011255637-1820178900.png"></p>
<p>（3）此时在从节点中再次查询这个key，会发现主节点的操作已经同步至从节点：</p>
<p><img src="http://47.103.200.134/image/3c280a1e55398f9aa708e4edb1a532fa.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180628011302404-417931505.png"></p>
<p>（4）然后在主节点删除这个key：</p>
<p><img src="http://47.103.200.134/image/d82f5c16bf94a6a0fac00606a5424a63.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180628011309069-1397319420.png"></p>
<p>（5）此时在从节点中再次查询这个key，会发现主节点的操作已经同步至从节点：</p>
<p><img src="http://47.103.200.134/image/041ef7b0f176d841e4d8395d339c5de3.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180628011318424-343599365.png"></p>
<ol start="3">
<li>断开复制</li>
</ol>
<hr>
<p>通过slaveof \&lt;masterip> \&lt;masterport>命令建立主从复制关系以后，可以通过slaveof<br>no<br>one断开。需要注意的是，从节点断开复制后，不会删除已有的数据，只是不再接受主节点新的数据变化。</p>
<p>从节点执行slaveof no<br>one后，打印日志如下所示；可以看出断开复制后，从节点又变回为主节点。</p>
<p><img src="http://47.103.200.134/image/60f9580836cce679cb489a34da8a4c7b.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180628011330683-644091604.png"></p>
<p>主节点打印日志如下：</p>
<p><img src="http://47.103.200.134/image/828a423dbf5aabeee7cf3772ee9363c1.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180628011337649-815413808.png"></p>
<h1 id="三、主从复制的实现原理"><a href="#三、主从复制的实现原理" class="headerlink" title="三、主从复制的实现原理"></a>三、主从复制的实现原理</h1><p>上面一节中，介绍了如何操作可以建立主从关系；本小节将介绍主从复制的实现原理。</p>
<p>主从复制过程大体可以分为3个阶段：连接建立阶段（即准备阶段）、数据同步阶段、命令传播阶段；下面分别进行介绍。</p>
<ol>
<li>连接建立阶段</li>
</ol>
<hr>
<p>该阶段的主要作用是在主从节点之间建立连接，为数据同步做好准备。</p>
<h3 id="步骤1：保存主节点信息"><a href="#步骤1：保存主节点信息" class="headerlink" title="步骤1：保存主节点信息"></a>步骤1：保存主节点信息</h3><p>从节点服务器内部维护了两个字段，即masterhost和masterport字段，用于存储主节点的ip和port信息。</p>
<p>需要注意的是，<strong>slaveof是异步命令，从节点完成主节点ip和port的保存后，向发送slaveof命令的客户端直接返回OK，实际的复制操作在这之后才开始进行。</strong></p>
<p>这个过程中，可以看到从节点打印日志如下：</p>
<p><img src="http://47.103.200.134/image/46c084ef032801eef10658ddfe878c94.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180628011353199-43354413.png"></p>
<h3 id="步骤2：建立socket连接"><a href="#步骤2：建立socket连接" class="headerlink" title="步骤2：建立socket连接"></a>步骤2：建立socket连接</h3><p>从节点每秒1次调用复制定时函数replicationCron()，如果发现了有主节点可以连接，便会根据主节点的ip和port，创建socket连接。如果连接成功，则：</p>
<p>从节点：为该socket建立一个专门处理复制工作的文件事件处理器，负责后续的复制工作，如接收RDB文件、接收命令传播等。</p>
<p>主节点：接收到从节点的socket连接后（即accept之后），为该socket创建相应的客户端状态，<strong>并将从节点看做是连接到主节点的一个客户端，后面的步骤会以从节点向主节点发送命令请求的形式来进行。</strong></p>
<p>这个过程中，从节点打印日志如下：</p>
<p><img src="http://47.103.200.134/image/f81ae8cf1351c158802ec1b63085e97b.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180628011400533-833761023.png"></p>
<h3 id="步骤3：发送ping命令"><a href="#步骤3：发送ping命令" class="headerlink" title="步骤3：发送ping命令"></a>步骤3：发送ping命令</h3><p>从节点成为主节点的客户端之后，发送ping命令进行首次请求，目的是：检查socket连接是否可用，以及主节点当前是否能够处理请求。</p>
<p>从节点发送ping命令后，可能出现3种情况：</p>
<p>（1）返回pong：说明socket连接正常，且主节点当前可以处理请求，复制过程继续。</p>
<p>（2）超时：一定时间后从节点仍未收到主节点的回复，说明socket连接不可用，则从节点断开socket连接，并重连。</p>
<p>（3）返回pong以外的结果：如果主节点返回其他结果，如正在处理超时运行的脚本，说明主节点当前无法处理命令，则从节点断开socket连接，并重连。</p>
<p>在主节点返回pong情况下，从节点打印日志如下：</p>
<p><img src="http://47.103.200.134/image/c843d3c139a3d9de4d6015a2740981b9.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180628011408822-1702643515.png"></p>
<h3 id="步骤4：身份验证"><a href="#步骤4：身份验证" class="headerlink" title="步骤4：身份验证"></a>步骤4：身份验证</h3><p>如果从节点中设置了masterauth选项，则从节点需要向主节点进行身份验证；没有设置该选项，则不需要验证。从节点进行身份验证是通过向主节点发送auth命令进行的，auth命令的参数即为配置文件中的masterauth的值。</p>
<p>如果主节点设置密码的状态，与从节点masterauth的状态一致（一致是指都存在，且密码相同，或者都不存在），则身份验证通过，复制过程继续；如果不一致，则从节点断开socket连接，并重连。</p>
<h3 id="步骤5：发送从节点端口信息"><a href="#步骤5：发送从节点端口信息" class="headerlink" title="步骤5：发送从节点端口信息"></a>步骤5：发送从节点端口信息</h3><p>身份验证之后，从节点会向主节点发送其监听的端口号（前述例子中为6380），主节点将该信息保存到该从节点对应的客户端的slave_listening_port字段中；该端口信息除了在主节点中执行info<br>Replication时显示以外，没有其他作用。</p>
<ol start="2">
<li>数据同步阶段</li>
</ol>
<hr>
<p>主从节点之间的连接建立以后，便可以开始进行数据同步，该阶段可以理解为从节点数据的初始化。具体执行的方式是：从节点向主节点发送psync命令（Redis2.8以前是sync命令），开始同步。</p>
<p>数据同步阶段是主从复制最核心的阶段，根据主从节点当前状态的不同，可以分为全量复制和部分复制，下面会有一章专门讲解这两种复制方式以及psync命令的执行过程，这里不再详述。</p>
<p>需要注意的是，在数据同步阶段之前，从节点是主节点的客户端，主节点不是从节点的客户端；而到了这一阶段及以后，主从节点互为客户端。原因在于：在此之前，主节点只需要响应从节点的请求即可，不需要主动发请求，而在数据同步阶段和后面的命令传播阶段，主节点需要主动向从节点发送请求（如推送缓冲区中的写命令），才能完成复制。</p>
<ol start="3">
<li>命令传播阶段</li>
</ol>
<hr>
<p>数据同步阶段完成后，主从节点进入命令传播阶段；在这个阶段主节点将自己执行的写命令发送给从节点，从节点接收命令并执行，从而保证主从节点数据的一致性。</p>
<p>在命令传播阶段，除了发送写命令，主从节点还维持着心跳机制：PING和REPLCONF<br>ACK。由于心跳机制的原理涉及部分复制，因此将在介绍了部分复制的相关内容后单独介绍该心跳机制。</p>
<p><strong>延迟与不一致</strong></p>
<p>需要注意的是，命令传播是异步的过程，即主节点发送写命令后并不会等待从节点的回复；因此实际上主从节点之间很难保持实时的一致性，延迟在所难免。数据不一致的程度，与主从节点之间的网络状况、主节点写命令的执行频率、以及主节点中的repl-disable-tcp-nodelay配置等有关。</p>
<p>repl-disable-tcp-nodelay<br>no：该配置作用于命令传播阶段，控制主节点是否禁止与从节点的TCP_NODELAY；默认no，即不禁止TCP_NODELAY。当设置为yes时，TCP会对包进行合并从而减少带宽，但是发送的频率会降低，从节点数据延迟增加，一致性变差；具体发送频率与Linux内核的配置有关，默认配置为40ms。当设置为no时，TCP会立马将主节点的数据发送给从节点，带宽增加但延迟变小。</p>
<p>一般来说，只有当应用对Redis数据不一致的容忍度较高，且主从节点之间网络状况不好时，才会设置为yes；多数情况使用默认值no。</p>
<h1 id="四、【数据同步阶段】全量复制和部分复制"><a href="#四、【数据同步阶段】全量复制和部分复制" class="headerlink" title="四、【数据同步阶段】全量复制和部分复制"></a>四、【数据同步阶段】全量复制和部分复制</h1><p>在Redis2.8以前，从节点向主节点发送sync命令请求同步数据，此时的同步方式是全量复制；在Redis2.8及以后，从节点可以发送psync命令请求同步数据，此时根据主从节点当前状态的不同，同步方式可能是全量复制或部分复制。后文介绍以Redis2.8及以后版本为例。</p>
<ol>
<li><p>全量复制：用于初次复制或其他无法进行部分复制的情况，将主节点中的所有数据都发送给从节点，是一个非常重型的操作。</p>
</li>
<li><p>部分复制：用于网络中断等情况后的复制，只将中断期间主节点执行的写命令发送给从节点，与全量复制相比更加高效。需要注意的是，如果网络中断时间过长，导致主节点没有能够完整地保存中断期间执行的写命令，则无法进行部分复制，仍使用全量复制。</p>
</li>
<li><p>全量复制</p>
</li>
</ol>
<hr>
<p>Redis通过psync命令进行全量复制的过程如下：</p>
<p>（1）从节点判断无法进行部分复制，向主节点发送全量复制的请求；或从节点发送部分复制的请求，但主节点判断无法进行全量复制；具体判断过程需要在讲述了部分复制原理后再介绍。</p>
<p>（2）主节点收到全量复制的命令后，执行bgsave，在后台生成RDB文件，并使用一个缓冲区（称为复制缓冲区）记录从现在开始执行的所有写命令</p>
<p>（3）主节点的bgsave执行完成后，将RDB文件发送给从节点；<strong>从节点首先清除自己的旧数据，然后载入接收的RDB文件</strong>，将数据库状态更新至主节点执行bgsave时的数据库状态</p>
<p>（4）主节点将前述复制缓冲区中的所有写命令发送给从节点，从节点执行这些写命令，将数据库状态更新至主节点的最新状态</p>
<p>（5）如果从节点开启了AOF，则会触发bgrewriteaof的执行，从而保证AOF文件更新至主节点的最新状态</p>
<p>下面是执行全量复制时，主从节点打印的日志；可以看出日志内容与上述步骤是完全对应的。</p>
<p>主节点的打印日志如下：</p>
<p><img src="http://47.103.200.134/image/981f2540784071d7f2f83eff04bf0f0c.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180628011456793-1960688528.png"></p>
<p>从节点打印日志如下图所示：</p>
<p><img src="http://47.103.200.134/image/1889714528c9234d5980310ea4b61d8a.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180628011502796-1951938935.png"></p>
<p>其中，有几点需要注意：从节点接收了来自主节点的89260个字节的数据；从节点在载入主节点的数据之前要先将老数据清除；从节点在同步完数据后，调用了bgrewriteaof。</p>
<p>通过全量复制的过程可以看出，全量复制是非常重型的操作：</p>
<p>（1）主节点通过bgsave命令fork子进程进行RDB持久化，该过程是非常消耗CPU、内存(页表复制)、硬盘IO的；关于bgsave的性能问题，可以参考 <a href="https://www.cnblogs.com/kismetv/p/9137897.html" target="_blank" rel="noopener">深入学习Redis（2）：持久化</a></p>
<p>（2）主节点通过网络将RDB文件发送给从节点，对主从节点的带宽都会带来很大的消耗</p>
<p>（3）从节点清空老数据、载入新RDB文件的过程是阻塞的，无法响应客户端的命令；如果从节点执行bgrewriteaof，也会带来额外的消耗</p>
<ol start="2">
<li>部分复制</li>
</ol>
<hr>
<p>由于全量复制在主节点数据量较大时效率太低，因此Redis2.8开始提供部分复制，用于处理网络中断时的数据同步。</p>
<p>部分复制的实现，依赖于三个重要的概念：</p>
<h3 id="（1）复制偏移量"><a href="#（1）复制偏移量" class="headerlink" title="（1）复制偏移量"></a>（1）复制偏移量</h3><p>主节点和从节点分别维护一个复制偏移量（offset），代表的是<strong>主节点向从节点传递的字节数</strong>；主节点每次向从节点传播N个字节数据时，主节点的offset增加N；从节点每次收到主节点传来的N个字节数据时，从节点的offset增加N。</p>
<p>offset用于判断主从节点的数据库状态是否一致：如果二者offset相同，则一致；如果offset不同，则不一致，此时可以根据两个offset找出从节点缺少的那部分数据。例如，如果主节点的offset是1000，而从节点的offset是500，那么部分复制就需要将offset为501-1000的数据传递给从节点。而offset为501-1000的数据存储的位置，就是下面要介绍的复制积压缓冲区。</p>
<h3 id="（2）复制积压缓冲区"><a href="#（2）复制积压缓冲区" class="headerlink" title="（2）复制积压缓冲区"></a>（2）复制积压缓冲区</h3><p>复制积压缓冲区是由主节点维护的、固定长度的、先进先出(FIFO)队列，默认大小1MB；当主节点开始有从节点时创建，其作用是备份主节点最近发送给从节点的数据。注意，无论主节点有一个还是多个从节点，都只需要一个复制积压缓冲区。</p>
<p>在命令传播阶段，主节点除了将写命令发送给从节点，还会发送一份给复制积压缓冲区，作为写命令的备份；除了存储写命令，复制积压缓冲区中还存储了其中的每个字节对应的复制偏移量（offset）。由于复制积压缓冲区定长且是先进先出，所以它保存的是主节点最近执行的写命令；时间较早的写命令会被挤出缓冲区。</p>
<p>由于该缓冲区长度固定且有限，因此可以备份的写命令也有限，当主从节点offset的差距过大超过缓冲区长度时，将无法执行部分复制，只能执行全量复制。反过来说，为了提高网络中断时部分复制执行的概率，可以根据需要增大复制积压缓冲区的大小(通过配置repl-backlog-size)；例如如果网络中断的平均时间是60s，而主节点平均每秒产生的写命令(特定协议格式)所占的字节数为100KB，则复制积压缓冲区的平均需求为6MB，保险起见，可以设置为12MB，来保证绝大多数断线情况都可以使用部分复制。</p>
<p>从节点将offset发送给主节点后，主节点根据offset和缓冲区大小决定能否执行部分复制：</p>
<ul>
<li><p>如果offset偏移量之后的数据，仍然都在复制积压缓冲区里，则执行部分复制；</p>
</li>
<li><p>如果offset偏移量之后的数据已不在复制积压缓冲区中（数据已被挤出），则执行全量复制。</p>
</li>
</ul>
<h3 id="（3）服务器运行ID-runid"><a href="#（3）服务器运行ID-runid" class="headerlink" title="（3）服务器运行ID(runid)"></a>（3）服务器运行ID(runid)</h3><p>每个Redis节点(无论主从)，在启动时都会自动生成一个随机ID(每次启动都不一样)，由40个随机的十六进制字符组成；runid用来唯一识别一个Redis节点。通过info<br>Server命令，可以查看节点的runid：</p>
<p><img src="http://47.103.200.134/image/f4d3b2789a1cfe556a181d80c6c678aa.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180628011537662-712436367.png"></p>
<p>主从节点初次复制时，主节点将自己的runid发送给从节点，从节点将这个runid保存起来；当断线重连时，从节点会将这个runid发送给主节点；主节点根据runid判断能否进行部分复制：</p>
<ul>
<li><p>如果从节点保存的runid与主节点现在的runid相同，说明主从节点之前同步过，主节点会继续尝试使用部分复制(到底能不能部分复制还要看offset和复制积压缓冲区的情况)；</p>
</li>
<li><p>如果从节点保存的runid与主节点现在的runid不同，说明从节点在断线前同步的Redis节点并不是当前的主节点，只能进行全量复制。</p>
</li>
</ul>
<ol start="3">
<li>psync命令的执行</li>
</ol>
<hr>
<p>在了解了复制偏移量、复制积压缓冲区、节点运行id之后，本节将介绍psync命令的参数和返回值，从而说明psync命令执行过程中，主从节点是如何确定使用全量复制还是部分复制的。</p>
<p>psync命令的执行过程可以参见下图（图片来源：《Redis设计与实现》）：</p>
<p><img src="http://47.103.200.134/image/cbc4a1eff6e97174311e5fdbf68a5f61.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180628011547892-692403928.png"></p>
<p>（1）首先，从节点根据当前状态，决定如何调用psync命令：</p>
<ul>
<li><p>如果从节点之前未执行过slaveof或最近执行了slaveof no<br>one，则从节点发送命令为psync ? -1，向主节点请求全量复制；</p>
</li>
<li><p>如果从节点之前执行了slaveof，则发送命令为psync \&lt;runid><br>\&lt;offset>，其中runid为上次复制的主节点的runid，offset为上次复制截止时从节点保存的复制偏移量。</p>
</li>
</ul>
<p>（2）主节点根据收到的psync命令，及当前服务器状态，决定执行全量复制还是部分复制：</p>
<ul>
<li><p>如果主节点版本低于Redis2.8，则返回-ERR回复，此时从节点重新发送sync命令执行全量复制；</p>
</li>
<li><p>如果主节点版本够新，且runid与从节点发送的runid相同，且从节点发送的offset之后的数据在复制积压缓冲区中都存在，则回复+CONTINUE，表示将进行部分复制，从节点等待主节点发送其缺少的数据即可；</p>
</li>
<li><p>如果主节点版本够新，但是runid与从节点发送的runid不同，或从节点发送的offset之后的数据已不在复制积压缓冲区中(在队列中被挤出了)，则回复+FULLRESYNC<br>\&lt;runid><br>\&lt;offset>，表示要进行全量复制，其中runid表示主节点当前的runid，offset表示主节点当前的offset，从节点保存这两个值，以备使用。</p>
</li>
</ul>
<ol start="4">
<li>部分复制演示</li>
</ol>
<hr>
<p>在下面的演示中，网络中断几分钟后恢复，断开连接的主从节点进行了部分复制；为了便于模拟网络中断，本例中的主从节点在局域网中的两台机器上。</p>
<p><strong>网络中断</strong></p>
<p>网络中断一段时间后，主节点和从节点都会发现失去了与对方的连接（关于主从节点对超时的判断机制，后面会有说明）；此后，从节点便开始执行对主节点的重连，由于此时网络还没有恢复，重连失败，从节点会一直尝试重连。</p>
<p>主节点日志如下：</p>
<p><img src="http://47.103.200.134/image/d7e61f5aa308f07bd4d25c43a72d600e.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180628011609348-1802555230.png"></p>
<p>从节点日志如下：</p>
<p><img src="http://47.103.200.134/image/ba767310fa9557b115b7b14f7041200e.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180628011615849-621207089.png"></p>
<p><strong>网络恢复</strong></p>
<p>网络恢复后，从节点连接主节点成功，并请求进行部分复制，主节点接收请求后，二者进行部分复制以同步数据。</p>
<p>主节点日志如下：</p>
<p><img src="http://47.103.200.134/image/1ab29460647080969e2ae4d8bf051420.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180628011623772-1032753515.png"></p>
<p>从节点日志如下：</p>
<p><img src="http://47.103.200.134/image/3c0e83e368025e7e877293b1eeb09127.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180628011630326-1569443208.png"></p>
<h1 id="五、【命令传播阶段】心跳机制"><a href="#五、【命令传播阶段】心跳机制" class="headerlink" title="五、【命令传播阶段】心跳机制"></a>五、【命令传播阶段】心跳机制</h1><p>在命令传播阶段，除了发送写命令，主从节点还维持着心跳机制：PING和REPLCONF<br>ACK。心跳机制对于主从复制的超时判断、数据安全等有作用。</p>
<h2 id="1-主-从：PING"><a href="#1-主-从：PING" class="headerlink" title="1.主->从：PING"></a>1.主->从：PING</h2><p>每隔指定的时间，<strong>主节点会向从节点发送PING命令</strong>，这个PING命令的作用，主要是为了让从节点进行超时判断。</p>
<p>PING发送的频率由repl-ping-slave-period参数控制，单位是秒，默认值是10s。</p>
<p>关于该PING命令究竟是由主节点发给从节点，还是相反，有一些争议；因为在Redis的官方文档中，对该参数的注释中说明是从节点向主节点发送PING命令，如下图所示：</p>
<p><img src="http://47.103.200.134/image/144c82d0ad322f5392dccfd63bd6f5c3.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180628011653835-25800141.png"></p>
<p>但是根据该参数的名称(含有ping-slave)，以及代码实现，我认为该PING命令是主节点发给从节点的。相关代码如下：</p>
<p><img src="http://47.103.200.134/image/2b77a14e5ef8395c7ae89b30d5b85bff.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180628011700171-401488218.png"></p>
<ol start="2">
<li>从->主：REPLCONF ACK</li>
</ol>
<hr>
<p>在命令传播阶段，<strong>从节点会向主节点发送REPLCONF<br>ACK命令，</strong>频率是每秒1次；命令格式为：REPLCONF ACK<br>{offset}，其中offset指从节点保存的复制偏移量。REPLCONF ACK命令的作用包括：</p>
<p>（1）实时监测主从节点网络状态：该命令会被主节点用于复制超时的判断。此外，在主节点中使用info<br>Replication，可以看到其从节点的状态中的lag值，代表的是主节点上次收到该REPLCONF<br>ACK命令的时间间隔，在正常情况下，该值应该是0或1，如下图所示：</p>
<p><img src="http://47.103.200.134/image/257253d39d9ec72184b1f5fb48802240.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180628011708219-1385546367.png"></p>
<p>（2）检测命令丢失：从节点发送了自身的offset，主节点会与自己的offset对比，如果从节点数据缺失（如网络丢包），主节点会推送缺失的数据（这里也会利用复制积压缓冲区）。<strong>注意，offset和复制积压缓冲区，不仅可以用于部分复制，也可以用于处理命令丢失等情形；区别在于前者是在断线重连后进行的，而后者是在主从节点没有断线的情况下进行的。</strong></p>
<p>（3）辅助保证从节点的数量和延迟：Redis主节点中使用min-slaves-to-write和min-slaves-max-lag参数，来保证主节点在不安全的情况下不会执行写命令；所谓不安全，是指从节点数量太少，或延迟过高。例如min-slaves-to-write和min-slaves-max-lag分别是3和10，含义是如果从节点数量小于3个，或所有从节点的延迟值都大于10s，则主节点拒绝执行写命令。而这里从节点延迟值的获取，就是通过主节点接收到REPLCONF<br>ACK命令的时间来判断的，即前面所说的info Replication中的lag值。</p>
<h1 id="六、应用中的问题"><a href="#六、应用中的问题" class="headerlink" title="六、应用中的问题"></a>六、应用中的问题</h1><ol>
<li>读写分离及其中的问题</li>
</ol>
<hr>
<p>在主从复制基础上实现的读写分离，可以实现Redis的读负载均衡：由主节点提供写服务，由一个或多个从节点提供读服务（多个从节点既可以提高数据冗余程度，也可以最大化读负载能力）；在读负载较大的应用场景下，可以大大提高Redis服务器的并发量。下面介绍在使用Redis读写分离时，需要注意的问题。</p>
<h3 id="（1）延迟与不一致问题"><a href="#（1）延迟与不一致问题" class="headerlink" title="（1）延迟与不一致问题"></a>（1）延迟与不一致问题</h3><p>前面已经讲到，由于主从复制的命令传播是异步的，延迟与数据的不一致不可避免。如果应用对数据不一致的接受程度程度较低，可能的优化措施包括：优化主从节点之间的网络环境（如在同机房部署）；监控主从节点延迟（通过offset）判断，如果从节点延迟过大，通知应用不再通过该从节点读取数据；使用集群同时扩展写负载和读负载等。</p>
<p>在命令传播阶段以外的其他情况下，从节点的数据不一致可能更加严重，例如连接在数据同步阶段，或从节点失去与主节点的连接时等。从节点的slave-serve-stale-data参数便与此有关：它控制这种情况下从节点的表现；如果为yes（默认值），则从节点仍能够响应客户端的命令，如果为no，则从节点只能响应info、slaveof等少数命令。该参数的设置与应用对数据一致性的要求有关；如果对数据一致性要求很高，则应设置为no。</p>
<h3 id="（2）数据过期问题"><a href="#（2）数据过期问题" class="headerlink" title="（2）数据过期问题"></a>（2）数据过期问题</h3><p>在单机版Redis中，存在两种删除策略：</p>
<ul>
<li><p>惰性删除：服务器不会主动删除数据，只有当客户端查询某个数据时，服务器判断该数据是否过期，如果过期则删除。</p>
</li>
<li><p>定期删除：服务器执行定时任务删除过期数据，但是考虑到内存和CPU的折中（删除会释放内存，但是频繁的删除操作对CPU不友好），该删除的频率和执行时间都受到了限制。</p>
</li>
</ul>
<p>在主从复制场景下，为了主从节点的数据一致性，从节点不会主动删除数据，而是由主节点控制从节点中过期数据的删除。由于主节点的惰性删除和定期删除策略，都不能保证主节点及时对过期数据执行删除操作，因此，当客户端通过Redis从节点读取数据时，很容易读取到已经过期的数据。</p>
<p>Redis<br>3.2中，从节点在读取数据时，增加了对数据是否过期的判断：如果该数据已过期，则不返回给客户端；将Redis升级到3.2可以解决数据过期问题。</p>
<h3 id="（3）故障切换问题"><a href="#（3）故障切换问题" class="headerlink" title="（3）故障切换问题"></a>（3）故障切换问题</h3><p>在没有使用哨兵的读写分离场景下，应用针对读和写分别连接不同的Redis节点；当主节点或从节点出现问题而发生更改时，需要及时修改应用程序读写Redis数据的连接；连接的切换可以手动进行，或者自己写监控程序进行切换，但前者响应慢、容易出错，后者实现复杂，成本都不算低。</p>
<h3 id="（4）总结"><a href="#（4）总结" class="headerlink" title="（4）总结"></a>（4）总结</h3><p>在使用读写分离之前，可以考虑其他方法增加Redis的读负载能力：如尽量优化主节点（减少慢查询、减少持久化等其他情况带来的阻塞等）提高负载能力；使用Redis集群同时提高读负载能力和写负载能力等。如果使用读写分离，可以使用哨兵，使主从节点的故障切换尽可能自动化，并减少对应用程序的侵入。</p>
<ol start="2">
<li>复制超时问题</li>
</ol>
<hr>
<p>主从节点复制超时是导致复制中断的最重要的原因之一，本小节单独说明超时问题，下一小节说明其他会导致复制中断的问题。</p>
<p><strong>超时判断意义</strong></p>
<p>在复制连接建立过程中及之后，主从节点都有机制判断连接是否超时，其意义在于：</p>
<p>（1）如果主节点判断连接超时，其会释放相应从节点的连接，从而释放各种资源，否则无效的从节点仍会占用主节点的各种资源（输出缓冲区、带宽、连接等）；此外连接超时的判断可以让主节点更准确的知道当前有效从节点的个数，有助于保证数据安全（配合前面讲到的min-slaves-to-write等参数）。</p>
<p>（2）如果从节点判断连接超时，则可以及时重新建立连接，避免与主节点数据长期的不一致。</p>
<p><strong>判断机制</strong></p>
<p>主从复制超时判断的核心，在于repl-timeout参数，该参数规定了超时时间的阈值（默认60s），对于主节点和从节点同时有效；主从节点触发超时的条件分别如下：</p>
<p>（1）主节点：每秒1次调用复制定时函数replicationCron()，在其中判断当前时间距离上次收到各个从节点REPLCONF<br>ACK的时间，是否超过了repl-timeout值，如果超过了则释放相应从节点的连接。</p>
<p>（2）从节点：从节点对超时的判断同样是在复制定时函数中判断，基本逻辑是：</p>
<ul>
<li><p>如果当前处于连接建立阶段，且距离上次收到主节点的信息的时间已超过repl-timeout，则释放与主节点的连接；</p>
</li>
<li><p>如果当前处于数据同步阶段，且收到主节点的RDB文件的时间超时，则停止数据同步，释放连接；</p>
</li>
<li><p>如果当前处于命令传播阶段，且距离上次收到主节点的PING命令或数据的时间已超过repl-timeout值，则释放与主节点的连接。</p>
</li>
</ul>
<p>主从节点判断连接超时的相关源代码如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">/* Replication cron function, called 1 time per second. */</span><br><span class="line">void replicationCron(void) &#123;</span><br><span class="line">    static long long replication_cron_loops = 0;</span><br><span class="line"> </span><br><span class="line">    /* Non blocking connection timeout? */</span><br><span class="line">    if (server.masterhost &amp;&amp;</span><br><span class="line">        (server.repl_state == REDIS_REPL_CONNECTING ||</span><br><span class="line">         slaveIsInHandshakeState()) &amp;&amp;</span><br><span class="line">         (time(NULL)-server.repl_transfer_lastio) &gt; server.repl_timeout)</span><br><span class="line">    &#123;</span><br><span class="line">        redisLog(REDIS_WARNING,&quot;Timeout connecting to the MASTER...&quot;);</span><br><span class="line">        undoConnectWithMaster();</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    /* Bulk transfer I/O timeout? */</span><br><span class="line">    if (server.masterhost &amp;&amp; server.repl_state == REDIS_REPL_TRANSFER &amp;&amp;</span><br><span class="line">        (time(NULL)-server.repl_transfer_lastio) &gt; server.repl_timeout)</span><br><span class="line">    &#123;</span><br><span class="line">        redisLog(REDIS_WARNING,&quot;Timeout receiving bulk data from MASTER... If the problem persists try to set the &apos;repl-timeout&apos; parameter in redis.conf to a larger value.&quot;);</span><br><span class="line">        replicationAbortSyncTransfer();</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    /* Timed out master when we are an already connected slave? */</span><br><span class="line">    if (server.masterhost &amp;&amp; server.repl_state == REDIS_REPL_CONNECTED &amp;&amp;</span><br><span class="line">        (time(NULL)-server.master-&gt;lastinteraction) &gt; server.repl_timeout)</span><br><span class="line">    &#123;</span><br><span class="line">        redisLog(REDIS_WARNING,&quot;MASTER timeout: no data nor PING received...&quot;);</span><br><span class="line">        freeClient(server.master);</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    //此处省略无关代码……</span><br><span class="line"> </span><br><span class="line">    /* Disconnect timedout slaves. */</span><br><span class="line">    if (listLength(server.slaves)) &#123;</span><br><span class="line">        listIter li;</span><br><span class="line">        listNode *ln;</span><br><span class="line">        listRewind(server.slaves,&amp;li);</span><br><span class="line">        while((ln = listNext(&amp;li))) &#123;</span><br><span class="line">            redisClient *slave = ln-&gt;value;</span><br><span class="line">            if (slave-&gt;replstate != REDIS_REPL_ONLINE) continue;</span><br><span class="line">            if (slave-&gt;flags &amp; REDIS_PRE_PSYNC) continue;</span><br><span class="line">            if ((server.unixtime - slave-&gt;repl_ack_time) &gt; server.repl_timeout)</span><br><span class="line">            &#123;</span><br><span class="line">                redisLog(REDIS_WARNING, &quot;Disconnecting timedout slave: %s&quot;,</span><br><span class="line">                    replicationGetSlaveName(slave));</span><br><span class="line">                freeClient(slave);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    //此处省略无关代码……</span><br><span class="line"> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><strong>需要注意的坑</strong></p>
<p>下面介绍与复制阶段连接超时有关的一些实际问题：</p>
<p>（1）数据同步阶段：在主从节点进行全量复制bgsave时，主节点需要首先fork子进程将当前数据保存到RDB文件中，然后再将RDB文件通过网络传输到从节点。如果RDB文件过大，主节点在fork子进程+保存RDB文件时耗时过多，可能会导致从节点长时间收不到数据而触发超时；此时从节点会重连主节点，然后再次全量复制，再次超时，再次重连……这是个悲伤的循环。为了避免这种情况的发生，除了注意Redis单机数据量不要过大，另一方面就是适当增大repl-timeout值，具体的大小可以根据bgsave耗时来调整。</p>
<p>（2）命令传播阶段：如前所述，在该阶段主节点会向从节点发送PING命令，频率由repl-ping-slave-period控制；该参数应明显小于repl-timeout值(后者至少是前者的几倍)。否则，如果两个参数相等或接近，网络抖动导致个别PING命令丢失，此时恰巧主节点也没有向从节点发送数据，则从节点很容易判断超时。</p>
<p>（3）慢查询导致的阻塞：如果主节点或从节点执行了一些慢查询（如keys<br>*或者对大数据的hgetall等），导致服务器阻塞；阻塞期间无法响应复制连接中对方节点的请求，可能导致复制超时。</p>
<ol start="3">
<li>复制中断问题</li>
</ol>
<hr>
<p>主从节点超时是复制中断的原因之一，除此之外，还有其他情况可能导致复制中断，其中最主要的是复制缓冲区溢出问题。</p>
<h3 id="复制缓冲区溢出"><a href="#复制缓冲区溢出" class="headerlink" title="复制缓冲区溢出"></a>复制缓冲区溢出</h3><p>前面曾提到过，在全量复制阶段，主节点会将执行的写命令放到复制缓冲区中，该缓冲区存放的数据包括了以下几个时间段内主节点执行的写命令：bgsave生成RDB文件、RDB文件由主节点发往从节点、从节点清空老数据并载入RDB文件中的数据。当主节点数据量较大，或者主从节点之间网络延迟较大时，可能导致该缓冲区的大小超过了限制，此时主节点会断开与从节点之间的连接；这种情况可能引起全量复制->复制缓冲区溢出导致连接中断->重连->全量复制->复制缓冲区溢出导致连接中断……的循环。</p>
<p>复制缓冲区的大小由client-output-buffer-limit slave {hard limit} {soft limit}<br>{soft seconds}配置，默认值为client-output-buffer-limit slave 256MB 64MB<br>60，其含义是：如果buffer大于256MB，或者连续60s大于64MB，则主节点会断开与该从节点的连接。该参数是可以通过config<br>set命令动态配置的（即不重启Redis也可以生效）。</p>
<p>当复制缓冲区溢出时，主节点打印日志如下所示：</p>
<p><img src="http://47.103.200.134/image/0b186317fb62c3b516bb97cfaebbde7c.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180628012000540-1190099498.png"></p>
<p><strong>需要注意的是，复制缓冲区是客户端输出缓冲区的一种，主节点会为每一个从节点分别分配复制缓冲区；而复制积压缓冲区则是一个主节点只有一个，无论它有多少个从节点。</strong></p>
<ol start="4">
<li>各场景下复制的选择及优化技巧</li>
</ol>
<hr>
<p>在介绍了Redis复制的种种细节之后，现在我们可以来总结一下，在下面常见的场景中，何时使用部分复制，以及需要注意哪些问题。</p>
<h3 id="（1）第一次建立复制"><a href="#（1）第一次建立复制" class="headerlink" title="（1）第一次建立复制"></a>（1）第一次建立复制</h3><p>此时全量复制不可避免，但仍有几点需要注意：如果主节点的数据量较大，应该尽量避开流量的高峰期，避免造成阻塞；如果有多个从节点需要建立对主节点的复制，可以考虑将几个从节点错开，避免主节点带宽占用过大。此外，如果从节点过多，也可以调整主从复制的拓扑结构，由一主多从结构变为树状结构（中间的节点既是其主节点的从节点，也是其从节点的主节点）；但使用树状结构应该谨慎：虽然主节点的直接从节点减少，降低了主节点的负担，但是多层从节点的延迟增大，数据一致性变差；且结构复杂，维护相当困难。</p>
<h3 id="（2）主节点重启"><a href="#（2）主节点重启" class="headerlink" title="（2）主节点重启"></a>（2）主节点重启</h3><p>主节点重启可以分为两种情况来讨论，一种是故障导致宕机，另一种则是有计划的重启。</p>
<p><strong>主节点宕机</strong></p>
<p>主节点宕机重启后，runid会发生变化，因此不能进行部分复制，只能全量复制。</p>
<p>实际上在主节点宕机的情况下，应进行故障转移处理，将其中的一个从节点升级为主节点，其他从节点从新的主节点进行复制；且故障转移应尽量的自动化，后面文章将要介绍的哨兵便可以进行自动的故障转移。</p>
<p><strong>安全重启：debug reload</strong></p>
<p>在一些场景下，可能希望对主节点进行重启，例如主节点内存碎片率过高，或者希望调整一些只能在启动时调整的参数。如果使用普通的手段重启主节点，会使得runid发生变化，可能导致不必要的全量复制。</p>
<p>为了解决这个问题，Redis提供了debug<br>reload的重启方式：<strong>重启后，主节点的runid和offset都不受影响，</strong>避免了全量复制。</p>
<p>如下图所示，debug reload重启后runid和offset都未受影响：</p>
<p><img src="http://47.103.200.134/image/2700e362f3cc65596f8f05bfb86dc34d.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180628012018427-1532559550.png"></p>
<p>但debug<br>reload是一柄双刃剑：它会清空当前内存中的数据，重新从RDB文件中加载，这个过程会导致主节点的阻塞，因此也需要谨慎。</p>
<h3 id="（3）从节点重启"><a href="#（3）从节点重启" class="headerlink" title="（3）从节点重启"></a>（3）从节点重启</h3><p>从节点宕机重启后，其保存的主节点的runid会丢失，因此即使再次执行slaveof，也无法进行部分复制。</p>
<h3 id="（4）网络中断"><a href="#（4）网络中断" class="headerlink" title="（4）网络中断"></a>（4）网络中断</h3><p>如果主从节点之间出现网络问题，造成短时间内网络中断，可以分为多种情况讨论。</p>
<p>第一种情况：网络问题时间极为短暂，只造成了短暂的丢包，主从节点都没有判定超时（未触发repl-timeout）；此时只需要通过REPLCONF<br>ACK来补充丢失的数据即可。</p>
<p>第二种情况：网络问题时间很长，主从节点判断超时（触发了repl-timeout），且丢失的数据过多，超过了复制积压缓冲区所能存储的范围；此时主从节点无法进行部分复制，只能进行全量复制。为了尽可能避免这种情况的发生，应该根据实际情况适当调整复制积压缓冲区的大小；此外及时发现并修复网络中断，也可以减少全量复制。</p>
<p>第三种情况：介于前述两种情况之间，主从节点判断超时，且丢失的数据仍然都在复制积压缓冲区中；此时主从节点可以进行部分复制。</p>
<ol start="5">
<li>复制相关的配置</li>
</ol>
<hr>
<p>这一节总结一下与复制有关的配置，说明这些配置的作用、起作用的阶段，以及配置方法等；通过了解这些配置，一方面加深对Redis复制的了解，另一方面掌握这些配置的方法，可以优化Redis的使用，少走坑。</p>
<p>配置大致可以分为主节点相关配置、从节点相关配置以及与主从节点都有关的配置，下面分别说明。</p>
<h3 id="（1）与主从节点都有关的配置"><a href="#（1）与主从节点都有关的配置" class="headerlink" title="（1）与主从节点都有关的配置"></a>（1）与主从节点都有关的配置</h3><p>首先介绍最特殊的配置，它决定了该节点是主节点还是从节点：</p>
<p>1)   slaveof \&lt;masterip><br>\&lt;masterport>：Redis启动时起作用；作用是建立复制关系，开启了该配置的Redis服务器在启动后成为从节点。该注释默认注释掉，即Redis服务器默认都是主节点。</p>
<p>2)   repl-timeout 60：与各个阶段主从节点连接超时判断有关，见前面的介绍。</p>
<h3 id="（2）主节点相关配置"><a href="#（2）主节点相关配置" class="headerlink" title="（2）主节点相关配置"></a>（2）主节点相关配置</h3><p>1)   repl-diskless-sync<br>no：作用于全量复制阶段，控制主节点是否使用diskless复制（无盘复制）。所谓diskless复制，是指在全量复制时，主节点不再先把数据写入RDB文件，而是直接写入slave的socket中，整个过程中不涉及硬盘；diskless复制在磁盘IO很慢而网速很快时更有优势。需要注意的是，截至Redis3.0，diskless复制处于实验阶段，默认是关闭的。</p>
<p>2)   repl-diskless-sync-delay<br>5：该配置作用于全量复制阶段，当主节点使用diskless复制时，该配置决定主节点向从节点发送之前停顿的时间，单位是秒；只有当diskless复制打开时有效，默认5s。之所以设置停顿时间，是基于以下两个考虑：(1)向slave的socket的传输一旦开始，新连接的slave只能等待当前数据传输结束，才能开始新的数据传输<br>(2)多个从节点有较大的概率在短时间内建立主从复制。</p>
<p>3)   client-output-buffer-limit slave 256MB 64MB<br>60：与全量复制阶段主节点的缓冲区大小有关，见前面的介绍。</p>
<p>4)   repl-disable-tcp-nodelay no：与命令传播阶段的延迟有关，见前面的介绍。</p>
<p>5)   masterauth<br>\&lt;master-password>：与连接建立阶段的身份验证有关，见前面的介绍。</p>
<p>6)   repl-ping-slave-period<br>10：与命令传播阶段主从节点的超时判断有关，见前面的介绍。</p>
<p>7)   repl-backlog-size 1mb：复制积压缓冲区的大小，见前面的介绍。</p>
<p>8)   repl-backlog-ttl<br>3600：当主节点没有从节点时，复制积压缓冲区保留的时间，这样当断开的从节点重新连进来时，可以进行全量复制；默认3600s。如果设置为0，则永远不会释放复制积压缓冲区。</p>
<p>9)   min-slaves-to-write 3与min-slaves-max-lag<br>10：规定了主节点的最小从节点数目，及对应的最大延迟，见前面的介绍。</p>
<h3 id="（3）从节点相关配置"><a href="#（3）从节点相关配置" class="headerlink" title="（3）从节点相关配置"></a>（3）从节点相关配置</h3><p>1)   slave-serve-stale-data<br>yes：与从节点数据陈旧时是否响应客户端命令有关，见前面的介绍。</p>
<p>2)   slave-read-only<br>yes：从节点是否只读；默认是只读的。由于从节点开启写操作容易导致主从节点的数据不一致，因此该配置尽量不要修改。</p>
<ol start="6">
<li>单机内存大小限制</li>
</ol>
<hr>
<p>在 <a href="https://www.cnblogs.com/kismetv/p/9137897.html" target="_blank" rel="noopener">深入学习Redis（2）：持久化</a> 一文中，讲到了fork操作对Redis单机内存大小的限制。实际上在Redis的使用中，限制单机内存大小的因素非常之多，下面总结一下在主从复制中，单机内存过大可能造成的影响：</p>
<p>（1）切主：当主节点宕机时，一种常见的容灾策略是将其中一个从节点提升为主节点，并将其他从节点挂载到新的主节点上，此时这些从节点只能进行全量复制；如果Redis单机内存达到10GB，一个从节点的同步时间在几分钟的级别；如果从节点较多，恢复的速度会更慢。如果系统的读负载很高，而这段时间从节点无法提供服务，会对系统造成很大的压力。</p>
<p>（2）从库扩容：如果访问量突然增大，此时希望增加从节点分担读负载，如果数据量过大，从节点同步太慢，难以及时应对访问量的暴增。</p>
<p>（3）缓冲区溢出：（1）和（2）都是从节点可以正常同步的情形（虽然慢），但是如果数据量过大，导致全量复制阶段主节点的复制缓冲区溢出，从而导致复制中断，则主从节点的数据同步会全量复制->复制缓冲区溢出导致复制中断->重连->全量复制->复制缓冲区溢出导致复制中断……的循环。</p>
<p>（4）超时：如果数据量过大，全量复制阶段主节点fork+保存RDB文件耗时过大，从节点长时间接收不到数据触发超时，主从节点的数据同步同样可能陷入全量复制->超时导致复制中断->重连->全量复制->超时导致复制中断……的循环。</p>
<p>此外，主节点单机内存除了绝对量不能太大，其占用主机内存的比例也不应过大：最好只使用50%-65%的内存，留下30%-45%的内存用于执行bgsave命令和创建复制缓冲区等。</p>
<ol start="7">
<li>info Replication</li>
</ol>
<hr>
<p>在Redis客户端通过info<br>Replication可以查看与复制相关的状态，对于了解主从节点的当前状态，以及解决出现的问题都会有帮助。</p>
<p>主节点：</p>
<p><img src="http://47.103.200.134/image/fb322a09636f4b4c2cac90b108ea0e1a.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180628012051376-2011129261.png"></p>
<p>从节点：</p>
<p><img src="http://47.103.200.134/image/65eff7d794eb0b0926dc65abbd6bf93e.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180628012057112-2012438265.png"></p>
<p>对于从节点，上半部分展示的是其作为从节点的状态，从connectd_slaves开始，展示的是其作为潜在的主节点的状态。</p>
<p>info Replication中展示的大部分内容在文章中都已经讲述，这里不再详述。</p>
<h1 id="七、总结"><a href="#七、总结" class="headerlink" title="七、总结"></a>七、总结</h1><p>下面回顾一下本文的主要内容：</p>
<p>1、主从复制的作用：宏观的了解主从复制是为了解决什么样的问题，即数据冗余、故障恢复、读负载均衡等。</p>
<p>2、主从复制的操作：即slaveof命令。</p>
<p>3、主从复制的原理：主从复制包括了连接建立阶段、数据同步阶段、命令传播阶段；其中数据同步阶段，有全量复制和部分复制两种数据同步方式；命令传播阶段，主从节点之间有PING和REPLCONF<br>ACK命令互相进行心跳检测。</p>
<p>4、应用中的问题：包括读写分离的问题（数据不一致问题、数据过期问题、故障切换问题等）、复制超时问题、复制中断问题等，然后总结了主从复制相关的配置，其中repl-timeout、client-output-buffer-limit<br>slave等对解决Redis主从复制中出现的问题可能会有帮助。</p>
<p>主从复制虽然解决或缓解了数据冗余、故障恢复、读负载均衡等问题，但其缺陷仍很明显：故障恢复无法自动化；写操作无法负载均衡；存储能力受到单机的限制；这些问题的解决，需要哨兵和集群的帮助，我将在后面的文章中介绍，欢迎关注。</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>《Redis开发与运维》</p>
<p>《Redis设计与实现》</p>
<p>《Redis实战》</p>
<p><a href="http://mdba.cn/2015/03/16/redis复制中断问题-慢查询/" target="_blank" rel="noopener">http://mdba.cn/2015/03/16/redis复制中断问题-慢查询/</a></p>
<p><a href="https://redislabs.com/blog/top-redis-headaches-for-devops-replication-buffer/" target="_blank" rel="noopener">https://redislabs.com/blog/top-redis-headaches-for-devops-replication-buffer/</a></p>
<p><a href="http://mdba.cn/2015/03/17/redis主从复制（2）-replication-buffer与replication-backlog/" target="_blank" rel="noopener">http://mdba.cn/2015/03/17/redis主从复制（2）-replication-buffer与replication-backlog/</a></p>
<p><a href="https://github.com/antirez/redis/issues/918" target="_blank" rel="noopener">https://github.com/antirez/redis/issues/918</a></p>
<p><a href="https://blog.csdn.net/qbw2010/article/details/50496982" target="_blank" rel="noopener">https://blog.csdn.net/qbw2010/article/details/50496982</a></p>
<p><a href="https://mp.weixin.qq.com/s?__biz=MzIxMzEzMjM5NQ==&amp;mid=2651029484&amp;idx=1&amp;sn=5882f4c7c390a0a0e4f6dfd872e203b5&amp;chksm=8c4caae8bb3b23fe77909e307d45a071186f55069e5207602c61383eab573885615c1d835904&amp;mpshare=1&amp;scene=1&amp;srcid=0327SokqtxEY3WojWNDMHLYl\#rd" target="_blank" rel="noopener">https://mp.weixin.qq.com/s?__biz=MzIxMzEzMjM5NQ==&amp;mid=2651029484&amp;idx=1&amp;sn=5882f4c7c390a0a0e4f6dfd872e203b5&amp;chksm=8c4caae8bb3b23fe77909e307d45a071186f55069e5207602c61383eab573885615c1d835904&amp;mpshare=1&amp;scene=1&amp;srcid=0327SokqtxEY3WojWNDMHLYl\#rd</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.zengmanhua.cn/2019/06/14/持久化/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jin Yu Bao">
      <meta itemprop="description" content="生活源于奋斗">
      <meta itemprop="image" content="http://prl6c63q7.bkt.clouddn.com/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JinYuBao">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/06/14/持久化/" class="post-title-link" itemprop="url">持久化</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-06-14 15:43:21" itemprop="dateCreated datePublished" datetime="2019-06-14T15:43:21+08:00">2019-06-14</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/technology/" itemprop="url" rel="index"><span itemprop="name">技术</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2019/06/14/持久化/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/06/14/持久化/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong>前言</strong></p>
<p>在上一篇文章中，介绍了<a href>Redis的内存模型</a>，从这篇文章开始，将依次介绍Redis高可用相关的知识——持久化、复制(及读写分离)、哨兵、以及集群。</p>
<p>本文将先说明上述几种技术分别解决了Redis高可用的什么问题；然后详细介绍Redis的持久化技术，主要是RDB和AOF两种持久化方案；在介绍RDB和AOF方案时，不仅介绍其作用及操作方法，同时介绍持久化实现的一些原理细节及需要注意的问题。最后，介绍在实际使用中，持久化方案的选择，以及经常遇到的问题等。</p>
<p><strong>目录</strong></p>
<p><em>一、Redis高可用概述</em></p>
<p><a href>二、Redis持久化概述</a></p>
<p><em>三、RDB持久化</em></p>
<pre><code>[1. 触发条件]()

[2. 执行流程]()

[3. RDB文件]()

[4. 启动时加载]()

*5. RDB常用配置总结*
</code></pre><p><em>四、AOF持久化</em></p>
<pre><code>[1. 开启AOF]()

[2. 执行流程]()

[3. 启动时加载]()

[4. AOF常用配置总结]()
</code></pre><p><em>五、方案选择与常见问题</em></p>
<pre><code>*1. RDB和AOF的优缺点*

[2. 持久化策略选择]()
</code></pre><p>  <a href>3. fork阻塞：CPU的阻塞</a></p>
<p>  <a href>4.AOF追加阻塞：硬盘的阻塞</a></p>
<pre><code>*5. info命令与持久化*
</code></pre><p><em>六、总结</em></p>
<p><strong>一、Redis高可用概述</strong></p>
<p>在介绍Redis高可用之前，先说明一下在Redis的语境中高可用的含义。</p>
<p>我们知道，在web服务器中，高可用是指服务器可以正常访问的时间，衡量的标准是在多长时间内可以提供正常服务（99.9%、99.99%、99.999%<br>等等）。但是在Redis语境中，高可用的含义似乎要宽泛一些，除了保证提供正常服务(如主从分离、快速容灾技术)，还需要考虑数据容量的扩展、数据安全不会丢失等。</p>
<p>在Redis中，实现高可用的技术主要包括持久化、复制、哨兵和集群，下面分别说明它们的作用，以及解决了什么样的问题。</p>
<ol>
<li><p>持久化：持久化是最简单的高可用方法(有时甚至不被归为高可用的手段)，主要作用是数据备份，即将数据存储在硬盘，保证数据不会因进程退出而丢失。</p>
</li>
<li><p>复制：复制是高可用Redis的基础，哨兵和集群都是在复制基础上实现高可用的。复制主要实现了数据的多机备份，以及对于读操作的负载均衡和简单的故障恢复。缺陷：故障恢复无法自动化；写操作无法负载均衡；存储能力受到单机的限制。</p>
</li>
<li><p>哨兵：在复制的基础上，哨兵实现了自动化的故障恢复。缺陷：写操作无法负载均衡；存储能力受到单机的限制。</p>
</li>
<li><p>集群：通过集群，Redis解决了写操作无法负载均衡，以及存储能力受到单机限制的问题，实现了较为完善的高可用方案。</p>
</li>
</ol>
<p><strong>二、Redis持久化概述</strong></p>
<p>持久化的功能：Redis是内存数据库，数据都是存储在内存中，为了避免进程退出导致数据的永久丢失，需要定期将Redis中的数据以某种形式(数据或命令)从内存保存到硬盘；当下次Redis重启时，利用持久化文件实现数据恢复。除此之外，为了进行灾难备份，可以将持久化文件拷贝到一个远程位置。</p>
<p>Redis持久化分为RDB持久化和AOF持久化<strong>：前者将当前数据保存到硬盘，后者则是将每次执行的写命令保存到硬盘（类似于MySQL的binlog）；</strong>由于AOF持久化的实时性更好，即当进程意外退出时丢失的数据更少，因此AOF是目前主流的持久化方式，不过RDB持久化仍然有其用武之地。</p>
<p>下面依次介绍RDB持久化和AOF持久化；由于Redis各个版本之间存在差异，如无特殊说明，以Redis3.0为准。</p>
<p><strong>三、RDB持久化</strong></p>
<p>RDB持久化是将当前进程中的数据生成快照保存到硬盘(因此也称作快照持久化)，保存的文件后缀是rdb；当Redis重新启动时，可以读取快照文件恢复数据。</p>
<p><strong>1. 触发条件</strong></p>
<p>RDB持久化的触发分为手动触发和自动触发两种。</p>
<p><strong>1) 手动触发</strong></p>
<p>save命令和bgsave命令都可以生成RDB文件。</p>
<p>save命令会阻塞Redis服务器进程，直到RDB文件创建完毕为止，在Redis服务器阻塞期间，服务器不能处理任何命令请求。</p>
<p><img src="http://47.103.200.134/image/e22dc38892da7c0988f95e781065c2d2.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180605085242889-137050862.png"></p>
<p>而bgsave命令会创建一个子进程，由子进程来负责创建RDB文件，父进程(即Redis主进程)则继续处理请求。</p>
<p><img src="http://47.103.200.134/image/5b4e14ee3a58cf851236596b9903a1a9.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180605085309364-1576452765.png"></p>
<p>此时服务器执行日志如下：</p>
<p><img src="http://47.103.200.134/image/883b914f81f47ee181633151e5868c97.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180605085325656-76060516.png"></p>
<p>bgsave命令执行过程中，只有fork子进程时会阻塞服务器，而对于save命令，整个过程都会阻塞服务器，因此save已基本被废弃，线上环境要杜绝save的使用；后文中也将只介绍bgsave命令。此外，在自动触发RDB持久化时，Redis也会选择bgsave而不是save来进行持久化；下面介绍自动触发RDB持久化的条件。</p>
<p><strong>2) 自动触发</strong></p>
<p><strong>save m n</strong></p>
<p>自动触发最常见的情况是在配置文件中通过save m<br>n，指定当m秒内发生n次变化时，会触发bgsave。</p>
<p>例如，查看redis的默认配置文件(Linux下为redis根目录下的redis.conf)，可以看到如下配置信息：</p>
<p><img src="http://47.103.200.134/image/e5279f356c67059465b3a31107a57274.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180605085420533-1928501600.png"></p>
<p>其中save 900<br>1的含义是：当时间到900秒时，如果redis数据发生了至少1次变化，则执行bgsave；save<br>300 10和save 60 10000同理。当三个save条件满足任意一个时，都会引起bgsave的调用。</p>
<p><strong>save m n的实现原理</strong></p>
<p>Redis的save m n，是通过serverCron函数、dirty计数器、和lastsave时间戳来实现的。</p>
<p>serverCron是Redis服务器的周期性操作函数，默认每隔100ms执行一次；该函数对服务器的状态进行维护，其中一项工作就是检查<br>save m n 配置的条件是否满足，如果满足就执行bgsave。</p>
<p>dirty计数器是Redis服务器维持的一个状态，记录了上一次执行bgsave/save命令后，服务器状态进行了多少次修改(包括增删改)；而当save/bgsave执行完成后，会将dirty重新置为0。</p>
<p>例如，如果Redis执行了set mykey helloworld，则dirty值会+1；如果执行了sadd myset<br>v1 v2<br>v3，则dirty值会+3；注意dirty记录的是服务器进行了多少次修改，而不是客户端执行了多少修改数据的命令。</p>
<p>lastsave时间戳也是Redis服务器维持的一个状态，记录的是上一次成功执行save/bgsave的时间。</p>
<p>save m n的原理如下：每隔100ms，执行serverCron函数；在serverCron函数中，遍历save<br>m n配置的保存条件，只要有一个条件满足，就进行bgsave。对于每一个save m<br>n条件，只有下面两条同时满足时才算满足：</p>
<p>（1）当前时间-lastsave > m</p>
<p>（2）dirty >= n</p>
<p><strong>save m n 执行日志</strong></p>
<p>下图是save m n触发bgsave执行时，服务器打印日志的情况：</p>
<p><img src="http://47.103.200.134/image/012b31a515b9703461be8f4412095798.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180605085606524-1682958341.png"></p>
<p><strong>其他自动触发机制</strong></p>
<p>除了save m n 以外，还有一些其他情况会触发bgsave：</p>
<ul>
<li><p>在主从复制场景下，如果从节点执行全量复制操作，则主节点会执行bgsave命令，并将rdb文件发送给从节点</p>
</li>
<li><p>执行shutdown命令时，自动执行rdb持久化，如下图所示：</p>
</li>
</ul>
<p><img src="http://47.103.200.134/image/bb05fba5391fe860bf945355e7c665c2.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180605085620830-1223048825.png"></p>
<p><strong>2. 执行流程</strong></p>
<p>前面介绍了触发bgsave的条件，下面将说明bgsave命令的执行流程，如下图所示(图片来源：<a href="https://blog.csdn.net/a1007720052/article/details/79126253)：" target="_blank" rel="noopener">https://blog.csdn.net/a1007720052/article/details/79126253)：</a></p>
<p><img src="http://47.103.200.134/image/1f9d0b79e335393d7825fca8637cafe1.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180605085813461-389677620.png"></p>
<p>图片中的5个步骤所进行的操作如下：</p>
<p>1)<br>Redis父进程首先判断：当前是否在执行save，或bgsave/bgrewriteaof（后面会详细介绍该命令）的子进程，如果在执行则bgsave命令直接返回。bgsave/bgrewriteaof<br>的子进程不能同时执行，主要是基于性能方面的考虑：两个并发的子进程同时执行大量的磁盘写操作，可能引起严重的性能问题。</p>
<p>2)<br>父进程执行fork操作创建子进程，这个过程中父进程是阻塞的，Redis不能执行来自客户端的任何命令</p>
<p>3)  父进程fork后，bgsave命令返回”Background saving<br>started”信息并不再阻塞父进程，并可以响应其他命令</p>
<p>4)<br>子进程创建RDB文件，根据父进程内存快照生成临时快照文件，完成后对原有文件进行原子替换</p>
<p>5)  子进程发送信号给父进程表示完成，父进程更新统计信息</p>
<p><strong>3. RDB文件</strong></p>
<p>RDB文件是经过压缩的二进制文件，下面介绍关于RDB文件的一些细节。</p>
<p><strong>存储路径</strong></p>
<p>RDB文件的存储路径既可以在启动前配置，也可以通过命令动态设定。</p>
<p>配置：dir配置指定目录，dbfilename指定文件名。默认是Redis根目录下的dump.rdb文件。</p>
<p>动态设定：Redis启动后也可以动态修改RDB存储路径，在磁盘损害或空间不足时非常有用；执行命令为config<br>set dir {newdir}和config set dbfilename {newFileName}。如下所示(Windows环境)：</p>
<p><img src="http://47.103.200.134/image/036cbc8873d4da1ddd4cd036170f8e11.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180605090102836-284073324.png"></p>
<p><strong>RDB文件格式</strong></p>
<p>RDB文件格式如下图所示（图片来源：《Redis设计与实现》）：</p>
<p><img src="http://47.103.200.134/image/89aa18a36a490ad5dfd8df5e5587501c.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180605090115749-1746859283.png"></p>
<p>其中各个字段的含义说明如下：</p>
<p>1)  REDIS：常量，保存着”REDIS”5个字符。</p>
<p>2)  db_version：RDB文件的版本号，注意不是Redis的版本号。</p>
<p>3)  SELECTDB 0 pairs：表示一个完整的数据库(0号数据库)，同理SELECTDB 3<br>pairs表示完整的3号数据库；只有当数据库中有键值对时，RDB文件中才会有该数据库的信息(上图所示的Redis中只有0号和3号数据库有键值对)；如果Redis中所有的数据库都没有键值对，则这一部分直接省略。其中：SELECTDB是一个常量，代表后面跟着的是数据库号码；0和3是数据库号码；pairs则存储了具体的键值对信息，包括key、value值，及其数据类型、内部编码、过期时间、压缩信息等等。</p>
<p>4)  EOF：常量，标志RDB文件正文内容结束。</p>
<p>5)<br>check_sum：前面所有内容的校验和；Redis在载入RBD文件时，会计算前面的校验和并与check_sum值比较，判断文件是否损坏。</p>
<p><strong>压缩</strong></p>
<p>Redis默认采用LZF算法对RDB文件进行压缩。虽然压缩耗时，但是可以大大减小RDB文件的体积，因此压缩默认开启；可以通过命令关闭：</p>
<p><img src="http://47.103.200.134/image/e4032d121168c9c1826b4ea7977216cb.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180605090239365-13188208.png"></p>
<p>需要注意的是，RDB文件的压缩并不是针对整个文件进行的，而是对数据库中的字符串进行的，且只有在字符串达到一定长度(20字节)时才会进行。</p>
<p><strong>4. 启动时加载</strong></p>
<p>RDB文件的载入工作是在服务器启动时自动执行的，并没有专门的命令。但是由于AOF的优先级更高，因此当AOF开启时，Redis会优先载入AOF文件来恢复数据；只有当AOF关闭时，才会在Redis服务器启动时检测RDB文件，并自动载入。服务器载入RDB文件期间处于阻塞状态，直到载入完成为止。</p>
<p>Redis启动日志中可以看到自动载入的执行：</p>
<p><img src="http://47.103.200.134/image/686c50547f1879076f28276bcfaae8a4.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180605090316297-2056098245.png"></p>
<p>Redis载入RDB文件时，会对RDB文件进行校验，如果文件损坏，则日志中会打印错误，Redis启动失败。</p>
<p><strong>5. RDB常用配置总结</strong></p>
<p>下面是RDB常用的配置项，以及默认值；前面介绍过的这里不再详细介绍。</p>
<ul>
<li><p>save m n：bgsave自动触发的条件；如果没有save m<br>n配置，相当于自动的RDB持久化关闭，不过此时仍可以通过其他方式触发</p>
</li>
<li><p>stop-writes-on-bgsave-error<br>yes：当bgsave出现错误时，Redis是否停止执行写命令；设置为yes，则当硬盘出现问题时，可以及时发现，避免数据的大量丢失；设置为no，则Redis无视bgsave的错误继续执行写命令，当对Redis服务器的系统(尤其是硬盘)使用了监控时，该选项考虑设置为no</p>
</li>
<li><p>rdbcompression yes：是否开启RDB文件压缩</p>
</li>
<li><p>rdbchecksum<br>yes：是否开启RDB文件的校验，在写入文件和读取文件时都起作用；关闭checksum在写入文件和启动文件时大约能带来10%的性能提升，但是数据损坏时无法发现</p>
</li>
<li><p>dbfilename dump.rdb：RDB文件名</p>
</li>
<li><p>dir ./：RDB文件和AOF文件所在目录</p>
</li>
</ul>
<p><strong>四、AOF持久化</strong></p>
<p>RDB持久化是将进程数据写入文件，而AOF持久化(即Append Only<br>File持久化)，则是将Redis执行的每次写命令记录到单独的日志文件中（有点像MySQL的binlog）；当Redis重启时再次执行AOF文件中的命令来恢复数据。</p>
<p>与RDB相比，AOF的实时性更好，因此已成为主流的持久化方案。</p>
<p><strong>1. 开启AOF</strong></p>
<p>Redis服务器默认开启RDB，关闭AOF；要开启AOF，需要在配置文件中配置：</p>
<p>appendonly yes</p>
<p><strong>2. 执行流程</strong></p>
<p>由于需要记录Redis的每条写命令，因此AOF不需要触发，下面介绍AOF的执行流程。</p>
<p>AOF的执行流程包括：</p>
<ul>
<li><p>命令追加(append)：将Redis的写命令追加到缓冲区aof_buf；</p>
</li>
<li><p>文件写入(write)和文件同步(sync)：根据不同的同步策略将aof_buf中的内容同步到硬盘；</p>
</li>
<li><p>文件重写(rewrite)：定期重写AOF文件，达到压缩的目的。</p>
</li>
</ul>
<p><strong>1) 命令追加(append)</strong></p>
<p>Redis先将写命令追加到缓冲区，而不是直接写入文件，主要是为了避免每次有写命令都直接写入硬盘，导致硬盘IO成为Redis负载的瓶颈。</p>
<p>命令追加的格式是Redis命令请求的协议格式，它是一种纯文本格式，具有兼容性好、可读性强、容易处理、操作简单避免二次开销等优点；具体格式略。在AOF文件中，除了用于指定数据库的select命令（如select<br>0 为选中0号数据库）是由Redis添加的，其他都是客户端发送来的写命令。</p>
<p><strong>2) 文件写入(write)和文件同步(sync)</strong></p>
<p>Redis提供了多种AOF缓存区的同步文件策略，策略涉及到操作系统的write函数和fsync函数，说明如下：</p>
<p>为了提高文件写入效率，在现代操作系统中，当用户调用write函数将数据写入文件时，操作系统通常会将数据暂存到一个内存缓冲区里，当缓冲区被填满或超过了指定时限后，才真正将缓冲区的数据写入到硬盘里。这样的操作虽然提高了效率，但也带来了安全问题：如果计算机停机，内存缓冲区中的数据会丢失；因此系统同时提供了fsync、fdatasync等同步函数，可以强制操作系统立刻将缓冲区中的数据写入到硬盘里，从而确保数据的安全性。</p>
<p>AOF缓存区的同步文件策略由参数appendfsync控制，各个值的含义如下：</p>
<ul>
<li><p>always：命令写入aof_buf后立即调用系统fsync操作同步到AOF文件，fsync完成后线程返回。这种情况下，每次有写命令都要同步到AOF文件，硬盘IO成为性能瓶颈，Redis只能支持大约几百TPS写入，严重降低了Redis的性能；即便是使用固态硬盘（SSD），每秒大约也只能处理几万个命令，而且会大大降低SSD的寿命。</p>
</li>
<li><p>no：命令写入aof_buf后调用系统write操作，不对AOF文件做fsync同步；同步由操作系统负责，通常同步周期为30秒。这种情况下，文件同步的时间不可控，且缓冲区中堆积的数据会很多，数据安全性无法保证。</p>
</li>
<li><p>everysec：命令写入aof_buf后调用系统write操作，write完成后线程返回；fsync同步文件操作由专门的线程每秒调用一次。<strong>everysec是前述两种策略的折中，是性能和数据安全性的平衡，因此是Redis的默认配置，也是我们推荐的配置。</strong></p>
</li>
</ul>
<p><strong>3) 文件重写(rewrite)</strong></p>
<p>随着时间流逝，Redis服务器执行的写命令越来越多，AOF文件也会越来越大；过大的AOF文件不仅会影响服务器的正常运行，也会导致数据恢复需要的时间过长。</p>
<p>文件重写是指定期重写AOF文件，减小AOF文件的体积。需要注意的是，<strong>AOF重写是把Redis进程内的数据转化为写命令，同步到新的AOF文件；不会对旧的AOF文件进行任何读取、写入操作!</strong></p>
<p>关于文件重写需要注意的另一点是：对于AOF持久化来说，文件重写虽然是强烈推荐的，但并不是必须的；即使没有文件重写，数据也可以被持久化并在Redis启动的时候导入；因此在一些实现中，会关闭自动的文件重写，然后通过定时任务在每天的某一时刻定时执行。</p>
<p>文件重写之所以能够压缩AOF文件，原因在于：</p>
<ul>
<li><p>过期的数据不再写入文件</p>
</li>
<li><p>无效的命令不再写入文件：如有些数据被重复设值(set mykey v1, set mykey<br>v2)、有些数据被删除了(sadd myset v1, del myset)等等</p>
</li>
<li><p>多条命令可以合并为一个：如sadd myset v1, sadd myset v2, sadd myset<br>v3可以合并为sadd myset v1 v2<br>v3。不过为了防止单条命令过大造成客户端缓冲区溢出，对于list、set、hash、zset类型的key，并不一定只使用一条命令；而是以某个常量为界将命令拆分为多条。这个常量在redis.h/REDIS_AOF_REWRITE_ITEMS_PER_CMD中定义，不可更改，3.0版本中值是64。</p>
</li>
</ul>
<p><img src="http://47.103.200.134/image/ff1b0fb4f61a19471c099bf8c47c5e45.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180605091657431-1777000468.png"></p>
<p>通过上述内容可以看出，由于重写后AOF执行的命令减少了，文件重写既可以减少文件占用的空间，也可以加快恢复速度。</p>
<p><strong>文件重写的触发</strong></p>
<p>文件重写的触发，分为手动触发和自动触发：</p>
<p>手动触发：直接调用bgrewriteaof命令，该命令的执行与bgsave有些类似：都是fork子进程进行具体的工作，且都只有在fork时阻塞。</p>
<p><img src="http://47.103.200.134/image/ffb78c16347e8b6379e4644672bf2522.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180605091720655-1144425871.png"></p>
<p>此时服务器执行日志如下：</p>
<p><img src="http://47.103.200.134/image/d64d764f36bfefa7910ca0df55f5185d.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180605091728855-1220695695.png"></p>
<p>自动触发：根据auto-aof-rewrite-min-size和auto-aof-rewrite-percentage参数，以及aof_current_size和aof_base_size状态确定触发时机。</p>
<ul>
<li><p>auto-aof-rewrite-min-size：执行AOF重写时，文件的最小体积，默认值为64MB。</p>
</li>
<li><p>auto-aof-rewrite-percentage：执行AOF重写时，当前AOF大小(即aof_current_size)和上一次重写时AOF大小(aof_base_size)的比值。</p>
</li>
</ul>
<p>其中，参数可以通过config get命令查看：</p>
<p><img src="http://47.103.200.134/image/0c2ba449acacc9e6a4c716fa794c0584.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180605091826619-1149439298.png"></p>
<p>状态可以通过info persistence查看：</p>
<p><img src="http://47.103.200.134/image/b9c1ac708204a48858df96839a5e0792.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180605091913978-93129453.png"></p>
<p>只有当auto-aof-rewrite-min-size和auto-aof-rewrite-percentage两个参数同时满足时，才会自动触发AOF重写，即bgrewriteaof操作。</p>
<p>自动触发bgrewriteaof时，可以看到服务器日志如下：</p>
<p><img src="http://47.103.200.134/image/436c059ee19a2bda0510267ba3db5c89.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180605091932313-1279644027.png"></p>
<p><strong>文件重写的流程</strong></p>
<p>文件重写流程如下图所示(图片来源：<a href="http://www.cnblogs.com/yangmingxianshen/p/8373205.html)：" target="_blank" rel="noopener">http://www.cnblogs.com/yangmingxianshen/p/8373205.html)：</a></p>
<p><img src="http://47.103.200.134/image/890fafa81323d9958582d5902d413e70.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180605092001589-1724580361.png"></p>
<p>关于文件重写的流程，有两点需要特别注意：(1)重写由父进程fork子进程进行；(2)重写期间Redis执行的写命令，需要追加到新的AOF文件中，为此Redis引入了aof_rewrite_buf缓存。</p>
<p>对照上图，文件重写的流程如下：</p>
<p>1) Redis父进程首先判断当前是否存在正在执行<br>bgsave/bgrewriteaof的子进程，如果存在则bgrewriteaof命令直接返回，如果存在bgsave命令则等bgsave执行完成后再执行。前面曾介绍过，这个主要是基于性能方面的考虑。</p>
<p>2) 父进程执行fork操作创建子进程，这个过程中父进程是阻塞的。</p>
<p>3.1) 父进程fork后，bgrewriteaof命令返回”Background append only file rewrite<br>started”信息并不再阻塞父进程，并可以响应其他命令。<strong>Redis的所有写命令依然写入AOF缓冲区，并根据appendfsync策略同步到硬盘，保证原有AOF机制的正确。</strong></p>
<p>3.2)<br>由于fork操作使用写时复制技术，子进程只能共享fork操作时的内存数据。<strong>由于父进程依然在响应命令，因此Redis使用AOF重写缓冲区(图中的aof_rewrite_buf)保存这部分数据，防止新AOF文件生成期间丢失这部分数据。也就是说，bgrewriteaof执行期间，Redis的写命令同时追加到aof_buf和aof_rewirte_buf两个缓冲区。</strong></p>
<p>4) 子进程根据内存快照，按照命令合并规则写入到新的AOF文件。</p>
<p>5.1)<br>子进程写完新的AOF文件后，向父进程发信号，父进程更新统计信息，具体可以通过info<br>persistence查看。</p>
<p>5.2)<br>父进程把AOF重写缓冲区的数据写入到新的AOF文件，这样就保证了新AOF文件所保存的数据库状态和服务器当前状态一致。</p>
<p>5.3) 使用新的AOF文件替换老文件，完成AOF重写。</p>
<p><strong>3. 启动时加载</strong></p>
<p>前面提到过，当AOF开启时，Redis启动时会优先载入AOF文件来恢复数据；只有当AOF关闭时，才会载入RDB文件恢复数据。</p>
<p>当AOF开启，且AOF文件存在时，Redis启动日志：</p>
<p><img src="http://47.103.200.134/image/2d3b86784f423497e5dec829331b3439.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180605125715427-372924099.png"></p>
<p>当AOF开启，但AOF文件不存在时，即使RDB文件存在也不会加载(更早的一些版本可能会加载，但3.0不会)，Redis启动日志如下：</p>
<p><img src="http://47.103.200.134/image/70e7dd203c88f9b0a6ccc525ea0c9da2.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180605125726244-1151986629.png"></p>
<p><strong>文件校验</strong></p>
<p>与载入RDB文件类似，Redis载入AOF文件时，会对AOF文件进行校验，如果文件损坏，则日志中会打印错误，Redis启动失败。但如果是AOF文件结尾不完整(机器突然宕机等容易导致文件尾部不完整)，且aof-load-truncated参数开启，则日志中会输出警告，Redis忽略掉AOF文件的尾部，启动成功。aof-load-truncated参数默认是开启的：</p>
<p><img src="http://47.103.200.134/image/bd73c61b0fb58d0a9bd90c78e28092f3.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180605125752302-1021481114.png"></p>
<p><strong>伪客户端</strong></p>
<p>因为Redis的命令只能在客户端上下文中执行，而载入AOF文件时命令是直接从文件中读取的，并不是由客户端发送；因此Redis服务器在载入AOF文件之前，会创建一个没有网络连接的客户端，之后用它来执行AOF文件中的命令，命令执行的效果与带网络连接的客户端完全一样。</p>
<p><strong>4. AOF常用配置总结</strong></p>
<p>下面是AOF常用的配置项，以及默认值；前面介绍过的这里不再详细介绍。</p>
<ul>
<li><p>appendonly no：是否开启AOF</p>
</li>
<li><p>appendfilename “appendonly.aof”：AOF文件名</p>
</li>
<li><p>dir ./：RDB文件和AOF文件所在目录</p>
</li>
<li><p>appendfsync everysec：fsync持久化策略</p>
</li>
<li><p>no-appendfsync-on-rewrite<br>no：AOF重写期间是否禁止fsync；如果开启该选项，可以减轻文件重写时CPU和硬盘的负载（尤其是硬盘），但是可能会丢失AOF重写期间的数据；需要在负载和安全性之间进行平衡</p>
</li>
<li><p>auto-aof-rewrite-percentage 100：文件重写触发条件之一</p>
</li>
<li><p>auto-aof-rewrite-min-size 64mb：文件重写触发提交之一</p>
</li>
<li><p>aof-load-truncated yes：如果AOF文件结尾损坏，Redis启动时是否仍载入AOF文件</p>
</li>
</ul>
<p><strong>五、方案选择与常见问题</strong></p>
<p>前面介绍了RDB和AOF两种持久化方案的细节，下面介绍RDB和AOF的特点、如何选择持久化方案，以及在持久化过程中常遇到的问题等。</p>
<p><strong>1. RDB和AOF的优缺点</strong></p>
<p>RDB和AOF各有优缺点：</p>
<p><strong>RDB持久化</strong></p>
<p>优点：RDB文件紧凑，体积小，网络传输快，适合全量复制；恢复速度比AOF快很多。当然，与AOF相比，RDB最重要的优点之一是对性能的影响相对较小。</p>
<p>缺点：RDB文件的致命缺点在于其数据快照的持久化方式决定了必然做不到实时持久化，而在数据越来越重要的今天，数据的大量丢失很多时候是无法接受的，因此AOF持久化成为主流。此外，RDB文件需要满足特定格式，兼容性差（如老版本的Redis不兼容新版本的RDB文件）。</p>
<p><strong>AOF持久化</strong></p>
<p>与RDB持久化相对应，AOF的优点在于支持秒级持久化、兼容性好，缺点是文件大、恢复速度慢、对性能影响大。</p>
<p><strong>2. 持久化策略选择</strong></p>
<p>在介绍持久化策略之前，首先要明白无论是RDB还是AOF，持久化的开启都是要付出性能方面代价的：对于RDB持久化，一方面是bgsave在进行fork操作时Redis主进程会阻塞，另一方面，子进程向硬盘写数据也会带来IO压力；对于AOF持久化，向硬盘写数据的频率大大提高(everysec策略下为秒级)，IO压力更大，甚至可能造成AOF追加阻塞问题（后面会详细介绍这种阻塞），此外，AOF文件的重写与RDB的bgsave类似，会有fork时的阻塞和子进程的IO压力问题。相对来说，由于AOF向硬盘中写数据的频率更高，因此对Redis主进程性能的影响会更大。</p>
<p>在实际生产环境中，根据数据量、应用对数据的安全要求、预算限制等不同情况，会有各种各样的持久化策略；如完全不使用任何持久化、使用RDB或AOF的一种，或同时开启RDB和AOF持久化等。此外，持久化的选择必须与Redis的主从策略一起考虑，因为主从复制与持久化同样具有数据备份的功能，而且主机master和从机slave可以独立的选择持久化方案。</p>
<p>下面分场景来讨论持久化策略的选择，下面的讨论也只是作为参考，实际方案可能更复杂更具多样性。</p>
<p>（1）如果Redis中的数据完全丢弃也没有关系（如Redis完全用作DB层数据的cache），那么无论是单机，还是主从架构，都可以不进行任何持久化。</p>
<p>（2）在单机环境下（对于个人开发者，这种情况可能比较常见），如果可以接受十几分钟或更多的数据丢失，选择RDB对Redis的性能更加有利；如果只能接受秒级别的数据丢失，应该选择AOF。</p>
<p>（3）但在多数情况下，我们都会配置主从环境，slave的存在既可以实现数据的热备，也可以进行读写分离分担Redis读请求，以及在master宕掉后继续提供服务。</p>
<p>在这种情况下，一种可行的做法是：</p>
<p>master：完全关闭持久化（包括RDB和AOF），这样可以让master的性能达到最好</p>
<p>slave：关闭RDB，开启AOF（如果对数据安全要求不高，开启RDB关闭AOF也可以），并定时对持久化文件进行备份（如备份到其他文件夹，并标记好备份的时间）；然后关闭AOF的自动重写，然后添加定时任务，在每天Redis闲时（如凌晨12点）调用bgrewriteaof。</p>
<p>这里需要解释一下，为什么开启了主从复制，可以实现数据的热备份，还需要设置持久化呢？因为在一些特殊情况下，主从复制仍然不足以保证数据的安全，例如：</p>
<ul>
<li><p>master和slave进程同时停止：考虑这样一种场景，如果master和slave在同一栋大楼或同一个机房，则一次停电事故就可能导致master和slave机器同时关机，Redis进程停止；如果没有持久化，则面临的是数据的完全丢失。</p>
</li>
<li><p>master误重启：考虑这样一种场景，master服务因为故障宕掉了，如果系统中有自动拉起机制（即检测到服务停止后重启该服务）将master自动重启，由于没有持久化文件，那么master重启后数据是空的，slave同步数据也变成了空的；如果master和slave都没有持久化，同样会面临数据的完全丢失。需要注意的是，即便是使用了哨兵(关于哨兵后面会有文章介绍)进行自动的主从切换，也有可能在哨兵轮询到master之前，便被自动拉起机制重启了。因此，应尽量避免“自动拉起机制”和“不做持久化”同时出现。</p>
</li>
</ul>
<p>（4）异地灾备：上述讨论的几种持久化策略，针对的都是一般的系统故障，如进程异常退出、宕机、断电等，这些故障不会损坏硬盘。但是对于一些可能导致硬盘损坏的灾难情况，如火灾地震，就需要进行异地灾备。例如对于单机的情形，可以定时将RDB文件或重写后的AOF文件，通过scp拷贝到远程机器，如阿里云、AWS等；对于主从的情形，可以定时在master上执行bgsave，然后将RDB文件拷贝到远程机器，或者在slave上执行bgrewriteaof重写AOF文件后，将AOF文件拷贝到远程机器上。一般来说，由于RDB文件文件小、恢复快，因此灾难恢复常用RDB文件；异地备份的频率根据数据安全性的需要及其他条件来确定，但最好不要低于一天一次。</p>
<p><strong>3. fork阻塞：CPU的阻塞</strong></p>
<p>在Redis的实践中，众多因素限制了Redis单机的内存不能过大，例如：</p>
<ul>
<li><p>当面对请求的暴增，需要从库扩容时，Redis内存过大会导致扩容时间太长；</p>
</li>
<li><p>当主机宕机时，切换主机后需要挂载从库，Redis内存过大导致挂载速度过慢；</p>
</li>
<li><p>以及持久化过程中的fork操作，下面详细说明。</p>
</li>
</ul>
<p>首先说明一下fork操作：</p>
<p>父进程通过fork操作可以创建子进程；子进程创建后，父子进程共享代码段，不共享进程的数据空间，但是子进程会获得父进程的数据空间的副本。在操作系统fork的实际实现中，基本都采用了写时复制技术，即在父/子进程试图修改数据空间之前，父子进程实际上共享数据空间；但是当父/子进程的任何一个试图修改数据空间时，操作系统会为修改的那一部分(内存的一页)制作一个副本。</p>
<p>虽然fork时，子进程不会复制父进程的数据空间，但是会复制内存页表（页表相当于内存的索引、目录）；父进程的数据空间越大，内存页表越大，fork时复制耗时也会越多。</p>
<p>在Redis中，无论是RDB持久化的bgsave，还是AOF重写的bgrewriteaof，都需要fork出子进程来进行操作。如果Redis内存过大，会导致fork操作时复制内存页表耗时过多；而Redis主进程在进行fork时，是完全阻塞的，也就意味着无法响应客户端的请求，会造成请求延迟过大。</p>
<p>对于不同的硬件、不同的操作系统，fork操作的耗时会有所差别，一般来说，如果Redis单机内存达到了10GB，fork时耗时可能会达到百毫秒级别（如果使用Xen虚拟机，这个耗时可能达到秒级别）。因此，一般来说Redis单机内存一般要限制在10GB以内；不过这个数据并不是绝对的，可以通过观察线上环境fork的耗时来进行调整。观察的方法如下：执行命令info<br>stats，查看latest_fork_usec的值，单位为微秒。</p>
<p>为了减轻fork操作带来的阻塞问题，除了控制Redis单机内存的大小以外，还可以适度放宽AOF重写的触发条件、选用物理机或高效支持fork操作的虚拟化技术等，例如使用Vmware或KVM虚拟机，不要使用Xen虚拟机。</p>
<p><strong>4. AOF追加阻塞：硬盘的阻塞</strong></p>
<p>前面提到过，在AOF中，如果AOF缓冲区的文件同步策略为everysec，则：在主线程中，命令写入aof_buf后调用系统write操作，write完成后主线程返回；fsync同步文件操作由专门的文件同步线程每秒调用一次。</p>
<p>这种做法的问题在于，如果硬盘负载过高，那么fsync操作可能会超过1s；如果Redis主线程持续高速向aof_buf写入命令，硬盘的负载可能会越来越大，IO资源消耗更快；如果此时Redis进程异常退出，丢失的数据也会越来越多，可能远超过1s。</p>
<p>为此，Redis的处理策略是这样的：主线程每次进行AOF会对比上次fsync成功的时间；如果距上次不到2s，主线程直接返回；如果超过2s，则主线程阻塞直到fsync同步完成。因此，如果系统硬盘负载过大导致fsync速度太慢，会导致Redis主线程的阻塞；此外，使用everysec配置，AOF最多可能丢失2s的数据，而不是1s。</p>
<p>AOF追加阻塞问题定位的方法：</p>
<p>（1）监控info<br>Persistence中的aof_delayed_fsync：当AOF追加阻塞发生时（即主线程等待fsync而阻塞），该指标累加。</p>
<p>（2）AOF阻塞时的Redis日志：</p>
<p>Asynchronous AOF fsync is taking too long (disk is busy?). Writing the AOF buffer without waiting for fsync to complete, this may slow down Redis.</p>
<p>（3）如果AOF追加阻塞频繁发生，说明系统的硬盘负载太大；可以考虑更换IO速度更快的硬盘，或者通过IO监控分析工具对系统的IO负载进行分析，如iostat（系统级io）、iotop（io版的top）、pidstat等。</p>
<p><strong>5. info命令与持久化</strong></p>
<p>前面提到了一些通过info命令查看持久化相关状态的方法，下面来总结一下。</p>
<p>（1）info Persistence</p>
<p>执行结果如下：</p>
<p><img src="http://47.103.200.134/image/467ba0b6fb809bc69d873f0a600bea6b.png" alt="https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180605131816242-1924276636.png"></p>
<p>其中比较重要的包括：</p>
<ul>
<li><p>rdb_last_bgsave_status:上次bgsave 执行结果，可以用于发现bgsave错误</p>
</li>
<li><p>rdb_last_bgsave_time_sec:上次bgsave执行时间（单位是s），可以用于发现bgsave是否耗时过长</p>
</li>
<li><p>aof_enabled:AOF是否开启</p>
</li>
<li><p>aof_last_rewrite_time_sec:<br>上次文件重写执行时间（单位是s），可以用于发现文件重写是否耗时过长</p>
</li>
<li><p>aof_last_bgrewrite_status: 上次bgrewrite执行结果，可以用于发现bgrewrite错误</p>
</li>
<li><p>aof_buffer_length和aof_rewrite_buffer_length:aof缓存区大小和aof重写缓冲区大小</p>
</li>
<li><p>aof_delayed_fsync:AOF追加阻塞情况的统计</p>
</li>
</ul>
<p>（2）info stats</p>
<p>其中与持久化关系较大的是：latest_fork_usec，代表上次fork耗时，可以参见前面的讨论。</p>
<p><strong>六、总结</strong></p>
<p>本文主要内容可以总结如下：</p>
<p>1、持久化在Redis高可用中的作用：数据备份，与主从复制相比强调的是由内存到硬盘的备份。</p>
<p>2、RDB持久化：将数据快照备份到硬盘；介绍了其触发条件（包括手动出发和自动触发）、执行流程、RDB文件等，特别需要注意的是文件保存操作由fork出的子进程来进行。</p>
<p>3、AOF持久化：将执行的写命令备份到硬盘（类似于MySQL的binlog），介绍了其开启方法、执行流程等，特别需要注意的是文件同步策略的选择（everysec）、文件重写的流程。</p>
<p>4、一些现实的问题：包括如何选择持久化策略，以及需要注意的fork阻塞、AOF追加阻塞等。</p>
<p><strong>参考文献</strong></p>
<p>《Redis开发与运维》</p>
<p>《Redis设计与实现》</p>
<p>《Redis实战》</p>
<p><a href="http://www.redis.cn/topics/persistence.html" target="_blank" rel="noopener">http://www.redis.cn/topics/persistence.html</a></p>
<p><a href="https://mp.weixin.qq.com/s/fpupqLp-wjR8fQvYSQhVLg" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/fpupqLp-wjR8fQvYSQhVLg</a></p>
<p><a href="https://mp.weixin.qq.com/s?__biz=MzI4NTA1MDEwNg==&amp;mid=2650764050&amp;idx=1&amp;sn=891287b9f99a8c1dd4ce9e1805646741&amp;chksm=f3f9c687c48e4f91c6631e7f5e36a9169c10549386bec541dbeef92ed0023a373f6ec25c2ef1&amp;mpshare=1&amp;scene=1&amp;srcid=0525xnHQxiFwpzFWSME2LQrb#rd" target="_blank" rel="noopener">https://mp.weixin.qq.com/s?__biz=MzI4NTA1MDEwNg==&amp;mid=2650764050&amp;idx=1&amp;sn=891287b9f99a8c1dd4ce9e1805646741&amp;chksm=f3f9c687c48e4f91c6631e7f5e36a9169c10549386bec541dbeef92ed0023a373f6ec25c2ef1&amp;mpshare=1&amp;scene=1&amp;srcid=0525xnHQxiFwpzFWSME2LQrb#rd</a></p>
<p><a href="https://mp.weixin.qq.com/s?__biz=MzI4NTA1MDEwNg==&amp;mid=2650763383&amp;idx=1&amp;sn=348a84605a7cdefe4e075c9f0310f257&amp;chksm=f3f9c5e2c48e4cf41bd3f708bce3f9a1302a699cf7defe611e9aea120fcb424944119e079362&amp;mpshare=1&amp;scene=1&amp;srcid=0525XIl8KXvHYvX42oaUcop0#rd" target="_blank" rel="noopener">https://mp.weixin.qq.com/s?__biz=MzI4NTA1MDEwNg==&amp;mid=2650763383&amp;idx=1&amp;sn=348a84605a7cdefe4e075c9f0310f257&amp;chksm=f3f9c5e2c48e4cf41bd3f708bce3f9a1302a699cf7defe611e9aea120fcb424944119e079362&amp;mpshare=1&amp;scene=1&amp;srcid=0525XIl8KXvHYvX42oaUcop0#rd</a></p>
<p><a href="https://blog.csdn.net/tonyxf121/article/details/8475603" target="_blank" rel="noopener">https://blog.csdn.net/tonyxf121/article/details/8475603</a></p>
<p><a href="http://heylinux.com/archives/1932.html" target="_blank" rel="noopener">http://heylinux.com/archives/1932.html</a></p>
<p><a href="https://www.m690.com/archives/380/" target="_blank" rel="noopener">https://www.m690.com/archives/380/</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.zengmanhua.cn/2019/06/14/redis内存模型/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jin Yu Bao">
      <meta itemprop="description" content="生活源于奋斗">
      <meta itemprop="image" content="http://prl6c63q7.bkt.clouddn.com/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JinYuBao">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/06/14/redis内存模型/" class="post-title-link" itemprop="url">redis内存模型</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-06-14 15:12:09" itemprop="dateCreated datePublished" datetime="2019-06-14T15:12:09+08:00">2019-06-14</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/technology/" itemprop="url" rel="index"><span itemprop="name">技术</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2019/06/14/redis内存模型/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/06/14/redis内存模型/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p><img src="http://47.103.200.134/image/p19.jpg" alt><br><strong>前言</strong></p>
<p>Redis是目前最火爆的内存数据库之一，通过在内存中读写数据，大大提高了读写速度，可以说Redis是实现网站高并发不可或缺的一部分。<br>
          <!--noindex-->
          
            <div class="post-button text-center">
              <a class="btn" href="/2019/06/14/redis内存模型/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          
          <!--/noindex-->
        
      
    </p></div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.zengmanhua.cn/2019/05/24/ThreadLocal及ThreadLocal内存溢出分析/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jin Yu Bao">
      <meta itemprop="description" content="生活源于奋斗">
      <meta itemprop="image" content="http://prl6c63q7.bkt.clouddn.com/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JinYuBao">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/05/24/ThreadLocal及ThreadLocal内存溢出分析/" class="post-title-link" itemprop="url">ThreadLocal及ThreadLocal内存溢出分析</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-24 13:21:05" itemprop="dateCreated datePublished" datetime="2019-05-24T13:21:05+08:00">2019-05-24</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/technology/" itemprop="url" rel="index"><span itemprop="name">技术</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2019/05/24/ThreadLocal及ThreadLocal内存溢出分析/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/05/24/ThreadLocal及ThreadLocal内存溢出分析/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p><img src="http://47.103.200.134/image/p15.jpg" alt></p>
<h3 id="ThreadLocal-定义，以及是否可能引起的内存泄露-threadlocalMap的Key是弱引用，用线程池有可能泄露"><a href="#ThreadLocal-定义，以及是否可能引起的内存泄露-threadlocalMap的Key是弱引用，用线程池有可能泄露" class="headerlink" title="ThreadLocal 定义，以及是否可能引起的内存泄露(threadlocalMap的Key是弱引用，用线程池有可能泄露)"></a>ThreadLocal 定义，以及是否可能引起的内存泄露(threadlocalMap的Key是弱引用，用线程池有可能泄露)</h3><p>ThreadLocal 也可以跟踪一个请求，从接收请求，处理请求，到返回请求，只要线程不销毁，就可以在线程的任何地方，调用这个参数，这是百度二面的题目，参考：<br>
          <!--noindex-->
          
            <div class="post-button text-center">
              <a class="btn" href="/2019/05/24/ThreadLocal及ThreadLocal内存溢出分析/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          
          <!--/noindex-->
        
      
    </p></div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.zengmanhua.cn/2019/05/24/内存溢出-栈溢出/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jin Yu Bao">
      <meta itemprop="description" content="生活源于奋斗">
      <meta itemprop="image" content="http://prl6c63q7.bkt.clouddn.com/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JinYuBao">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/05/24/内存溢出-栈溢出/" class="post-title-link" itemprop="url">内存溢出&&栈溢出</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-24 10:02:54" itemprop="dateCreated datePublished" datetime="2019-05-24T10:02:54+08:00">2019-05-24</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/technology/" itemprop="url" rel="index"><span itemprop="name">技术</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2019/05/24/内存溢出-栈溢出/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/05/24/内存溢出-栈溢出/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h3 id="内存溢出-amp-amp-栈溢出"><a href="#内存溢出-amp-amp-栈溢出" class="headerlink" title="内存溢出&amp;&amp;栈溢出"></a>内存溢出&amp;&amp;栈溢出</h3><p><img src="http://47.103.200.134/image/p5.jpg" alt></p>
<h4 id="内存溢出"><a href="#内存溢出" class="headerlink" title="内存溢出"></a>内存溢出</h4>
          <!--noindex-->
          
            <div class="post-button text-center">
              <a class="btn" href="/2019/05/24/内存溢出-栈溢出/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          
          <!--/noindex-->
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.zengmanhua.cn/2019/05/23/并发编程之线程安全性、安全发布对象/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jin Yu Bao">
      <meta itemprop="description" content="生活源于奋斗">
      <meta itemprop="image" content="http://prl6c63q7.bkt.clouddn.com/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JinYuBao">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/05/23/并发编程之线程安全性、安全发布对象/" class="post-title-link" itemprop="url">并发编程之线程安全性、安全发布对象</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-23 23:04:38" itemprop="dateCreated datePublished" datetime="2019-05-23T23:04:38+08:00">2019-05-23</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/technology/" itemprop="url" rel="index"><span itemprop="name">技术</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2019/05/23/并发编程之线程安全性、安全发布对象/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/05/23/并发编程之线程安全性、安全发布对象/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h3 id="线程安全性"><a href="#线程安全性" class="headerlink" title="线程安全性"></a>线程安全性</h3><p><img src="http://47.103.200.134/image/p6.jpg" alt><br>当多个线程访问某个类时，不管运行时环境采用何种调度方式或者这些进程将如何交替执行，并且在主调代码中不需要任何额外的同步或协调，这个类都能表现出正确的行为，那么就称这个类是线程安全的。<br>
          <!--noindex-->
          
            <div class="post-button text-center">
              <a class="btn" href="/2019/05/23/并发编程之线程安全性、安全发布对象/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          
          <!--/noindex-->
        
      
    </p></div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.zengmanhua.cn/2019/05/23/CPU缓存一致性协议MESI/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jin Yu Bao">
      <meta itemprop="description" content="生活源于奋斗">
      <meta itemprop="image" content="http://prl6c63q7.bkt.clouddn.com/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JinYuBao">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/05/23/CPU缓存一致性协议MESI/" class="post-title-link" itemprop="url">CPU缓存一致性协议MESI</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-23 11:40:52" itemprop="dateCreated datePublished" datetime="2019-05-23T11:40:52+08:00">2019-05-23</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/technology/" itemprop="url" rel="index"><span itemprop="name">技术</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2019/05/23/CPU缓存一致性协议MESI/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/05/23/CPU缓存一致性协议MESI/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p><img src="http://47.103.200.134/image/p3.jpg" alt="输入图片说明"></p>
<h3 id="CPU高速缓存（Cache-Memory）"><a href="#CPU高速缓存（Cache-Memory）" class="headerlink" title="CPU高速缓存（Cache Memory）"></a>CPU高速缓存（Cache Memory）</h3><h4 id="CPU为何要有高速缓存"><a href="#CPU为何要有高速缓存" class="headerlink" title="CPU为何要有高速缓存"></a>CPU为何要有高速缓存</h4><p>CPU在摩尔定律的指导下以每18个月翻一番的速度在发展，然而内存和硬盘的发展速度远远不及CPU。这就造成了高性能能的内存和硬盘价格及其昂贵。然而CPU的高度运算需要高速的数据。为了解决这个问题，CPU厂商在CPU中内置了少量的高速缓存以解决I\O速度和CPU运算速度之间的不匹配问题。</p>
          <!--noindex-->
          
            <div class="post-button text-center">
              <a class="btn" href="/2019/05/23/CPU缓存一致性协议MESI/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          
          <!--/noindex-->
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.zengmanhua.cn/2019/05/23/内存屏障/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jin Yu Bao">
      <meta itemprop="description" content="生活源于奋斗">
      <meta itemprop="image" content="http://prl6c63q7.bkt.clouddn.com/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JinYuBao">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/05/23/内存屏障/" class="post-title-link" itemprop="url">内存屏障</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-23 10:29:38" itemprop="dateCreated datePublished" datetime="2019-05-23T10:29:38+08:00">2019-05-23</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/technology/" itemprop="url" rel="index"><span itemprop="name">技术</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2019/05/23/内存屏障/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/05/23/内存屏障/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p><img src="http://47.103.200.134/image/p2.jpg" alt="输入图片说明"></p>
<h4 id="为什么会有内存屏障"><a href="#为什么会有内存屏障" class="headerlink" title="为什么会有内存屏障"></a>为什么会有内存屏障</h4><ul>
<li>每个CPU都会有自己的缓存（有的甚至L1,L2,L3），缓存的目的就是为了提高性能，避免每次都要向内存取。但是这样的弊端也很明显：不能实时的和内存发生信息交换，分在不同CPU执行的不同线程对同一个变量的缓存值不同。</li>
<li>用volatile关键字修饰变量可以解决上述问题，那么volatile是如何做到这一点的呢？那就是内存屏障，内存屏障是硬件层的概念，不同的硬件平台实现内存屏障的手段并不是一样，java通过屏蔽这些差异，统一由jvm来生成内存屏障的指令。
          <!--noindex-->
          
            <div class="post-button text-center">
              <a class="btn" href="/2019/05/23/内存屏障/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          
          <!--/noindex-->
        
      
    </li></ul></div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <div class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <a href="/">
              <img class="site-author-image" itemprop="image" src="http://prl6c63q7.bkt.clouddn.com/avatar.jpg" alt="Jin Yu Bao">
                </a>
            
              <p class="site-author-name" itemprop="name">Jin Yu Bao</p>
              <div class="site-description motion-element" itemprop="description">生活源于奋斗</div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">15</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                      <a href="/categories/">
                    
                  
                    
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">2</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                      <a href="/tags/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">4</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://github.com/jinyubao" title="GitHub &rarr; https://github.com/jinyubao" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="mailto:1345551624@qq.com" title="E-Mail &rarr; mailto:1345551624@qq.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                </span>
              
            </div>
          

          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-inline">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-globe"></i>
                -- 推荐浏览网址 --
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="https://www.github.com" title="https://www.github.com" rel="noopener" target="_blank">Github</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://www.zhihu.com" title="https://www.zhihu.com" rel="noopener" target="_blank">知乎</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://www.uisdc.com" title="http://www.uisdc.com" rel="noopener" target="_blank">优设</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://www.jianshu.com" title="https://www.jianshu.com" rel="noopener" target="_blank">简书</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://blog.csdn.net" title="https://blog.csdn.net" rel="noopener" target="_blank">CSDN</a>
                  </li>
                
              </ul>
              <div id="days"></div>
<script>
function show_date_time(){
window.setTimeout("show_date_time()", 1000);
BirthDay=new Date("05/18/2019 13:47:14");
today=new Date();
timeold=(today.getTime()-BirthDay.getTime());
sectimeold=timeold/1000
secondsold=Math.floor(sectimeold);
msPerDay=24*60*60*1000
e_daysold=timeold/msPerDay
daysold=Math.floor(e_daysold);
e_hrsold=(e_daysold-daysold)*24;
hrsold=setzero(Math.floor(e_hrsold));
e_minsold=(e_hrsold-hrsold)*60;
minsold=setzero(Math.floor((e_hrsold-hrsold)*60));
seconds=setzero(Math.floor((e_minsold-minsold)*60));
document.getElementById('days').innerHTML="已运行 "+daysold+" 天 "+hrsold+" 小时 "+minsold+" 分 "+seconds+" 秒";
}
function setzero(i){
if (i<10)
{i="0" + i};
return i;
}
show_date_time();
</script>

            </div>
          
          <iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="280" height="86" src="//music.163.com/outchain/player?type=2&id=455556558&auto=1&height=66"></iframe>
          
            
          
          <div id="days"></div>
<script>
function show_date_time(){
window.setTimeout("show_date_time()", 1000);
BirthDay=new Date("05/18/2019 13:47:14");
today=new Date();
timeold=(today.getTime()-BirthDay.getTime());
sectimeold=timeold/1000
secondsold=Math.floor(sectimeold);
msPerDay=24*60*60*1000
e_daysold=timeold/msPerDay
daysold=Math.floor(e_daysold);
e_hrsold=(e_daysold-daysold)*24;
hrsold=setzero(Math.floor(e_hrsold));
e_minsold=(e_hrsold-hrsold)*60;
minsold=setzero(Math.floor((e_hrsold-hrsold)*60));
seconds=setzero(Math.floor((e_minsold-minsold)*60));
document.getElementById('days').innerHTML="已运行 "+daysold+" 天 "+hrsold+" 小时 "+minsold+" 分 "+seconds+" 秒";
}
function setzero(i){
if (i<10)
{i="0" + i};
return i;
}
show_date_time();
</script>

        </div>
      </div>

      

      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script src="https://cdn.jsdelivr.net/npm/meting@1.1.0/dist/Meting.min.js"></script>
<div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Jin Yu Bao</span>

  

  
</div>









        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="post-meta-item-icon">
      <i class="fa fa-user"></i>
    </span>
    <span class="site-uv" title="总访客量">
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
    </span>
  

  
    <span class="post-meta-divider">|</span>
  

  
    <span class="post-meta-item-icon">
      <i class="fa fa-eye"></i>
    </span>
    <span class="site-pv" title="总访问量">
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
  
</div>









        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/utils.js?v=7.1.1"></script>

  <script src="/js/motion.js?v=7.1.1"></script>



  
  


  <script src="/js/affix.js?v=7.1.1"></script>

  <script src="/js/schemes/pisces.js?v=7.1.1"></script>




  

  


  <script src="/js/next-boot.js?v=7.1.1"></script>


  

  

  

  
  

<script src="//cdn1.lncld.net/static/js/3.11.1/av-min.js"></script>



<script src="//unpkg.com/valine/dist/Valine.min.js"></script>

<script>
  var GUEST = ['nick', 'mail', 'link'];
  var guest = 'nick,mail,link';
  guest = guest.split(',').filter(function(item) {
    return GUEST.indexOf(item) > -1;
  });
  new Valine({
    el: '#comments',
    verify: false,
    notify: false,
    appId: 'TRcVmXJ17nlU8oUlreTjl64y-gzGzoHsz',
    appKey: 'KTptYJdVQ4QJDnIEuFl9YVAv',
    placeholder: 'Just go go',
    avatar: 'wavatar',
    meta: guest,
    pageSize: '10' || 10,
    visitor: false,
    lang: '' || 'zh-cn'
  });
</script>





  
  <script>
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url).replace(/\/{2,}/g, '/');
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x"></i></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x"></i></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  

  

  
  <script>
    (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      bp.src = (curProtocol === 'https') ? 'https://zz.bdstatic.com/linksubmit/push.js' : 'http://push.zhanzhang.baidu.com/push.js';
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script>


  

  

  

  

  

  

  

  

</body>
</html>
