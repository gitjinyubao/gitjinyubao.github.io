<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F05%2F31%2Fhello-world%2F</url>
    <content type="text"><![CDATA[welcome here !]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>生活</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ThreadLocal及ThreadLocal内存溢出分析]]></title>
    <url>%2F2019%2F05%2F24%2FThreadLocal%E5%8F%8AThreadLocal%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[ThreadLocal 定义，以及是否可能引起的内存泄露(threadlocalMap的Key是弱引用，用线程池有可能泄露)ThreadLocal 也可以跟踪一个请求，从接收请求，处理请求，到返回请求，只要线程不销毁，就可以在线程的任何地方，调用这个参数，这是百度二面的题目，参考：1Threadlocal 传递参数(百度二面) ： https://www.cnblogs.com/aspirant/p/9183920.html 12345总结：1. JVM利用设置ThreadLocalMap的Key为弱引用，来避免内存泄露。2. JVM利用调用remove、get、set方法的时候，回收弱引用。3. 当ThreadLocal存储很多Key为null的Entry的时候，而不再去调用remove、get、set方法，那么将导致内存泄漏。4. 当使用static ThreadLocal的时候，延长ThreadLocal的生命周期，那也可能导致内存泄漏。因为，static变量在类未加载的时候，它就已经加载，当线程结束的时候，static变量不一定会回收。那么，比起普通成员变量使用的时候才加载，static的生命周期加长将更容易导致内存泄漏危机。http://www.importnew.com/22039.html 那么如何有效的避免呢？ 事实上，在ThreadLocalMap中的set/getEntry方法中，会对key为null（也即是ThreadLocal为null）进行判断，如果为null的话，那么是会对value置为null的。我们也可以通过调用ThreadLocal的remove方法进行释放！ threadlocal里面使用了一个存在弱引用的map,当释放掉threadlocal的强引用以后,map里面的value却没有被回收.而这块value永远不会被访问到了. 所以存在着内存泄露. 最好的做法是将调用threadlocal的remove方法. 在threadlocal的生命周期中,都存在这些引用. 看下图: 实线代表强引用,虚线代表弱引用.每个thread中都存在一个map, map的类型是ThreadLocal.ThreadLocalMap. Map中的key为一个threadlocal实例. 这个Map的确使用了弱引用,不过弱引用只是针对key. 每个key都弱引用指向threadlocal. 当把threadlocal实例置为null以后,没有任何强引用指向threadlocal实例,所以threadlocal将会被gc回收. 但是,我们的value却不能回收,因为存在一条从current thread连接过来的强引用. 只有当前thread结束以后, current thread就不会存在栈中,强引用断开, Current Thread, Map, value将全部被GC回收. 所以得出一个结论就是只要这个线程对象被gc回收，就不会出现内存泄露，但在threadLocal设为null和线程结束这段时间不会被回收的，就发生了我们认为的内存泄露.其实这是一个对概念理解的不一致，也没什么好争论的。最要命的是线程对象不被回收的情况，这就发生了真正意义上的内存泄露。比如使用线程池的时候，线程结束是不会销毁的，会再次使用的。就可能出现内存泄露。 PS.Java为了最小化减少内存泄露的可能性和影响，在ThreadLocal的get,set的时候都会清除线程Map里所有key为null的value。所以最怕的情况就是，threadLocal对象设null了，开始发生“内存泄露”，然后使用线程池，这个线程结束，线程放回线程池中不销毁，这个线程一直不被使用，或者分配使用了又不再调用get,set方法，那么这个期间就会发生真正的内存泄露。 应用场景最常见的ThreadLocal使用场景为 用来解决 数据库连接、Session管理等。如1234567891011121314151617181920212223private static ThreadLocal &lt; Connection &gt; connectionHolder = new ThreadLocal &lt; Connection &gt; () &#123; public Connection initialValue() &#123; return DriverManager.getConnection(DB_URL); &#125;&#125;;public static Connection getConnection() &#123; return connectionHolder.get();&#125;private static final ThreadLocal threadSession = new ThreadLocal();public static Session getSession() throws InfrastructureException &#123; Session s = (Session) threadSession.get(); try &#123; if (s == null) &#123; s = getSessionFactory().openSession(); threadSession.set(s); &#125; &#125; catch (HibernateException ex) &#123; throw new InfrastructureException(ex); &#125; return s;&#125; ThreadLocal是什么？有什么用？引入话题：在并发条件下，如何正确获得共享数据？举例：假设有多个用户需要获取用户信息，一个线程对应一个用户。在mybatis中，session用于操作数据库，那么设置、获取操作分别是session.set()、session.get()，如何保证每个线程都能正确操作达到想要的结果？ 12345678910111213141516171819202122232425262728293031323334/** * 回顾synchronized在多线程共享线程的问题 * @author qiuyongAaron */public class ThreadLocalOne &#123; volatile Person person=new Person(); public synchronized String setAndGet(String name)&#123; //System.out.print(Thread.currentThread().getName()+":"); person.name=name; //模拟网络延迟 try &#123; TimeUnit.SECONDS.sleep(2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return person.name; &#125; public static void main(String[] args) &#123; ThreadLocalOne threadLocal=new ThreadLocalOne(); new Thread(()-&gt;System.out.println(threadLocal.setAndGet("arron")),"t1").start(); new Thread(()-&gt;System.out.println(threadLocal.setAndGet("tony")),"t2").start(); &#125;&#125; class Person&#123; String name="tom"; public Person(String name) &#123; this.name=name; &#125; public Person()&#123;&#125;&#125; 12345678运行结果：无synchronized：t1:tonyt2:tony 有synchronized：t1:arront2:tony 步骤分析:1. 无synchronized的时候，因为非原子操作，显然不是预想结果，可参考我关于synchronized的讨论。 2. 现在，我们的需求是：每个线程独立的设置获取person信息，不被线程打扰。 3. 因为，person是共享数据，用同步互斥锁synchronized，当一个线程访问共享数据的时候，其他线程堵塞，不再多余赘述。 通过举例问题，可能大家又会很疑惑？mybatis、hibernate是如何实现的呢？synchronized不会很消耗资源，当成千上万个操作的时候，承受并发不说，数据返回延迟如何确保用户体验？ ThreadLocal是什么？有什么用？ 12345678910111213141516171819202122/** * 谈谈ThreadLocal的作用 * @author qiuyongAaron */public class ThreadLocalThree &#123; ThreadLocal&lt;Person&gt; threadLocal=new ThreadLocal&lt;Person&gt;(); public String setAndGet(String name)&#123; threadLocal.set(new Person(name)); try &#123; TimeUnit.SECONDS.sleep(2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return threadLocal.get().name; &#125; public static void main(String[] args) &#123; ThreadLocalThree threadLocal=new ThreadLocalThree(); new Thread(()-&gt;System.out.println("t1:"+threadLocal.setAndGet("arron")),"t1").start(); new Thread(()-&gt;System.out.println("t2:"+threadLocal.setAndGet("tony")),"t2").start(); &#125;&#125; 123运行结果：t1:arront2:tony 分析：1、根据预期结果，那ThreadLocal到底是什么？回顾Java内存模型： 在虚拟机中，堆内存用于存储共享数据（实例对象），堆内存也就是这里说的主内存。 每个线程将会在堆内存中开辟一块空间叫做线程的工作内存，附带一块缓存区用于存储共享数据副本。那么，共享数据在堆内存当中，线程通信就是通过主内存为中介，线程在本地内存读并且操作完共享变量操作完毕以后，把值写入主内存。 1. ThreadLocal被称为线程局部变量，说白了，他就是线程工作内存的一小块内存，用于存储数据。 2. 那么，ThreadLocal.set()、ThreadLocal.get()方法，就相当于把数据存储于线程本地，取也是在本地内存读取。就不会像synchronized需要频繁的修改主内存的数据，再把数据复制到工作内存，也大大提高访问效率。 2、ThreadLocal到底有什么用？ 1. 回到最开始的举例，也就等价于mabatis、hibernate为什么要使用threadlocal来存储session？ 2. 作用一：因为线程间的数据交互是通过工作内存与主存的频繁读写完成通信，然而存储于线程本地内存，提高访问效率，避免线程阻塞造成cpu吞吐率下降。 3. 作用二：在多线程中，每一个线程都需要维护session，轻易完成对线程独享资源的操作。 总结： Threadlocal是什么？在堆内存中，每个线程对应一块工作内存，threadlocal就是工作内存的一小块内存。 Threadlocal有什么用？threadlocal用于存取线程独享数据，提高访问效率。 ThreadLocal源码简要总结？那有同学可能还是有点云里雾里，感觉还是没有吃透？那线程内部如何去保证线程独享数据呢？在这里，我只做简要总结，若有兴趣，可参考文章尾部的文章链接。重点看get、set方法。12345678public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); &#125; 分析 一个线程对应一个ThreadLocalMap ，可以存储多个ThreadLocal对象。 ThreadLocal对象作为key、独享数据作为value。 ThreadLocalMap可参考HashMap，在ThreadMap里面存在Entry数组也就是一个Entry一个键值对。 12345678910111213public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(&quot;unchecked&quot;) T result = (T)e.value; return result; &#125; &#125; return setInitialValue(); &#125; 分析 一个线程对应一个ThreadLocalMap，get()就是当前线程获取自己的ThreadLocalMap。 线程根据使用那一小块的threadlocal，根据ThreadLocal对象作为key，去获取存储于ThreadLocalMap中的值。 总结回顾一下，我们在单线程中如何使用HashMap的？hashMap根据数组+链表来实现HashMap，一个key对应一个value。那么，我们抽象一下，Threadlocal也相当于在多线程中的一种HashMap用法，相当于对ThradLocal的操作也就如单线程操作一样。总之，ThreadLocal就是堆内存的一块小内存，它用ThreadLocalMap维护ThreadLocal对象作为key，独享数据作为value的东西。 ThreadLocal为什么会导致内存泄漏？synchronized是用时间换空间(牺牲时间)、ThreadLocal是用空间换时间(牺牲空间)，为什么这么说？因为synchronized操作数据，只需要在主存存一个变量即可，就阻塞等共享变量，而ThreadLocal是每个线程都创建一块小的堆工作内存。显然，印证了上面的说法。 一个线程对应一块工作内存，线程可以存储多个ThreadLocal。那么假设，开启1万个线程，每个线程创建1万个ThreadLocal，也就是每个线程维护1万个ThreadLocal小内存空间，而且当线程执行结束以后，假设这些ThreadLocal里的Entry还不会被回收，那么将很容易导致堆内存溢出。 怎么办？难道JVM就没有提供什么解决方案吗？ThreadLocal当然有想到，所以他们把ThreadLocal里的Entry设置为弱引用，当垃圾回收的时候，回收ThreadLocal。什么是弱引用？ Key使用强引用：也就是上述说的情况，引用ThreadLocal的对象被回收了，ThreadLocal的引用ThreadLocalMap的Key为强引用并没有被回收，如果不手动回收的话，ThreadLocal将不会回收那么将导致内存泄漏。 Key使用弱引用：引用的ThreadLocal的对象被回收了，ThreadLocal的引用ThreadLocalMap的Key为弱引用，如果内存回收，那么将ThreadLocalMap的Key将会被回收，ThreadLocal也将被回收。value在ThreadLocalMap调用get、set、remove的时候就会被清除。 比较两种情况，我们可以发现：由于ThreadLocalMap的生命周期跟Thread一样长，如果都没有手动删除对应key，都会导致内存泄漏，但是使用弱引用可以多一层保障：弱引用ThreadLocal不会内存泄漏，对应的value在下一次ThreadLocalMap调用set,get,remove的时候会被清除。 那按你这么说，既然JVM有保障了，还有什么内存泄漏可言？ThreadLocalMap使用ThreadLocal对象作为弱引用，当垃圾回收的时候，ThreadLocalMap中Key将会被回收，也就是将Key设置为null的Entry。如果线程迟迟无法结束，也就是ThreadLocal对象将一直不会回收，回顾到上面存在很多线程+TheradLocal，那么也将导致内存泄漏。(内存泄露的重点) 其实，在ThreadLocal中，当调用remove、get、set方法的时候，会清除为null的弱引用，也就是回收ThreadLocal。 1ThreadLocal提供一个线程（Thread）局部变量，访问到某个变量的每一个线程都拥有自己的局部变量。说白了，ThreadLocal就是想在多线程环境下去保证成员变量的安全。 ThreadLocal提供的方法ThreadLocal API1对于ThreadLocal而言，常用的方法，就是get/set/initialValue方法。 我们先来看一个例子运行结果是你想象中的结果么？很显然，在这里，并没有通过ThreadLocal达到线程隔离的机制，可是ThreadLocal不是保证线程安全的么？这是什么鬼？虽然，ThreadLocal让访问某个变量的线程都拥有自己的局部变量，但是如果这个局部变量都指向同一个对象呢？这个时候ThreadLocal就失效了。仔细观察下图中的代码，你会发现，threadLocal在初始化时返回的都是同一个对象a！ 看一看ThreadLocal源码我们直接看最常用的set操作：set线程局部变量createMap 你会看到，set需要首先获得当前线程对象Thread； 然后取出当前线程对象的成员变量ThreadLocalMap； 如果ThreadLocalMap存在，那么进行KEY/VALUE设置，KEY就是ThreadLocal； 如果ThreadLocalMap没有，那么创建一个； 说白了，当前线程中存在一个Map变量，KEY是ThreadLocal，VALUE是你设置的值。 看一下get操作：get1这里其实揭示了ThreadLocalMap里面的数据存储结构，从上面的代码来看，ThreadLocalMap中存放的就是Entry，Entry的KEY就是ThreadLocal，VALUE就是值 ThreadLocalMap.Entry：弱引用？在JAVA里面，存在强引用、弱引用、软引用、虚引用。这里主要谈一下强引用和弱引用。强引用，就不必说了，类似于： A a = new A(); B b = new B(); 考虑这样的情况： C c = new C(b); b = null; 考虑下GC的情况。要知道b被置为null，那么是否意味着一段时间后GC工作可以回收b所分配的内存空间呢？答案是否定的，因为即便b被置为null，但是c仍然持有对b的引用，而且还是强引用，所以GC不会回收b原先所分配的空间！既不能回收利用，又不能使用，这就造成了内存泄露。那么如何处理呢？ 可以c = null;也可以使用弱引用！（WeakReference w = new WeakReference(b);） 分析到这里，我们可以得到：内存结构图这里我们思考一个问题：ThreadLocal使用到了弱引用，是否意味着不会存在内存泄露呢？ 首先来说，如果把ThreadLocal置为null，那么意味着Heap中的ThreadLocal实例不在有强引用指向，只有弱引用存在，因此GC是可以回收这部分空间的，也就是key是可以回收的。但是value却存在一条从Current Thread过来的强引用链。因此只有当Current Thread销毁时，value才能得到释放。 因此，只要这个线程对象被gc回收，就不会出现内存泄露，但在threadLocal设为null和线程结束这段时间内不会被回收的，就发生了我们认为的内存泄露。最要命的是线程对象不被回收的情况，比如使用线程池的时候，线程结束是不会销毁的，再次使用的，就可能出现内存泄露。 那么如何有效的避免呢？ 事实上，在ThreadLocalMap中的set/getEntry方法中，会对key为null（也即是ThreadLocal为null）进行判断，如果为null的话，那么是会对value置为null的。我们也可以通过调用ThreadLocal的remove方法进行释放！ 1来源：https://www.cnblogs.com/aspirant/p/8991010.html]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java并发系统学习番外篇</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[内存溢出&&栈溢出]]></title>
    <url>%2F2019%2F05%2F24%2F%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA-%E6%A0%88%E6%BA%A2%E5%87%BA%2F</url>
    <content type="text"><![CDATA[内存溢出&amp;&amp;栈溢出 内存溢出 内存溢出的原因是什么？内存溢出是由于没被引用的对象（垃圾）过多造成JVM没有及时回收，造成的内存溢出。如果出现这种现象可行代码排查： 是否应用中的类中和引用变量过多使用了Static修饰 如public staitc Student s；在类中的属性中使用 static修饰的最好只用基本类型或字符串。如public static int i = 0; //public static String str; 是否 应用 中使用了大量的递归或无限递归（递归中用到了大量的建新的对象） 是否App中使用了大量循环或死循环（循环中用到了大量的新建的对象） 检查 应用 中是否使用了向数据库查询所有记录的方法。即一次性全部查询的方法，如果数据量超过10万多条了，就可能会造成内存溢出。所以在查询时应采用“分页查询”。 检查是否有数组，List，Map中存放的是对象的引用而不是对象，因为这些引用会让对应的对象不能被释放。会大量存储在内存中。 检查是否使用了“非字面量字符串进行+”的操作。因为String类的内容是不可变的，每次运行”+”就会产生新的对象，如果过多会造成新String对象过多，从而导致JVM没有及时回收而出现内存溢出。 1234567891011如String s1 = &quot;My name&quot;;String s2 = &quot;is&quot;;String s3 = &quot;xuwei&quot;;String str = s1 + s2 + s3 +.........;这是会容易造成内存溢出的但是String str = &quot;My name&quot; + &quot; is &quot; + &quot; xuwei&quot; + &quot; nice &quot; + &quot; to &quot; + &quot; meet you&quot;; //但是这种就不会造成内存溢出。因为这是”字面量字符串“，在运行&quot;+&quot;时就会在编译期间运行好。不会按照JVM来执行的。在使用String,StringBuffer,StringBuilder时，如果是字面量字符串进行&quot;+&quot;时，应选用String性能更好；如果是String类进行&quot;+&quot;时，在不考虑线程安全时，应选用StringBuilder性能更好。 12345678910111213141516171819public class Test &#123; public void testHeap()&#123; for(;;)&#123; //死循环一直创建对象，堆溢出 ArrayList list = new ArrayList (2000); &#125; &#125; int num=1; public void testStack()&#123; //无出口的递归调用，栈溢出 num++; this.testStack(); &#125; public static void main(String[] args)&#123; Test t = new Test (); t.testHeap(); t.testStack(); &#125; &#125; 栈溢出的原因 是否有递归调用 是否有大量循环或死循环 全局变量是否过多 数组、List、map数据是否过大 使用DDMS工具进行查找大概出现栈溢出的位置 JVM系列之实战内存溢出异常对象的创建过程关于对象的创建，第一反应是new关键字，那么本文就主要讲解new关键字创建对象的过程。1Student stu =new Student(&quot;张三&quot;，&quot;18&quot;); 就拿上面这句代码来说，虚拟机首先会去检查Student这个类有没有被加载，如果没有，首先去加载这个类到方法区，然后根据加载的Class类对象创建stu实例对象，需要注意的是，stu对象所需的内存大小在Student类加载完成后便可完全确定。内存分配完成后，虚拟机需要将分配到的内存空间的实例数据部分初始化为零值,这也就是为什么我们在编写Java代码时创建一个变量不需要初始化。紧接着，虚拟机会对对象的对象头进行必要的设置，如这个对象属于哪个类，如何找到类的元数据(Class对象),对象的锁信息，GC分代年龄等。设置完对象头信息后，调用类的构造函数。其实讲实话，虚拟机创建对象的过程远不止这么简单，我这里只是把大致的脉络讲解了一下，方便大家理解。 对象的内存布局刚刚提到的实例数据，对象头，有些小伙伴也许有点陌生，这一小节就详细讲解一下对象的内存布局,对象创建完成后大致可以分为以下几个部分: 对象头 实例数据 对齐填充 对象头 : 对象头中包含了对象运行时一些必要的信息，如GC分代信息，锁信息，哈希码，指向Class类元信息的指针等，其中对Javaer比较有用的是锁信息与指向Class对象的指针，关于锁信息，后期有机会讲解并发编程JUC时再扩展，关于指向Class对象的指针其实很好理解。比如上面那个Student的例子，当我们拿到stu对象时，调用Class stuClass=stu.getClass();的时候，其实就是根据这个指针去拿到了stu对象所属的Student类在方法区存放的Class类对象。虽然说的有点拗口，但这句话我反复琢磨了好几遍，应该是说清楚了。^_^ 实例数据 :实例数据部分是对象真正存储的有效信息，就是程序代码中所定义的各种类型的字段内容。 对齐填充 :虚拟机规范要求对象大小必须是8字节的整数倍。对齐填充其实就是来补全对象大小的。 对象的访问定位谈到对象的访问，还拿上面学生的例子来说，当我们拿到stu对象时，直接调用stu.getName();时，其实就完成了对对象的访问。但这里要累赘说一下的是，stu虽然通常被认为是一个对象，其实准确来说是不准确的，stu只是一个变量，变量里存储的是指向对象的指针，(如果干过C或者C++的小伙伴应该比较清楚指针这个概念)，当我们调用stu.getName()时，虚拟机会根据指针找到堆里面的对象然后拿到实例数据name.需要注意的是，当我们调用stu.getClass()时，虚拟机会首先根据stu指针定位到堆里面的对象，然后根据对象头里面存储的指向Class类元信息的指针再次到方法区拿到Class对象，进行了两次指针寻找。具体讲解图如下: 实战内存异常内存异常是我们工作当中经常会遇到问题，但如果仅仅会通过加大内存参数来解决问题显然是不够的，应该通过一定的手段定位问题，到底是因为参数问题，还是程序问题(无限创建，内存泄露)。定位问题后才能采取合适的解决方案，而不是一内存溢出就查找相关参数加大。 123概念- 内存泄露:代码中的某个对象本应该被虚拟机回收，但因为拥有GCRoot引用而没有被回收。关于GCRoot概念，下一篇文章讲解。- 内存溢出: 虚拟机由于堆中拥有太多不可回收对象没有回收，导致无法继续创建新对象。 在分析问题之前先给大家讲一讲排查内存溢出问题的方法，内存溢出时JVM虚拟机会退出，那么我们怎么知道JVM运行时的各种信息呢，Dump机制会帮助我们，可以通过加上VM参数-XX:+HeapDumpOnOutOfMemoryError让虚拟机在出现内存溢出异常时生成dump文件，然后通过外部工具(作者使用的是VisualVM)来具体分析异常的原因。 下面从以下几个方面来配合代码实战演示内存溢出及如何定位: Java堆内存异常 Java栈内存异常 方法区内存异常 Java堆内存异常12345678910111213/** VM Args: //这两个参数保证了堆中的可分配内存固定为20M -Xms20m -Xmx20m //文件生成的位置，作则生成在桌面的一个目录 -XX:+HeapDumpOnOutOfMemoryError //文件生成的位置，作则生成在桌面的一个目录 //文件生成的位置，作则生成在桌面的一个目录 -XX:HeapDumpPath=/Users/zdy/Desktop/dump/ */public class HeapOOM &#123; //创建一个内部类用于创建对象使用 static class OOMObject &#123; &#125; public static void main(String[] args) &#123; List&lt;OOMObject&gt; list = new ArrayList&lt;OOMObject&gt;(); //无限创建对象，在堆中 while (true) &#123; list.add(new OOMObject()); &#125; &#125;&#125; Run起来代码后爆出异常如下: java.lang.OutOfMemoryError: Java heap spaceDumping heap to /Users/zdy/Desktop/dump/java_pid1099.hprof … 可以看到生成了dump文件到指定目录。并且爆出了OutOfMemoryError，还告诉了你是哪一片区域出的问题:heap space 打开VisualVM工具导入对应的heapDump文件(如何使用请读者自行查阅相关资料)，相应的说明见图:“类标签” 切换到”实例数”标签页“实例数标签” 分析dump文件后，我们可以知道，OOMObject这个类创建了810326个实例。所以它能不溢出吗？接下来就在代码里找这个类在哪new的。排查问题。(我们的样例代码就不用排查了，While循环太凶猛了) Java栈内存异常老实说，在栈中出现异常(StackOverFlowError)的概率小到和去苹果专卖店买手机，买回来后发现是Android系统的概率是一样的。因为作者确实没有在生产环境中遇到过，除了自己作死写样例代码测试。先说一下异常出现的情况，前面讲到过，方法调用的过程就是方法帧进虚拟机栈和出虚拟机栈的过程，那么有两种情况可以导致StackOverFlowError,当一个方法帧(比如需要2M内存)进入到虚拟机栈(比如还剩下1M内存)的时候，就会报出StackOverFlow.这里先说一个概念，栈深度:指目前虚拟机栈中没有出栈的方法帧。虚拟机栈容量通过参数-Xss来控制,下面通过一段代码，把栈容量人为的调小一点，然后通过递归调用触发异常。 12345678910111213141516171819/** * VM Args： //设置栈容量为160K，默认1M -Xss160k */public class JavaVMStackSOF &#123; private int stackLength = 1; public void stackLeak() &#123; stackLength++; //递归调用，触发异常 stackLeak(); &#125; public static void main(String[] args) throws Throwable &#123; JavaVMStackSOF oom = new JavaVMStackSOF(); try &#123; oom.stackLeak(); &#125; catch (Throwable e) &#123; System.out.println("stack length:" + oom.stackLength); throw e; &#125; &#125;&#125; 结果如下:stack length:751Exception in thread “main” java.lang.StackOverflowError 可以看到，递归调用了751次，栈容量不够用了。默认的栈容量在正常的方法调用时，栈深度可以达到1000-2000深度，所以，一般的递归是可以承受的住的。如果你的代码出现了StackOverflowError，首先检查代码，而不是改参数。 这里顺带提一下，很多人在做多线程开发时，当创建很多线程时，容易出现OOM(OutOfMemoryError),这时可以通过具体情况，减少最大堆容量，或者栈容量来解决问题，这是为什么呢。请看下面的公式: 线程数 乘以 (最大栈容量)+最大堆值+其他内存(忽略不计或者一般不改动)=机器最大内存 当线程数比较多时，且无法通过业务上削减线程数，那么再不换机器的情况下，你只能把最大栈容量设置小一点，或者把最大堆值设置小一点。 方法区内存异常写到这里时，作者本来想写一个无限创建动态代理对象的例子来演示方法区溢出，避开谈论JDK7与JDK8的内存区域变更的过渡，但细想一想，还是把这一块从始致终的说清楚。在上一篇文章中JVM系列之Java内存结构详解讲到方法区时提到，JDK7环境下方法区包括了(运行时常量池),其实这么说是不准确的。因为从JDK7开始，HotSpot团队就想到开始去”永久代”,大家首先明确一个概念，方法区和”永久代”(PermGen space)是两个概念，方法区是JVM虚拟机规范，任何虚拟机实现(J9等)都不能少这个区间，而”永久代”只是HotSpot对方法区的一个实现。为了把知识点列清楚，我还是才用列表的形式: JDK7之前(包括JDK7)拥有”永久代”(PermGen space),用来实现方法区。但在JDK7中已经逐渐在实现中把永久代中把很多东西移了出来，比如:符号引用(Symbols)转移到了native heap,运行时常量池(interned strings)转移到了java heap；类的静态变量(class statics)转移到了java heap.所以这就是为什么我说上一篇文章中说方法区中包含运行时常量池是不正确的，因为已经移动到了java heap; 在JDK7之前(包括7)可以通过-XX:PermSize -XX:MaxPermSize来控制永久代的大小. JDK8正式去除”永久代”,换成Metaspace(元空间)作为JVM虚拟机规范中方法区的实现。 元空间与永久代之间最大的区别在于：元空间并不在虚拟机中，而是使用本地内存。因此，默认情况下，元空间的大小仅受本地内存限制，但仍可以通过参数控制:-XX:MetaspaceSize与-XX:MaxMetaspaceSize来控制大小。 下面作者还是通过一段代码，来不停的创建Class对象，在JDK8中可以看到metaSpace内存溢出:1234567891011121314151617181920/** 作者准备在JDK8下测试方法区，所以设置了Metaspace的大小为固定的8M -XX:MetaspaceSize=8m -XX:MaxMetaspaceSize=8m */public class JavaMethodAreaOOM &#123; public static void main(String[] args) &#123; while (true) &#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(OOMObject.class); enhancer.setUseCache(false); enhancer.setCallback(new MethodInterceptor() &#123; public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable &#123; return proxy.invokeSuper(obj, args); &#125; &#125;); //无限创建动态代理，生成Class对象 enhancer.create(); &#125; &#125; static class OOMObject &#123; &#125;&#125; 在JDK8的环境下将报出异常:Exception in thread “main” java.lang.OutOfMemoryError: Metaspace这是因为在调用CGLib的创建代理时会生成动态代理类，即Class对象到Metaspace,所以While一下就出异常了。提醒一下:虽然我们日常叫”堆Dump”,但是dump技术不仅仅是对于”堆”区域才有效，而是针对OOM的，也就是说不管什么区域，凡是能够报出OOM错误的，都可以使用dump技术生成dump文件来分析。 在经常动态生成大量Class的应用中，需要特别注意类的回收状况，这类场景除了例子中的CGLib技术，常见的还有，大量JSP，反射，OSGI等。需要特别注意，当出现此类异常，应该知道是哪里出了问题，然后看是调整参数，还是在代码层面优化。 附加-直接内存异常直接内存异常非常少见，而且机制很特殊，因为直接内存不是直接向操作系统分配内存，而且通过计算得到的内存不够而手动抛出异常，所以当你发现你的dump文件很小，而且没有明显异常，只是告诉你OOM，你就可以考虑下你代码里面是不是直接或者间接使用了NIO而导致直接内存溢出。 1来源：https://my.oschina.net/u/2401092/blog/1621850]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java并发系统学习番外篇</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并发编程之线程安全性、安全发布对象]]></title>
    <url>%2F2019%2F05%2F23%2F%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E6%80%A7%E3%80%81%E5%AE%89%E5%85%A8%E5%8F%91%E5%B8%83%E5%AF%B9%E8%B1%A1%2F</url>
    <content type="text"><![CDATA[线程安全性当多个线程访问某个类时，不管运行时环境采用何种调度方式或者这些进程将如何交替执行，并且在主调代码中不需要任何额外的同步或协调，这个类都能表现出正确的行为，那么就称这个类是线程安全的。线程安全性主要体现： 原子性：提供了互斥访问，同一时刻只能有一个线程来对它进行操作 可见性：一个线程对主内存的修改可以及时的被其他线程观察到 有序性：一个线程观察其他线程中的指令执行顺序，由于指令重排序的存在，该观察结果一般是杂乱无序 原子性Atomic包位于java.util.concurrent.atomicAtomicXXX : CAS、Unsafe.compareAndSwapXXX CAS（Compare and swap）比较和替换是设计并发算法时用到的一种技术。简单来说，比较和替换是使用一个期望值和一个变量的当前值进行比较，如果当前变量的值与我们期望的值相等，就使用一个新值替换当前变量的值。 AtomicInteger123456789101112131415161718192021222324252627282930313233343536373839@Slf4j@ThreadSafepublic class CountExample2 &#123; // 请求总数 public static int clientTotal = 5000; // 同时并发执行的线程数 public static int threadTotal = 200; //从int类型换成了AtomicInteger public static AtomicInteger count = new AtomicInteger(0); public static void main(String[] args) throws Exception &#123; ExecutorService executorService = Executors.newCachedThreadPool(); final Semaphore semaphore = new Semaphore(threadTotal); final CountDownLatch countDownLatch = new CountDownLatch(clientTotal); for (int i = 0; i &lt; clientTotal ; i++) &#123; executorService.execute(() -&gt; &#123; try &#123; semaphore.acquire(); add(); semaphore.release(); &#125; catch (Exception e) &#123; log.error(&quot;exception&quot;, e); &#125; countDownLatch.countDown(); &#125;); &#125; countDownLatch.await(); executorService.shutdown(); log.info(&quot;count:&#123;&#125;&quot;, count.get()); &#125; private static void add() &#123; //调用了AtomicInteger方法 count.incrementAndGet(); // count.getAndIncrement(); &#125;&#125; 线程安全？源码分析AtomicInteger.java1234567891011121314151617private static final long serialVersionUID = 6214790243416807050L;// setup to use Unsafe.compareAndSwapInt for updatesprivate static final Unsafe unsafe = Unsafe.getUnsafe(); //通过反射获得private static final long valueOffset;static &#123; try &#123; valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField(&quot;value&quot;)); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125;&#125;private volatile int value;public final int incrementAndGet() &#123; //this 代表当前AtomicInteger对象 return unsafe.getAndAddInt(this, valueOffset, 1) + 1;&#125; Unsafe.java 123456789101112131415161718192021222324//本地方法，java底层方法/** * @param var1 对象 * @param var2 偏移量 * @param var3 期望值 * @param var5 修改值 */ public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5);/** * @param var1 当前对象 * @param var2 当前值 * @param var3 增量 */public final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; //底层值 do &#123; var5 = this.getIntVolatile(var1, var2); &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); // CAS核心 //当前值与底层值相同，则更新成var5 + var4 //不一样则不停的循环，直到值相同 return var5; &#125; AtomicInLong 与 LongAdder 1234567891011121314151617181920212223242526272829303132333435363738@Slf4j@ThreadSafepublic class AtomicExample2 &#123; // 请求总数 public static int clientTotal = 5000; // 同时并发执行的线程数 public static int threadTotal = 200; public static AtomicLong count = new AtomicLong(0); public static void main(String[] args) throws Exception &#123; ExecutorService executorService = Executors.newCachedThreadPool(); final Semaphore semaphore = new Semaphore(threadTotal); final CountDownLatch countDownLatch = new CountDownLatch(clientTotal); for (int i = 0; i &lt; clientTotal ; i++) &#123; executorService.execute(() -&gt; &#123; try &#123; semaphore.acquire(); add(); semaphore.release(); &#125; catch (Exception e) &#123; log.error(&quot;exception&quot;, e); &#125; countDownLatch.countDown(); &#125;); &#125; countDownLatch.await(); executorService.shutdown(); log.info(&quot;count:&#123;&#125;&quot;, count.get()); &#125; private static void add() &#123; count.incrementAndGet(); // count.getAndIncrement(); &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637@Slf4j@ThreadSafepublic class AtomicExample3 &#123; // 请求总数 public static int clientTotal = 5000; // 同时并发执行的线程数 public static int threadTotal = 200; public static LongAdder count = new LongAdder(); public static void main(String[] args) throws Exception &#123; ExecutorService executorService = Executors.newCachedThreadPool(); final Semaphore semaphore = new Semaphore(threadTotal); final CountDownLatch countDownLatch = new CountDownLatch(clientTotal); for (int i = 0; i &lt; clientTotal ; i++) &#123; executorService.execute(() -&gt; &#123; try &#123; semaphore.acquire(); add(); semaphore.release(); &#125; catch (Exception e) &#123; log.error(&quot;exception&quot;, e); &#125; countDownLatch.countDown(); &#125;); &#125; countDownLatch.await(); executorService.shutdown(); log.info(&quot;count:&#123;&#125;&quot;, count); &#125; private static void add() &#123; count.increment(); &#125;&#125; AtomicInLong 与 LongAdder 比较就像我们所知道的那样,AtomicLong的原理是依靠底层的cas来保障原子性的更新数据，在要添加或者减少的时候，会使用死循环不断地cas到特定的值，从而达到更新数据的目的。如果竞争不激烈，修改成功几率很高，否则失败概率很高，在失败几率很高的情况下，这些原子操作就会进行多次的循环操作尝试，因此性能会受到影响。 对于普通类型的Long和Doubble变量，JVM允许将64位的读操作或写操作拆成两个三十二位的操作。 LongAdder的核心是将热点数据分离，比如说它可以将AtomicLong内部核心数据value分离成一个数组，每个线程访问时，通过hash等算法，映射到其中一个数字进行计数，最终的计数结果则会这个数据的求和累加，其中热点数据value会被分离成多个cell，每个cell独自维护内部的值，当前对象实际值为所有cell累计合成，这样的话，热点就进行了有效的分离，并提高了并行度。 LongAdder在AtomicLong的基础上将单点的更新压力分散到各个节点，在低并发的时候通过对base的直接更新可以很好的保障和AtomicLong的性能基本保持一致，而在高并发的时候通过分散提高了性能。 ​缺点是LongAdder在统计的时候如果有并发更新，可能导致统计的数据有误差。 ​实际使用中，在处理高并发时，可以优先使用LongAdder，而不是继续使用AtomicLong，当然，在线程竞争很低的情况下，使用AtomicLong更简单更实际一些，并且效率会高些。其他情况下，比如序列号生成，这种情况下需要准确的数值，全局唯一的AtomicLong才是正确的选择，而不是LongAdder AtomicReference1The AtomicReference class provides reference objects that may be read and written atomically, so when multiple threads try to reach them at the same time, only one will be able to do so 原子性引用123456789101112131415@Slf4j@ThreadSafepublic class AtomicExample4 &#123; private static AtomicReference&lt;Integer&gt; count = new AtomicReference&lt;&gt;(0); public static void main(String[] args) &#123; count.compareAndSet(0, 2); // 2 count.compareAndSet(0, 1); // no count.compareAndSet(1, 3); // no count.compareAndSet(2, 4); // 4 count.compareAndSet(3, 5); // no log.info(&quot;count:&#123;&#125;&quot;, count.get()); &#125;&#125; 以上实例比较简单，我有个疑问？假如我们引用的是一个自定义的对象，并且对象里面有属性值，然后，修改对象中的属性值也是原子性的吗？还是只是对对象的引用是原子性操作。带着上面的疑问，进行源码分析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class AtomicReference&lt;V&gt; implements java.io.Serializable &#123; private static final long serialVersionUID = -1848883965231344442L; private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long valueOffset; static &#123; try &#123; valueOffset = unsafe.objectFieldOffset (AtomicReference.class.getDeclaredField(&quot;value&quot;)); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125; &#125; private volatile V value; /** * Creates a new AtomicReference with the given initial value. * * @param initialValue the initial value */ public AtomicReference(V initialValue) &#123; value = initialValue; &#125; /** * Creates a new AtomicReference with null initial value. */ public AtomicReference() &#123; &#125; /** * 不需要安全防护 */ public final V get() &#123; return value; &#125; /** * 设值值不需要进行对象安全防护 */ public final void set(V newValue) &#123; value = newValue; &#125; /** * 很明显调用的是csa操作 * 比较对象是否相同，进行设值 * 设值成功返回true，否则返回false */ public final boolean compareAndSet(V expect, V update) &#123; return unsafe.compareAndSwapObject(this, valueOffset, expect, update); &#125; /** * 设置新的值并且返回旧的值 * 原子操作 */ @SuppressWarnings(&quot;unchecked&quot;) public final V getAndSet(V newValue) &#123; return (V)unsafe.getAndSetObject(this, valueOffset, newValue); &#125;&#125; 通过源码分析，可以得出 AtomicReference 所提供的某些方法可以进行原子性操作，如compareAndSet、getAndSet，这仅仅是对引用进行原子性操作 AtomicReference 不能保证对象中若存在属性值修改是线程安全的，如假设引用对象是person，修改person中name和age，多个线程同时从引用中获得对象，并进行修改，会出现线程不安全情况。下面我们通过代码来验证一下这条结论。 1234567891011121314151617181920212223242526272829303132333435363738394041424344@Slf4j@NotThreadSafepublic class AtomicReferenceTest &#123; // 请求总数 public static int clientTotal = 1000; // 同时并发执行的线程数 public static int threadTotal = 500; public static Person person = new Person(0,0); public static AtomicReference&lt;Person&gt; personAtomicReference = new AtomicReference(person); public static void main(String[] args) throws Exception &#123; ExecutorService executorService = Executors.newCachedThreadPool(); final Semaphore semaphore = new Semaphore(threadTotal); final CountDownLatch countDownLatch = new CountDownLatch(clientTotal); for (int i = 0; i &lt; clientTotal ; i++) &#123; final int result = i; executorService.execute(() -&gt; &#123; try &#123; semaphore.acquire(); modify(result); semaphore.release(); &#125; catch (Exception e) &#123; log.error(&quot;exception&quot;, e); &#125; countDownLatch.countDown(); &#125;); &#125; countDownLatch.await(); executorService.shutdown(); log.info(&quot;name:&#123;&#125;,age:&#123;&#125;&quot;,personAtomicReference.get().getName(), personAtomicReference.get().getAge()); &#125; //如果线程安全的话，age的值和name的值是一致的 //如果线程不安全的话，age的值和name是不一样的。 private static void modify(int i) &#123; personAtomicReference.get().setAge(personAtomicReference.get().getAge() + i); personAtomicReference.get().setName(personAtomicReference.get().getName() + i); &#125;&#125; 在低并发的情况下，输出的结果是正确的，但是在高并发的情况下结果差距就很大了118:09:52.473 [main] INFO com.mmall.concurrency.example.atomic.AtomicReferenceTest - name:496592,age:496922 AtomicReferenceFieldUpdateratomic包中提供AtomicReferenceFieldUpdater、AtomicIntegerFieldUpdater、AtomicLongFieldUpdater，原子性的更新某一个类实例的指定的某一个字段 AtomicIntegerFieldUpdater123456789101112131415161718192021222324252627@Slf4j@ThreadSafepublic class AtomicExample5 &#123; //AtomicIntegerFieldUpdater 原子性的更新某一个类的实例的指定的某一个字段 //并且该字段由volatile进行修饰同时不能被static修饰 //有些网上说而且不能被private修饰？下文将进行验证 private static AtomicIntegerFieldUpdater&lt;AtomicExample5&gt; updater = AtomicIntegerFieldUpdater.newUpdater(AtomicExample5.class, "count"); @Getter public volatile int count = 100; public static void main(String[] args) &#123; AtomicExample5 example5 = new AtomicExample5(); if (updater.compareAndSet(example5, 100, 120)) &#123; log.info("update success 1, &#123;&#125;", example5.getCount()); &#125; if (updater.compareAndSet(example5, 100, 120)) &#123; log.info("update success 2, &#123;&#125;", example5.getCount()); &#125; else &#123; log.info("update failed, &#123;&#125;", example5.getCount()); &#125; &#125;&#125; 结果输出1218:48:27.815 [main] INFO com.mmall.concurrency.example.atomic.AtomicExample5 - update success 1, 12018:48:27.825 [main] INFO com.mmall.concurrency.example.atomic.AtomicExample5 - update failed, 120 源码分析12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576public abstract class AtomicIntegerFieldUpdater&lt;T&gt; &#123; /** * * @param tclass 持有某字段的类 * @param fieldName 字段名字 */ @CallerSensitive public static &lt;U&gt; AtomicIntegerFieldUpdater&lt;U&gt; newUpdater(Class&lt;U&gt; tclass, String fieldName) &#123; return new AtomicIntegerFieldUpdaterImpl&lt;U&gt; (tclass, fieldName, Reflection.getCallerClass()); &#125; /** * 原子性设置 */ public int getAndSet(T obj, int newValue) &#123; int prev; do &#123; prev = get(obj); &#125; while (!compareAndSet(obj, prev, newValue)); return prev; &#125; private static class AtomicIntegerFieldUpdaterImpl&lt;T&gt; extends AtomicIntegerFieldUpdater&lt;T&gt; &#123; private static final Unsafe unsafe = Unsafe.getUnsafe(); private final long offset; private final Class&lt;T&gt; tclass; private final Class&lt;?&gt; cclass; AtomicIntegerFieldUpdaterImpl(final Class&lt;T&gt; tclass, final String fieldName, final Class&lt;?&gt; caller) &#123; final Field field; final int modifiers; try &#123; field = AccessController.doPrivileged( new PrivilegedExceptionAction&lt;Field&gt;() &#123; public Field run() throws NoSuchFieldException &#123; //字段不存在会抛异常 return tclass.getDeclaredField(fieldName); &#125; &#125;); //检查访问级别 modifiers = field.getModifiers(); sun.reflect.misc.ReflectUtil.ensureMemberAccess( caller, tclass, null, modifiers); ClassLoader cl = tclass.getClassLoader(); ClassLoader ccl = caller.getClassLoader(); if ((ccl != null) &amp;&amp; (ccl != cl) &amp;&amp; ((cl == null) || !isAncestor(cl, ccl))) &#123; sun.reflect.misc.ReflectUtil.checkPackageAccess(tclass); &#125; &#125; catch (PrivilegedActionException pae) &#123; throw new RuntimeException(pae.getException()); &#125; catch (Exception ex) &#123; throw new RuntimeException(ex); &#125; Class&lt;?&gt; fieldt = field.getType(); //必须是int if (fieldt != int.class) throw new IllegalArgumentException("Must be integer type"); //必须用volatile修饰 if (!Modifier.isVolatile(modifiers)) throw new IllegalArgumentException("Must be volatile type"); this.cclass = (Modifier.isProtected(modifiers) &amp;&amp; caller != tclass) ? caller : null; this.tclass = tclass; //用Unsafe里的那一坨方法去原子更新 offset = unsafe.objectFieldOffset(field); &#125; &#125;&#125; 从源码分析中，可以看出没有要求不能被private修饰 AtomicStampReference 此类是要核心解决CAS的ABA问题 ​ ABA问题：指CAS操作的时候，线程将某个变量值由A修改为B，但是又改回了A，其他线程发现A并未改变，于是CAS将进行值交换操作，实际上该值已经被改变过，这与CAS的核心思想是不符合的 ​ 解决思路：每次变量更新的时候，把变量的版本号进行更新，如果某变量被某个线程修改过，那么版本号一定会递增更新，从而解决ABA问题 ​ J.U.C 提供了两个类解决ABA问题，一个是AtomicStampReference ，另一个是 AtomicMarkableReference AtomicLongArray AtomicLong是作用是对长整形进行原子操作。而AtomicLongArray的作用则是对”长整形数组”进行原子操作,根据索引，对数据中的指定位置的数据进行院子性的更新 AtomicBoolean 12345678910111213141516171819202122232425262728293031323334353637383940414243@Slf4j@ThreadSafepublic class AtomicExample6 &#123; private static AtomicBoolean isHappened = new AtomicBoolean(false); // 请求总数 public static int clientTotal = 5000; // 同时并发执行的线程数 public static int threadTotal = 200; public static void main(String[] args) throws Exception &#123; ExecutorService executorService = Executors.newCachedThreadPool(); final Semaphore semaphore = new Semaphore(threadTotal); final CountDownLatch countDownLatch = new CountDownLatch(clientTotal); for (int i = 0; i &lt; clientTotal ; i++) &#123; executorService.execute(() -&gt; &#123; try &#123; semaphore.acquire(); test(); semaphore.release(); &#125; catch (Exception e) &#123; log.error("exception", e); &#125; countDownLatch.countDown(); &#125;); &#125; countDownLatch.await(); executorService.shutdown(); log.info("isHappened:&#123;&#125;", isHappened.get()); &#125; /* * 演示如何让一段代码中的某个逻辑在高并发场景下只执行一次 */ private static void test() &#123; //原子性操作，保证从false 到 true 只会执行一次 if (isHappened.compareAndSet(false, true)) &#123; log.info("execute"); //只会执行一次 &#125; &#125;&#125; 锁JAVA中能保证同一时刻，只有一个线程来进行对其进行操作的，除了atomic包中所提供的类之外，还有jdk提供的锁，JAVA主要提供以下锁： synchronized : 关键字，并且依赖与JVM，作用对象的作用范围内都是同一时刻只能有一个线程对其操作的 Lock : 接口类，依赖特殊的CPU指定，使用代码实现，常用子类ReentrantLock synchronized 修饰代码块：大括号括起来的代码，也称同步代码块，作用与调用的对象 修饰方法：整个方法，也称同步方法，作用与调用的对象 修饰静态方法：整个静态方法，作用于类的所有对象 修饰类：括号括起来的部分，作用与类的所有对象 同步代码块与同步方法演示与解析123456789101112131415161718192021222324252627282930313233@Slf4jpublic class SynchronizedExample1 &#123; // 修饰一个代码块 public void test1(int j) &#123; //同步代码块 作用于调用的对象 synchronized (this) &#123; for (int i = 0; i &lt; 10; i++) &#123; log.info("test1 &#123;&#125; - &#123;&#125;", j, i); &#125; &#125; &#125; // 修饰一个方法 同步方法 作用于调用的对象 public synchronized void test2(int j) &#123; for (int i = 0; i &lt; 10; i++) &#123; log.info("test2 &#123;&#125; - &#123;&#125;", j, i); &#125; &#125; public static void main(String[] args) &#123; SynchronizedExample1 example1 = new SynchronizedExample1(); SynchronizedExample1 example2 = new SynchronizedExample1(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; &#123; example1.test2(1); &#125;); executorService.execute(() -&gt; &#123; //example1.test2(1) example2.test2(2); &#125;); &#125;&#125; 若线程池中开启两个线程： 使用同步方法进行验证： ​ 若两个线程中都使用同一个对象进行操作，那么他们是同步的,输出的结果都是先执行test2-1 0-9的输出后执行test2-2 0-9的输出或先执行test2-2 0-9的输出后执行test2-1 0-9的输出 1234567executorService.execute(() -&gt; &#123; example1.test2(1);&#125;);executorService.execute(() -&gt; &#123; example1.test2(2) //example2.test2(2);&#125;); 若两个线程中不使用同一个对象进行操作，那么他们输出即为交叉执行1234567executorService.execute(() -&gt; &#123; example1.test2(1);&#125;);executorService.execute(() -&gt; &#123; //example1.test2(2) example2.test2(2);&#125;); 注意：如果某个类为父类，并且存在同步方法，子类在继承这个类后，如果子类调用该父类的同步方法后，该方法是没有synchronized关键字的，原因是synchronized不属于方法声明的一部分 修饰静态方法与修饰类演示与解析 12345678910111213141516171819202122232425262728293031323334@Slf4j//作用于类的所有对象public class SynchronizedExample2 &#123; // 修饰一个类 public static void test1(int j) &#123; synchronized (SynchronizedExample2.class) &#123; for (int i = 0; i &lt; 10; i++) &#123; log.info("test1 &#123;&#125; - &#123;&#125;", j, i); &#125; &#125; &#125; // 修饰一个静态方法 public static synchronized void test2(int j) &#123; for (int i = 0; i &lt; 10; i++) &#123; log.info("test2 &#123;&#125; - &#123;&#125;", j, i); &#125; &#125; public static void main(String[] args) &#123; SynchronizedExample2 example1 = new SynchronizedExample2(); SynchronizedExample2 example2 = new SynchronizedExample2(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; &#123; example1.test1(1); //example1.test2(1); &#125;); executorService.execute(() -&gt; &#123; example2.test1(2); //example2.test2(2); &#125;); &#125;&#125; 从上面类的执行结果，同一个类的不同对象执行同步修饰的方法，执行的顺序是同步的 对比 synchronized ：不可中断锁，适合竞争不激烈，可读性较好 Lock：可中断锁，多样化同步，竞争激烈时能维持常态 Atomic：竞争激烈时能维持常态，比Lock性能好；只能同步一个值 可见性一个线程对主内存的修改可以及时的被其他线程观察到。导致共享变量在线程间不可见的原因： 线程交叉执行 重排序结合线程交叉执行 共享变量更新后的值没有在工作内存与主存间及时更新 对于可见性，JVM提供了 synchronized 和 volatile synchronized JMM关于synchronized的两条规定： 线程解锁前，必须把共享变量的最新值刷新到主内存 线程加锁时，将清空工作内存中共享变量的值，从而使用共享变量时需要从主内存中重新读取最新的值（注意：加锁与解锁是同一把锁） volatileIntroduction通过加入内存屏障和禁止重排序优化来实现 对volatile变量写操作时，会在写操作后加入一条store屏障指令，将本地内存中的共享变量值刷新到主内存中 对volatile变量读操作是，会在读操作前加入一条load屏障指令，从主内存中读取共享变量 通过上面两点，任何时候，不同的线程总能看到该变量的最新值。所有的指令操作都是CPU级别的 Verification1234567891011121314151617181920212223242526272829303132333435363738@Slf4j@NotThreadSafepublic class CountExample4 &#123; // 请求总数 public static int clientTotal = 5000; // 同时并发执行的线程数 public static int threadTotal = 200; public static volatile int count = 0; public static void main(String[] args) throws Exception &#123; ExecutorService executorService = Executors.newCachedThreadPool(); final Semaphore semaphore = new Semaphore(threadTotal); final CountDownLatch countDownLatch = new CountDownLatch(clientTotal); for (int i = 0; i &lt; clientTotal ; i++) &#123; executorService.execute(() -&gt; &#123; try &#123; semaphore.acquire(); add(); semaphore.release(); &#125; catch (Exception e) &#123; log.error("exception", e); &#125; countDownLatch.countDown(); &#125;); &#125; countDownLatch.await(); executorService.shutdown(); log.info("count:&#123;&#125;", count); &#125; //输出结果是线程不安全的。 private static void add() &#123; count++; &#125;&#125; 通过例子可以得知，即使通过volatile修饰变量，但依然无法保证线程安全 原因分析：123456private static void add() &#123; count++; //分3步 //1.取出当前count值 //2.count + 1 //3.count 重新写回主存&#125; 假设同时有两个线程进行操作，两个线程同时执行到第一步（从内存中读取最新值）得到一样的最新的结果，然后进入第二步（+1操作）并进行第三步（从新写回主存）。尽管第一步获取的值是一样的，但是同时将+1后的操作写回主存，这样就会丢掉某个+1的操作，这样就会出现线程不安全问题结论： volatile进行加操作线程不安全的，不适合计数场景 volatile关键字不具有原子性 使用场景 使用volatile必须具备两个条件 对变量的写操作，不依赖于当前值 该变量没有包含在具有其他变量的不变式子中 因此volatile适合作为状态的标记量 1234567891011volatile boolean inited = false;//线程1context = loadContext();inited = true;//线程2while(!inited)&#123; sleep();&#125;doSomethingWithConfig(context); 有序性JAVA内存模型中，允许编译器和处理器对指令进行重排序，但是重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性 volatile、synchronized、Lock：通过 volatile、synchronized、Lock 保证一定的有序性。显然，synchronized、Lock 保证每一个时刻只有一个线程可以执行被同步的代码，相当于让线程顺序执行同步代码，从而保证有序性。另外，JMM具备一些先天的有序性，即不需要额外的手段，就能保证有序性，即 Happens-before 原则，如果两个操作的执行次序，没有办法通过 Happens-before 原则推到出来，虚拟机进行随意的重排序，那么就不能保证有序行。 happens-before 程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作 (个人理解：一段程序代码的执行，在单个线程中看起来是有序的，程序看起来的执行是按照代码的顺序执行的，因为虚拟机可能会对指令进行重排序，虽然进行了重排序，但是最终结果是与程序顺序执行的结果是一致的，只会对不存在数据依赖的指令进行重排序，因此在单个线程中是有序执行的。这条规则是保证程序在单线程中执行结果的正确性，但无法保证多线程执行结果的正确性) 锁定规则：一个unLock操作先行发生于后面对同一个锁额lock操作； volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作； 传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C； 线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作； 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生； 线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行； 对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始； 安全发布对象安全发布对象的四种方法： 在静态初始化函数中初始化一个对象引用 将对象的引用保存到volatile类型域或者AtomicReference对象中 将对象的引用保存到某个正确构造对象的final类型域中 将对象的引用保存到一个由锁保护的域中 案例分析 Spring 框架中，Spring管理的类都是单例模式。如何保证一个实例只被初始化一次，且线程安全？通过不同单例的写法，具体描述安全发布对象的四种方法： 普通单例模式1234567891011121314151617181920212223242526/** * 懒汉模式 * 单例实例在第一次使用时进行创建 */@NotThreadSafepublic class SingletonExample1 &#123; // 私有构造函数 private SingletonExample1() &#123; //可能这里会存在很多的操作 //如资源加载、运算等 &#125; // 单例对象 private static SingletonExample1 instance = null; // 静态的工厂方法 // 单线毫无问题 public static SingletonExample1 getInstance() &#123; //多线程环境下存在线程安全问题 if (instance == null) &#123; instance = new SingletonExample1(); &#125; return instance; &#125;&#125; 1234567891011121314151617181920212223/** * 饿汉模式 * 单例实例在类装载时进行创建 * * 缺点：1.若构造方法中存在过多的处理、会导加载缓慢，从而引起性能问题 * 2.只进行加载，并无实际调用，导致资源浪费 */@ThreadSafepublic class SingletonExample2 &#123; // 私有构造函数 private SingletonExample2() &#123; &#125; // 单例对象 private static SingletonExample2 instance = new SingletonExample2(); // 静态的工厂方法 public static SingletonExample2 getInstance() &#123; return instance; &#125;&#125; 双重检测机制123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * 懒汉模式 -》 双重同步锁单例模式 * 单例实例在第一次使用时进行创建 */@NotThreadSafepublic class SingletonExample4 &#123; // 私有构造函数 private SingletonExample4() &#123; &#125; // 单例对象 private static SingletonExample4 instance = null; // 静态的工厂方法 public static SingletonExample4 getInstance() &#123; if (instance == null) &#123; // 双重检测机制 // B synchronized (SingletonExample4.class) &#123; // 同步锁 if (instance == null) &#123; instance = new SingletonExample4(); // A - 3 &#125; &#125; &#125; return instance; &#125; //这样的双重检测机制是线程不安全的 // 1、memory = allocate() 分配对象的内存空间 // 2、ctorInstance() 初始化对象 // 3、instance = memory 设置instance指向刚分配的内存 //多线程环境下 // JVM和cpu优化，发生了指令重排 // 1、memory = allocate() 分配对象的内存空间 // 3、instance = memory 设置instance指向刚分配的内存 // 2、ctorInstance() 初始化对象 //假设存在线程A、B同时进入双重检测机制 //当线程A执行到 instance = new SingletonExample4(); // A - 执行到指令的第三步进行内存分配，但是未初始化对象 //B执行到 if (instance == null) &#123; // 双重检测机制 //b发现instance不为空，直接返回对象，实上对象初始化并未开始&#125; 静态域初始化1234567891011121314151617181920212223242526272829303132/** * 饿汉模式 * 单例实例在类装载时进行创建 * * 静态域与静态代码块是顺序执行的，若将1 2 处位置进行交换则会出现空指针异常 */@ThreadSafepublic class SingletonExample6 &#123; // 私有构造函数 private SingletonExample6() &#123; &#125; //1. // 单例对象 private static SingletonExample6 instance = null; //2. static &#123; instance = new SingletonExample6(); &#125; // 静态的工厂方法 public static SingletonExample6 getInstance() &#123; return instance; &#125; public static void main(String[] args) &#123; System.out.println(getInstance().hashCode()); System.out.println(getInstance().hashCode()); &#125;&#125; 最安全的枚举模式12345678910111213141516171819202122232425262728293031/** * 枚举模式：最安全 */@ThreadSafe@Recommendpublic class SingletonExample7 &#123; // 私有构造函数 private SingletonExample7() &#123; &#125; public static SingletonExample7 getInstance() &#123; return Singleton.INSTANCE.getInstance(); &#125; private enum Singleton &#123; INSTANCE; private SingletonExample7 singleton; // JVM保证这个方法绝对只调用一次 Singleton() &#123; singleton = new SingletonExample7(); &#125; public SingletonExample7 getInstance() &#123; return singleton; &#125; &#125;&#125; 线程安全策略创建后状态不能被修改的对象叫作不可变对象。不可变对象天生就是线程安全的。它们的常量（变量）是在构造函数中创建的，既然它们的状态无法被修改，那么这些常量永远不会被改变——不可变对象永远是线程安全的。不可变对象需要满足的条件 对象创建以后其状态就不能修改 对象所有域都是final类型 对象是正确创建的（在对象创建期间，this引用没有逸出） finalfinal关键字：类、方法、变量 修饰类：不能被继承，final类中的成员属性可以根据需要设置为final，但final类中所有的成员方法都被隐式指定为final方法。一般不建议将类设置为final类型。可以参考String类。 修饰方法：1）锁定方法不被继承类修改；2）效率 修饰变量：1）基本数据类型变量，初始化后便不能进行修改；2）引用类型变量，初始化之后不能再指向别的引用 12345678910111213141516171819202122232425262728@Slf4j@NotThreadSafepublic class ImmutableExample1 &#123; private final static Integer a = 1; private final static String b = "2"; //引用类型不允许引用指向改变，但是对象值还是可以进行修改的 private final static Map&lt;Integer, Integer&gt; map = Maps.newHashMap(); static &#123; map.put(1, 2); map.put(3, 4); map.put(5, 6); &#125; public static void main(String[] args) &#123;// a = 2; //编译时报错// b = "3"; //编译时报错// map = Maps.newHashMap(); //编译时报错 map.put(1, 3); //容易引发线程安全问题 log.info("&#123;&#125;", map.get(1)); &#125; //可以修饰参数 private void test(final int a) &#123;// a = 1; &#125;&#125; Collectionsjava提供Collections工具类，在类中提供了多种不允许修改的方法 ​ Collections.unmodifiableXXX：Collection、List、Set、Map… 123456789101112131415161718192021Slf4j@ThreadSafepublic class ImmutableExample2 &#123; private static Map&lt;Integer, Integer&gt; map = Maps.newHashMap(); static &#123; map.put(1, 2); map.put(3, 4); map.put(5, 6); //处理过后的map是不可以再进行修改的 map = Collections.unmodifiableMap(map); &#125; public static void main(String[] args) &#123; //允许操作，但是操作会报错，扔出异常 map.put(1, 3); log.info(&quot;&#123;&#125;&quot;, map.get(1)); &#125;&#125; 12345678910111213141516public class Collections &#123; public static &lt;K,V&gt; Map&lt;K,V&gt; unmodifiableMap(Map&lt;? extends K, ? extends V&gt; m) &#123; return new UnmodifiableMap&lt;&gt;(m); &#125; private static class UnmodifiableMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Serializable &#123; @Override public boolean remove(Object key, Object value) &#123; throw new UnsupportedOperationException(); &#125; @Override public boolean replace(K key, V oldValue, V newValue) &#123; throw new UnsupportedOperationException(); &#125; &#125;&#125; Guava​ 谷歌的Guava提供类似Java中的Collections ​ ImmutableXXX：Collection、List、Set、Map… pom.xml 12345&lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;23.0&lt;/version&gt;&lt;/dependency&gt; 123456789101112131415161718@ThreadSafepublic class ImmutableExample3 &#123; private final static ImmutableList&lt;Integer&gt; list = ImmutableList.of(1, 2, 3); private final static List&lt;Integer&gt; lists = ImmutableList.of(1, 2, 3); private final static ImmutableSet set = ImmutableSet.copyOf(list); private final static ImmutableMap&lt;Integer, Integer&gt; map = ImmutableMap.of(1, 2, 3, 4); private final static ImmutableMap&lt;Integer, Integer&gt; map2 = ImmutableMap.&lt;Integer, Integer&gt;builder() .put(1, 2).put(3, 4).put(5, 6).build(); public static void main(String[] args) &#123; System.out.println(map2.get(3)); &#125;&#125; 1来源：https://www.jianshu.com/p/895950290179]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java并发系统学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CPU缓存一致性协议MESI]]></title>
    <url>%2F2019%2F05%2F23%2FCPU%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7%E5%8D%8F%E8%AE%AEMESI%2F</url>
    <content type="text"><![CDATA[CPU高速缓存（Cache Memory）CPU为何要有高速缓存CPU在摩尔定律的指导下以每18个月翻一番的速度在发展，然而内存和硬盘的发展速度远远不及CPU。这就造成了高性能能的内存和硬盘价格及其昂贵。然而CPU的高度运算需要高速的数据。为了解决这个问题，CPU厂商在CPU中内置了少量的高速缓存以解决I\O速度和CPU运算速度之间的不匹配问题。 在CPU访问存储设备时，无论是存取数据抑或存取指令，都趋于聚集在一片连续的区域中，这就被称为局部性原理。 1时间局部性（Temporal Locality）：如果一个信息项正在被访问，那么在近期它很可能还会被再次访问。 比如循环、递归、方法的反复调用等。 1空间局部性（Spatial Locality）：如果一个存储器的位置被引用，那么将来他附近的位置也会被引用。 比如顺序执行的代码、连续创建的两个对象、数组等。 带有高速缓存的CPU执行计算的流程 程序以及数据被加载到主内存 指令和数据被加载到CPU的高速缓存 CPU执行指令，把结果写到高速缓存 高速缓存中的数据写回主内存 目前流行的多级缓存结构由于CPU的运算速度超越了1级缓存的数据I\O能力，CPU厂商又引入了多级的缓存结构。 多级缓存结构 多核CPU多级缓存一致性协议MESI多核CPU的情况下有多个一级缓存，如何保证缓存内部数据的一致,不让系统数据混乱。这里就引出了一个一致性的协议MESI。 MESI协议缓存状态MESI 是指4中状态的首字母。每个Cache line有4个状态，可用2个bit表示，它们分别是： 1缓存行（Cache line）:缓存存储数据的单元。 注意： 对于M和E状态而言总是精确的，他们在和该缓存行的真正状态是一致的，而S状态可能是非一致的。如果一个缓存将处于S状态的缓存行作废了，而另一个缓存实际上可能已经独享了该缓存行，但是该缓存却不会将该缓存行升迁为E状态，这是因为其它缓存不会广播他们作废掉该缓存行的通知，同样由于缓存并没有保存该缓存行的copy的数量，因此（即使有这种通知）也没有办法确定自己是否已经独享了该缓存行。 从上面的意义看来E状态是一种投机性的优化：如果一个CPU想修改一个处于S状态的缓存行，总线事务需要将所有该缓存行的copy变成invalid状态，而修改E状态的缓存不需要使用总线事务。 MESI状态转换 理解该图的前置说明：1.触发事件 触发事件描述本地读取（Local read）本地cache读取本地cache数据本地写入（Local write）本地cache写入本地cache数据远端读取（Remote read）其他cache读取本地cache数据远端写入（Remote write）其他cache写入本地cache数据 2.cache分类：前提：所有的cache共同缓存了主内存中的某一条数据。 本地cache:指当前cpu的cache。触发cache:触发读写事件的cache。其他cache:指既除了以上两种之外的cache。注意：本地的事件触发 本地cache和触发cache为相同。 上图的切换解释： 状态触发本地读取触发本地写入触发远端读取触发远端写入M状态（修改）本地cache:M 触发cache:M其他cache:I本地cache:M 触发cache:M其他cache:I本地cache:M→E→S触发cache:I→S其他cache:I→S同步主内存后修改为E独享,同步触发、其他cache后本地、触发、其他cache修改为S共享本地cache:M→E→S→I触发cache:I→S→E→M其他cache:I→S→I同步和读取一样,同步完成后触发cache改为M，本地、其他cache改为IE状态（独享）本地cache:E触发cache:E其他cache:I本地cache:E→M触发cache:E→M其他cache:I本地cache变更为M,其他cache状态应当是I（无效）本地cache:E→S触发cache:I→S其他cache:I→S当其他cache要读取该数据时，其他、触发、本地cache都被设置为S(共享)本地cache:E→S→I触发cache:I→S→E→M其他cache:I→S→I当触发cache修改本地cache独享数据时时，将本地、触发、其他cache修改为S共享.然后触发cache修改为独享，其他、本地cache修改为I（无效），触发cache再修改为MS状态(共享)本地cache:S触发cache:S其他cache:S本地cache:S→E→M触发cache:S→E→M其他cache:S→I 当本地cache修改时，将本地cache修改为E,其他cache修改为I,然后再将本地cache为M状态本地cache:S触发cache:S其他cache:S本地cache:S→I触发cache：S→E→M其他cache:S→I当触发cache要修改本地共享数据时，触发cache修改为E（独享）,本地、其他cache修改为I（无效）,触发cache再次修改为M(修改)I状态（无效）本地cache:I→S或者I→E触发cache:I→S或者I →E其他cache:E、M、I→S、I本地、触发cache将从I无效修改为S共享或者E独享，其他cache将从E、M、I 变为S或者I本地cache:I→S→E→M触发cache:I→S→E→M其他cache:M、E、S→S→I既然是本cache是I，其他cache操作与它无关既然是本cache是I，其他cache操作与它无关 下图示意了，当一个cache line的调整的状态的时候，另外一个cache line 需要调整的状态。 MESIM×××√E×××√S××√√I√√√√ 举个栗子来说： 假设cache 1 中有一个变量x = 0的cache line 处于S状态(共享)。那么其他拥有x变量的cache 2、cache 3等x的cache line调整为S状态（共享）或者调整为 I 状态（无效）。 多核缓存协同操作假设有三个CPU A、B、C，对应三个缓存分别是cache a、b、 c。在主内存中定义了x的引用值为0。 单核读取那么执行流程是：CPU A发出了一条指令，从主内存中读取x。从主内存通过bus读取到缓存中（远端读取Remote read）,这是该Cache line修改为E状态（独享）. 双核读取那么执行流程是：CPU A发出了一条指令，从主内存中读取x。CPU A从主内存通过bus读取到 cache a中并将该cache line 设置为E状态。CPU B发出了一条指令，从主内存中读取x。CPU B试图从主内存中读取x时，CPU A检测到了地址冲突。这时CPU A对相关数据做出响应。此时x 存储于cache a和cache b中，x在chche a和cache b中都被设置为S状态(共享)。 修改数据那么执行流程是：CPU A 计算完成后发指令需要修改x.CPU A 将x设置为M状态（修改）并通知缓存了x的CPU B, CPU B将本地cache b中的x设置为I状态(无效)CPU A 对x进行赋值。 同步数据那么执行流程是： CPU B 发出了要读取x的指令。CPU B 通知CPU A,CPU A将修改后的数据同步到主内存时cache a 修改为E（独享）CPU A同步CPU B的x,将cache a和同步后cache b中的x设置为S状态（共享）。 MESI优化和他们引入的问题缓存的一致性消息传递是要时间的，这就使其切换时会产生延迟。当一个缓存被切换状态时其他缓存收到消息完成各自的切换并且发出回应消息这么一长串的时间中CPU都会等待所有缓存响应完成。可能出现的阻塞都会导致各种各样的性能问题和稳定性问题。 CPU切换状态阻塞解决-存储缓存（Store Bufferes）比如你需要修改本地缓存中的一条信息，那么你必须将I（无效）状态通知到其他拥有该缓存数据的CPU缓存中，并且等待确认。等待确认的过程会阻塞处理器，这会降低处理器的性能。应为这个等待远远比一个指令的执行时间长的多。 Store Bufferes为了避免这种CPU运算能力的浪费，Store Bufferes被引入使用。处理器把它想要写入到主存的值写到缓存，然后继续去处理其他事情。当所有失效确认（Invalidate Acknowledge）都接收到时，数据才会最终被提交。这么做有两个风险 Store Bufferes的风险第一、就是处理器会尝试从存储缓存（Store buffer）中读取值，但它还没有进行提交。这个的解决方案称为Store Forwarding，它使得加载的时候，如果存储缓存中存在，则进行返回。第二、保存什么时候会完成，这个并没有任何保证。 123456789101112value = 3；void exeToCPUA()&#123; value = 10; isFinsh = true;&#125;void exeToCPUB()&#123; if(isFinsh)&#123; //value一定等于10？！ assert value == 10; &#125;&#125; 试想一下开始执行时，CPU A保存着finished在E(独享)状态，而value并没有保存在它的缓存中。（例如，Invalid）。在这种情况下，value会比finished更迟地抛弃存储缓存。完全有可能CPU B读取finished的值为true，而value的值不等于10。 即isFinsh的赋值在value赋值之前。 这种在可识别的行为中发生的变化称为重排序（reordings）。注意，这不意味着你的指令的位置被恶意（或者好意）地更改。 它只是意味着其他的CPU会读到跟程序中写入的顺序不一样的结果。 顺便提一下NIO的设计和Store Bufferes的设计是非常相像的。 硬件内存模型执行失效也不是一个简单的操作，它需要处理器去处理。另外，存储缓存（Store Buffers）并不是无穷大的，所以处理器有时需要等待失效确认的返回。这两个操作都会使得性能大幅降低。为了应付这种情况，引入了失效队列。它们的约定如下： 对于所有的收到的Invalidate请求，Invalidate Acknowlege消息必须立刻发送 Invalidate并不真正执行，而是被放在一个特殊的队列中，在方便的时候才会去执行。 处理器不会发送任何消息给所处理的缓存条目，直到它处理Invalidate。 即便是这样处理器已然不知道什么时候优化是允许的，而什么时候并不允许。干脆处理器将这个任务丢给了写代码的人。这就是内存屏障（Memory Barriers）。 写屏障 Store Memory Barrier(a.k.a. ST, SMB, smp_wmb)是一条告诉处理器在执行这之后的指令之前，应用所有已经在存储缓存（store buffer）中的保存的指令。 1读屏障Load Memory Barrier (a.k.a. LD, RMB, smp_rmb)是一条告诉处理器在执行任何的加载前，先应用所有已经在失效队列中的失效操作的指令。 123456789101112void executedOnCpu0() &#123; value = 10; //在更新数据之前必须将所有存储缓存（store buffer）中的指令执行完毕。 storeMemoryBarrier(); finished = true;&#125;void executedOnCpu1() &#123; while(!finished); //在读取之前将所有失效队列中关于该数据的指令执行完毕。 loadMemoryBarrier(); assert value == 10;&#125; 现在确实安全了。完美无暇！ 后记然而，对于程序员来说简直是一个灾难。不想和平台耦合我们要跨平台。Write One,Run Everywhere!幸好java解决了这个问题，至于如何解决的请关注JMM(JavaMemoryMode)与物理内存相爱相杀。 1来源： https://www.cnblogs.com/yanlong300/p/8986041.html]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java并发系统学习番外篇</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[内存屏障]]></title>
    <url>%2F2019%2F05%2F23%2F%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C%2F</url>
    <content type="text"><![CDATA[为什么会有内存屏障 每个CPU都会有自己的缓存（有的甚至L1,L2,L3），缓存的目的就是为了提高性能，避免每次都要向内存取。但是这样的弊端也很明显：不能实时的和内存发生信息交换，分在不同CPU执行的不同线程对同一个变量的缓存值不同。 用volatile关键字修饰变量可以解决上述问题，那么volatile是如何做到这一点的呢？那就是内存屏障，内存屏障是硬件层的概念，不同的硬件平台实现内存屏障的手段并不是一样，java通过屏蔽这些差异，统一由jvm来生成内存屏障的指令。 内存屏障是什么 硬件层的内存屏障分为两种：Load Barrier 和 Store Barrier即读屏障和写屏障。 内存屏障有两个作用： 12阻止屏障两侧的指令重排序；强制把写缓冲区/高速缓存中的脏数据等写回主内存，让缓存中相应的数据失效。 对于Load Barrier来说，在指令前插入Load Barrier，可以让高速缓存中的数据失效，强制从新从主内存加载数据； 对于Store Barrier来说，在指令后插入Store Barrier，能让写入缓存中的最新数据更新写入主内存，让其他线程可见。 java内存屏障 java的内存屏障通常所谓的四种即LoadLoad,StoreStore,LoadStore,StoreLoad实际上也是上述两种的组合，完成一系列的屏障和数据同步功能。 LoadLoad屏障：对于这样的语句Load1; LoadLoad; Load2，在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。 StoreStore屏障：对于这样的语句Store1; StoreStore; Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。 LoadStore屏障：对于这样的语句Load1; LoadStore; Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。 StoreLoad屏障：对于这样的语句Store1; StoreLoad; Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。 它的开销是四种屏障中最大的。在大多数处理器的实现中，这个屏障是个万能屏障，兼具其它三种内存屏障的功能 volatile语义中的内存屏障 volatile的内存屏障策略非常严格保守，非常悲观且毫无安全感的心态： 12这里是列表文本在每个volatile写操作前插入StoreStore屏障，在写操作后插入StoreLoad屏障；在每个volatile读操作前插入LoadLoad屏障，在读操作后插入LoadStore屏障； 由于内存屏障的作用，避免了volatile变量和其它指令重排序、线程之间实现了通信，使得volatile表现出了锁的特性。 final语义中的内存屏障 对于final域，编译器和CPU会遵循两个排序规则： 12新建对象过程中，构造体中对final域的初始化写入和这个对象赋值给其他引用变量，这两个操作不能重排序；（废话嘛）初次读包含final域的对象引用和读取这个final域，这两个操作不能重排序；（晦涩，意思就是先赋值引用，再调用final值） 总之上面规则的意思可以这样理解，必需保证一个对象的所有final域被写入完毕后才能引用和读取。这也是内存屏障的起的作用： 写final域：在编译器写final域完毕，构造体结束之前，会插入一个StoreStore屏障，保证前面的对final写入对其他线程/CPU可见，并阻止重排序。 读final域：在上述规则2中，两步操作不能重排序的机理就是在读final域前插入了LoadLoad屏障。 X86处理器中，由于CPU不会对写-写操作进行重排序，所以StoreStore屏障会被省略；而X86也不会对逻辑上有先后依赖关系的操作进行重排序，所以LoadLoad也会变省略。 1原文链接：https://www.jianshu.com/p/2ab5e3d7e510]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java并发系统学习番外篇</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LongAdder解析]]></title>
    <url>%2F2019%2F05%2F23%2FLongAdder%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[LongAdder解析 1摘要： 对`LongAdder`的最初了解是从Coolshell上的一篇文章中获得的，但是一直都没有深入的了解过其实现，只知道它相较于`AtomicLong`来说，更加适合写多读少的并发情景。今天，我们就研究一下`LongAdder`的原理，探究一下它如此高效的原因。 对LongAdder的最初了解是从Coolshell上的一篇文章中获得的，但是一直都没有深入的了解过其实现，只知道它相较于AtomicLong来说，更加适合写多读少的并发情景。今天，我们就研究一下LongAdder的原理，探究一下它如此高效的原因。 基本原理和思想123456789Java有很多并发控制机制，比如说以AQS为基础的锁或者以CAS为原理的自旋锁。不了解AQS的朋友可以阅读我之前的AQS源码解析文章。一般来说，CAS适合轻量级的并发操作，也就是并发量并不多，而且等待时间不长的情况，否则就应该使用普通锁，进入阻塞状态，避免CPU空转。 所以，如果你有一个Long类型的值会被多线程修改，那么使用CAS进行并发控制比较好，但是如果你是需要锁住一些资源，然后进行数据库操作，那么还是使用阻塞锁比较好。 第一种情况下，我们一般都使用AtomicLong。AtomicLong是通过无限循环不停的采取CAS的方法去设置内部的value，直到成功为止。那么当并发数比较多或出现更新热点时，就会导致CAS的失败机率变高，重试次数更多，越多的线程重试，CAS失败的机率越高，形成恶性循环，从而降低了效率。 而LongAdder的原理就是降低对value更新的并发数，也就是将对单一value的变更压力分散到多个value值上，降低单个value的“热度”。 我们知道LongAdder的大致原理之后，再来详细的了解一下它的具体实现，其中也有很多值得借鉴的并发编程的技巧。 LongAdder的成员变量LongAdder是Striped64 的子类，其有三个比较重要的成员函数，在之后的函数分析中需要使用到，这里先说明一下。 12345678// CPU的数量static final int NCPU = Runtime.getRuntime().availableProcessors();// Cell对象的数组，长度一般是2的指数transient volatile Cell[] cells;// 基础value值，当并发较低时，只累加该值transient volatile long base;// 创建或者扩容Cells数组时使用的自旋锁变量transient volatile int cellsBusy; cells是LongAdder的父类Striped64中的Cell数组类型的成员变量。每个Cell对象中都包含一个value值，并提供对这个value值的CAS操作。1234567static final class Cell &#123; volatile long value; Cell(long x) &#123; value = x; &#125; final boolean cas(long cmp, long val) &#123; return UNSAFE.compareAndSwapLong(this, valueOffset, cmp, val); &#125;&#125; Add操作我们首先来看一下LongAdder的add函数，其会多次尝试CAS操作将值进行累加，如果成功了就直接返回，失败则继续执行。代码比较复杂，而且涉及的情况比较多，我们就以梳理历次尝试CAS操作为主线，讲清楚这些CAS操作的前提条件和场景。 1234567891011121314public void add(long x) &#123; Cell[] as; long b, v; int m; Cell a; // 当cells数组为null时，会进行第一次cas操作尝试。 if ((as = cells) != null || !casBase(b = base, b + x)) &#123; boolean uncontended = true; if (as == null || (m = as.length - 1) &lt; 0 || (a = as[getProbe() &amp; m]) == null || !(uncontended = a.cas(v = a.value, v + x))) // 当cells数组不为null，并且通过getProbe() &amp; m // 定位的Cell对象不为null时进行第二次CAS操作。 // 如果执行不成功，则进入longAccumulate函数。 longAccumulate(x, null, uncontended); &#125;&#125; 当并发量较少时，cell数组尚未初始化，所以只调用casBase函数，对base变量进行CAS累加。 我们来看一下casBase函数相关的源码吧。我们可以认为变量base就是第一个value值，也是基础value变量。先调用casBase函数来cas一下base变量，如果成功了，就不需要在进行下面比较复杂的算法， 123final boolean casBase(long cmp, long val) &#123; return UNSAFE.compareAndSwapLong(this, BASE, cmp, val);&#125; 当并发量逐渐提高时，casBase函数会失败。如果cells数组为null或为空,就直接调用longAccumulate方法。因为cells为null或在为空，说明cells未 初始化，所以调用longAccumulate进行初始化。否则继续判断。 如果cells中已经初始化，就继续进行后续判断。我们先来理解一下getProbe() &amp; m的这个操作吧，可以把这个操作当作一次计算”hash”值，然后将cells中这个位置的Cell对象赋值给变量a。如果变量a不为null，那么就调用该对象的cas方法去设置其value值。如果a为null，或在cas赋值发生冲突，那么调用longAccumulate方法。 LongAccumulate方法longAccumulate函数比较复杂，带有我的注释的代码已经贴在了文章后边，这里我们就只讲一下其中比较关键的一些技巧和思想。 首先，我们都知道只有当对base的cas操作失败之后，LongAdder才引入Cell数组．所以在longAccumulate中就是对Cell数组进行操作，分别涉及了数组的初始化，扩容和设置某个位置的Cell对象等操作。 在这段代码中，关于cellBusy的cas操作构成了一个SpinLock，这就是经典的SpinLock的编程技巧，大家可以学习一下。 我们先来看一下longAccumulate的主体代码，首先是一个无限for循环，然后根据cells数组的状态来判断是要进行cells数组的初始化，还是进行对象添加或者扩容。 12345678910111213141516171819202122232425262728final void longAccumulate(long x, LongBinaryOperator fn, boolean wasUncontended) &#123; int h; if ((h = getProbe()) == 0) &#123; //获取PROBE变量，探针变量，与当前运行的线程相关，不同线程不同 ThreadLocalRandom.current(); //初始化PROBE变量，和getProbe都使用Unsafe类提供的原子性操作。 h = getProbe(); wasUncontended = true; &#125; boolean collide = false; for (;;) &#123; //cas经典无限循环，不断尝试 Cell[] as; Cell a; int n; long v; if ((as = cells) != null &amp;&amp; (n = as.length) &gt; 0) &#123; // cells不为null,并且数组size大于0,表示cells已经初始化了 // 初始化Cell对象并设置到数组中或者进行数组扩容 &#125; else if (cellsBusy == 0 &amp;&amp; cells == as &amp;&amp; casCellsBusy()) &#123; //cells数组未初始化，获得cellsBusy lock,进行cells数组的初始化 // cells数组初始化操作 &#125; //如果初始化数组失败了，那就再次尝试一下直接cas base变量， // 如果成功了就直接返回，这是最后一个进行CAS操作的地方。 else if (casBase(v = base, ((fn == null) ? v + x : fn.applyAsLong(v, x)))) break; &#125; &#125; 进行Cell数组代码如下所示，它首先调用casCellsBusy函数获取了cellsBusy‘锁’，然后进行数组的初始化操作，最后将cellBusy’锁’释放掉。 1234567891011121314// 注意在进入这段代码之前已经casCellsBusy获得cellsBusy这个锁变量了。boolean init = false;try &#123; if (cells == as) &#123; Cell[] rs = new Cell[2]; rs[h &amp; 1] = new Cell(x); //设置x的值为cell对象的value值 cells = rs; init = true; &#125;&#125; finally &#123; cellsBusy = 0;&#125;if (init) break; 如果Cell数组已经初始化过了，那么就进行Cell数组的设置或者扩容。这部分代码有一系列的if else的判断，如果前一个条件不成立，才会进入下一条判断。 首先，当Cell数组中对应位置的cell对象为null时，表明该位置的Cell对象需要进行初始化，所以使用casCellsBusy函数获取’锁’，然后初始化Cell对象，并且设置进cells数组，最后释放掉’锁’。 当Cell数组中对应位置的cell对象不为null，则直接调用其cas操作进行累加。 当上述操作都失败后，认为多个线程在对同一个位置的Cell对象进行操作，这个Cell对象是一个“热点”，所以Cell数组需要进行扩容，将热点分散。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758if ((a = as[(n - 1) &amp; h]) == null) &#123; //通过与操作计算出来需要操作的Cell对象的坐标 if (cellsBusy == 0) &#123; //volatile 变量，用来实现spinLock,来在初始化和resize cells数组时使用。 //当cellsBusy为0时，表示当前可以对cells数组进行操作。 Cell r = new Cell(x);//将x值直接赋值给Cell对象 if (cellsBusy == 0 &amp;&amp; casCellsBusy()) &#123;//如果这个时候cellsBusy还是0 //就cas将其设置为非０，如果成功了就是获得了spinLock的锁．可以对cells数组进行操作． //如果失败了，就会再次执行一次循环 boolean created = false; try &#123; Cell[] rs; int m, j; //判断cells是否已经初始化，并且要操作的位置上没有cell对象． if ((rs = cells) != null &amp;&amp; (m = rs.length) &gt; 0 &amp;&amp; rs[j = (m - 1) &amp; h] == null) &#123; rs[j] = r; //将之前创建的值为x的cell对象赋值到cells数组的响应位置． created = true; &#125; &#125; finally &#123; //经典的spinLock编程技巧，先获得锁，然后try finally将锁释放掉 //将cellBusy设置为0就是释放锁． cellsBusy = 0; &#125; if (created) break; //如果创建成功了，就是使用x创建了新的cell对象，也就是新创建了一个分担热点的value continue; &#125; &#125; collide = false; //未发生碰撞&#125;else if (!wasUncontended)//是否已经发生过一次cas操作失败 wasUncontended = true; //设置成true,以便第二次进入下一个else if 判断else if (a.cas(v = a.value, ((fn == null) ? v + x : fn.applyAsLong(v, x)))) //fn是操作类型，如果是空，就是相加，所以让a这个cell对象中的value值和x相加，然后在cas设置，如果成果 //就直接返回 break;else if (n &gt;= NCPU || cells != as) //如果cells数组的大小大于系统的可获得处理器数量或在as不再和cells相等． collide = false;else if (!collide) collide = true;else if (cellsBusy == 0 &amp;&amp; casCellsBusy()) &#123; //再次获得cellsBusy这个spinLock,对数组进行resize try &#123; if (cells == as) &#123;//要再次检测as是否等于cells以免其他线程已经对cells进行了操作． Cell[] rs = new Cell[n &lt;&lt; 1]; //扩容一倍 for (int i = 0; i &lt; n; ++i) rs[i] = as[i]; cells = rs;//赋予cells一个新的数组对象 &#125; &#125; finally &#123; cellsBusy = 0; &#125; collide = false; continue;&#125;h = advanceProbe(h);//由于使用当前探针变量无法操作成功，所以重新设置一个,再次尝试 后记 本篇文章写的不是很好，我写完之后又看了一遍coolshell上的关于LongAdder的文章，感觉自己没有人家写的那么简洁明了。我对代码细节的注释和投入太多了。其实很多代码大家都可以看懂，并不需要大量的代码片段加注释。以后要注意一下。之后会接着研究一下JUC包中的其他类，希望大家多多关注。 1文章来源： https://yq.aliyun.com/articles/688822]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java并发系统学习番外篇</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java并发计数器分析]]></title>
    <url>%2F2019%2F05%2F22%2Fjava%E5%B9%B6%E5%8F%91%E8%AE%A1%E6%95%B0%E5%99%A8%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[前言一提到线程安全的并发计数器，AtomicLong 必然是第一个被联想到的工具。Atomic* 一系列的原子类以及它们背后的 CAS 无锁算法，常常是高性能，高并发的代名词。本文将会阐释，在并发场景下，使用 AtomicLong 来充当并发计数器将会是一个糟糕的设计，实际上存在不少 AtomicLong 之外的计数器方案。近期我研究了一些 Jdk1.8 以及 JCTools 的优化方案，并将它们的对比与实现细节整理于此。 AtomicLong 的前世今生在 Java 中，Atomic* 是高效的，这得益于 sun.misc.Unsafe 提供的一系列底层 API，使得 Java 这样的高级语言能够直接和硬件层面的 CPU 指令打交道。并且在 Jdk1.7 中，这样的底层指令可以配合 CAS 操作，达到 Lock-Free。 在 Jdk1.7 中，AtomicLong 的关键代码如下： 123456789101112public final long getAndIncrement() &#123; while (true) &#123; long current = get(); long next = current + 1; if (compareAndSet(current, next)) return current; &#125;&#125;public final boolean compareAndSet(long expect, long update) &#123; return unsafe.compareAndSwapLong(this, valueOffset, expect, update);&#125; 1. get() 方法 volatile 读当前 long 值 2. 自增 3. 自旋判断新值与当前值 4. 自旋成功，返回；否则返回 1 我们特别留意到 Jdk1.7 中 unsafe 使用的方法是 compareAndSwapLong，它与 x86 CPU 上的 LOCK CMPXCHG 指令对应，并且在应用层使用 while(true) 完成自 旋，这个细节在 Jdk1.8 中发生了变化。 在 Jdk1.8 中，AtomicLong 的关键代码如下： 123public final long getAndIncrement() &#123; return unsafe.getAndAddLong(this, valueOffset, 1L);&#125; Jdk1.7 的 CAS 操作已经不复存在了，转而使用了 getAndAddLong 方法，它与 x86 CPU 上的 LOCK XADD 指令对应，以原子方式返回当前值并递增（fetch and add）。 Atomic* 高效的原因，回答 CAS 是不够全面且不够严谨的，Jdk1.7 的 unsafe.compareAndSwapLong 以及 Jdk1.8 的 unsafe.getAndAddLong 才是关键，且 Jdk1.8 中不存在 CAS。 ```123456Jdk1.8 AtomicLong 相比 Jdk1.7 AtomicLong 的表现是要优秀的，这点我们将在后续的测评中见证。#### Jdk1.8 AtomicLong 相比 Jdk1.7 AtomicLong 的表现是要优秀的，这点我们将在后续的测评中见证。无论在 Jdk1.7 还是 Jdk1.8 中，Atomic* 的开销都是很大的，主要体现在： 高并发下，CAS 操作可能会频繁失败，真正更新成功的线程占少数。(Jdk1.7 独有的问题) 我之前的文章中介绍过“伪共享” (false sharing) 问题，但在 CAS 中，问题则表现的更为直接，这是“真共享”，与”伪共享“存在相同的问题：缓存行失效，缓存一致性开销变大。 底层指令的开销不见得很低，无论是 LOCK XADD 还是 LOCK CMPXCHG，想深究的朋友可以参考 instruction_tables ，（这一点可能有点钻牛角尖，但不失为一个角度去分析高并发下可行的优化） Atomic 所做的，比我们的诉求可能更大，有时候我们只需要计数器具备线程安全地递增这样的特性，但 Atomic 的相关操作每一次都伴随着值的返回。他是个带返回值的方法，而不是 void 方法，而多做了活大概率意味着额外的开销。 12抛开上述导致 AtomicLong 慢的原因，AtomicLong 仍然具备优势： 上述的第 4 点换一个角度也是 AtomicLong 的有点，相比下面要介绍的其他计数器方案，AtomicLong 能够保证每次操作都精确的返回真实的递增值。你可以借助 AtomicLong 来做并发场景下的递增序列号方案，注意，本文主要讨论的是计数器方案，而不是序列号方案。 实现简单，回到那句话：“简单的架构通常性能不高，高性能的架构通常复杂度很高”，AtomicLong 属于性能相对较高，但实现极其简单的那种方案，因为大部分的复杂性，由 JMM 和 JNI 方法屏蔽了。相比下面要介绍的其他计数器实现，AtomicLong 真的太“简易”了。 12![upload successful](http://47.103.200.134/image/AtomicLongSpeet.png) 横向对比，写的性能相比读的性能要差很多，在 20 个线程下写性能比读性能差距了 4~5 倍。 纵向对比，主要关注并发写，线程竞争激烈的情况下，单次自增耗时从 22 ns 增长为了 488 ns，有明显的性能下降。 实际场景中，我们需要统计系统的 qps、接口调用次数，都需要使用到计数的功能，写才是关键，并不是每时每刻都需要关注自增后的返回值，而 AtomicLong 恰恰在核心的写性能上有所欠缺。由此引出其他计数器方案。 123#### 认识 LongAdderDoug Lea 在 JDK1.8 中找到了一个上述问题的解决方案，他实现了一个 LongAdder 类。 @since 1.8@author Doug Leapublic class LongAdder extends Striped64 implements Serializable {}123456789101112131415LongAdder 的 API 如下![upload successful](http://47.103.200.134/image/longAddr.png)你应当发现，LongAdder 和 AtomicLong 明显的区别在于，increment 是一个 void 方法。直接来看看 LongAdder 的性能表现如何。(LA = LongAdder, AL = AtomicLong, 单位 ns/op)![upload successful](http://47.103.200.134/image/longAddrSpett.png)我们从中可以发现一些有意思的现象，网上不少很多文章没有从读写上对比二者，直接宣称 LongAdder 性能优于 AtomicLong，其实不太严谨。在单线程下，并发问题没有暴露，两者没有体现出差距；随着并发量加大，LongAdder 的 increment 操作更加优秀，而 AtomicLong 的 get 操作则更加优秀。鉴于在计数器场景下的特点—写多读少，所以写性能更高的 LongAdder 更加适合。#### LongAdder 写速度快的背后网上分析 LongAdder 源码的文章并不少，我不打算详细分析源码，而是挑选了一些必要的细节以及多数文章没有提及但我认为值得分析的内容。![upload successful](http://47.103.200.134/image/cell.png) Cell 设计减少并发修改时的冲突在 LongAdder 的父类 Striped64 中存在一个 volatile Cell[] cells; 数组，其长度是 2 的幂次方，每个 Cell 都填充了一个 @Contended 的 Long 字段，为了避免伪共享问题。 123456``` @sun.misc.Contended static final class Cell &#123; volatile long value; Cell(long x) &#123; value = x; &#125; // ... ignore&#125; 通过一系列算法，将计数结果分散在了多个 Cell 中，Cell 会随着并发量升高时发生扩容，最坏情况下 Cell 123456789101112```public long sum() &#123; Cell[] as = cells; Cell a; long sum = base; if (as != null) &#123; for (int i = 0; i &lt; as.length; ++i) &#123; if ((a = as[i]) != null) sum += a.value; &#125; &#125; return sum;&#125; ConcurrentHashMap 中的 size() 中也存在，毕竟他们的作者都是 Doug Lea。```12 并发场景下高效获取随机数 LongAdder 内部算法需要获取随机数，而 Random 类在并发场景下也是可以优化的。12 ThreadLocalRandom random = ThreadLocalRandom.current();random.nextInt(5);12```使用 ThreadLocalRandom 替代 Random，同样出现在了 LongAdder 的代码中。 123. longAccumulatelongAccumulate 方法是 LongAdder 的核心方法，内部存在大量的分支判断。首先和 Jdk1.7 的 AtomicLong 一样，它使用的是 UNSAFE.compareAndSwapLong 来完成自旋，不同之处在于，其在初次 cas 方式失败的情况下(说明多个线程同时想更新这个值)，尝试将这个值分隔成多个 Cell，让这些竞争的线程只负责更新自己所属的 Cell，这样将竞争压力分散开。 LongAdder 的前世今生1其实在 Jdk1.7 时代，LongAdder 还未诞生时，就有一些人想着自己去实现一个高性能的计数器了，比如一款 Java 性能监控框架 dropwizard/metrics 就做了这样事，在早期版本中，其优化手段并没有 Jdk1.8 的 LongAdder 丰富，而在 metrics 的最新版本中，其已经使用 Jdk1.8 的 LongAdder 替换掉了自己的轮子。在最后的测评中，我们将 metrics 版本的 LongAdder 也作为一个参考对象。 JCTools 中的 ConcurrentAutoTable1并非只有 LongAdder 考虑到了并发场景下计数器的优化，大名鼎鼎的并发容器框架 JCTool 中也提供了和今天主题相关的实现，虽然其名称和 Counter 看似没有关系，但通过其 Java 文档和 API ，可以发现其设计意图考虑到了计数器的场景。 1在最后的测评中，我们将 JCTools 的 ConcurrentAutoTable 也作为一个参考对象。 最终测评1Jdk1.7 的 AtomicLong，Jdk1.8 的 AtomicLong，Jdk 1.8 的 LongAdder，Metrics 的 LongAdder，JCTools 的 ConcurrentAutoTable，我对这五种类型的计数器使用 JMH 进行基准测试。 1234public interface Counter &#123; void inc(); long get();&#125; 1将 5 个类都适配成 Counter 接口的实现类，采用 @State(Scope.Group)，@Group 将各组测试用例进行隔离，尽可能地排除了互相之间的干扰，由于计数器场景的特性，我安排了 20 个线程进行并发写，1 个线程与之前的写线程共存，进行并发读。Mode=avgt 代表测试的是方法的耗时，越低代表性能越高。 12345如果我们只关注 inc 即写性能，可以发现 jdk1.8 的 LongAdder 表现的最为优秀，ConcurrentAutoTable 以及两个版本的 LongAdder 在一个数量级之上；1.8 的 AtomicLong 相比 1.7 的 AtomicLong 优秀很多，可以得出这样的结论，1.7 的 CAS+LOCK CMPXCHG 方案的确不如 1.8 的 LOCK XADD 来的优秀，但如果与特地优化过的其他计数器方案来进行比较，便相形见绌了。如果关注 get 性能，虽然这意义不大，但可以见得，AtomicLong 的 get 性能在高并发下表现依旧优秀，而 LongAdder 组合求值的特性，导致其性能必然存在一定下降，位列第二梯队，而 ConcurrentAutoTable 的并发读性能最差。关注整体性能，CounterBenchmark.rw 是对一组场景的整合打分，可以发现，在我们模拟的高并发计数器场景下，1.8 的 LongAdder 获得整体最低的延迟 98 ns，相比性能最差的 Jdk1.7 AtomicLong 实现，高了整整 10 倍有余，并且，随着并发度提升，这个数值还会增大。 AtomicLong 可以被废弃吗？既然 LongAdder 的性能高出 AtomicLong 这么多，我们还有理由使用 AtomicLong 吗？ 1本文重点讨论的角度还是比较局限的：单机场景下并发计数器的高效实现。AtomicLong 依然在很多场景下有其存在的价值，例如一个内存中的序列号生成器，AtomicLong 可以满足每次递增之后都精准的返回其递增值，而 LongAdder 并不具备这样的特性。LongAdder 为了性能而丧失了一部分功能，这体现了计算机的哲学，无处不在的 trade off。 高性能计数器总结 AtomicLong ：并发场景下读性能优秀，写性能急剧下降，不适合作为高性能的计数器方案。内存需求量少。 LongAdder ：并发场景下写性能优秀，读性能由于组合求值的原因，不如直接读值的方案，但由于计数器场景写多读少的缘故，整体性能在几个方案中最优，是高性能计数器的首选方案。由于 Cells 数组以及缓存行填充的缘故，占用内存较大。 ConcurrentAutoTable ：拥有和 LongAdder 相近的写入性能，读性能则更加不如 LongAdder。它的使用需要引入 JCTools 依赖，相比 Jdk 自带的 LongAdder 并没有优势。但额外说明一点，ConcurrentAutoTable 的使用并非局限于计数器场景，其仍然存在很大的价值。 在前面提到的性能监控框架 Metrics，以及著名的熔断框架 Hystrix 中，都存在 LongAdder 的使用场景，有兴趣的朋友快去实践一下 LongAdder 吧。 12345678910111213本文所有的 JMH 测试代码，均可在我的 github 中获得：https://github.com/lexburner/JMH-samples.git微信不支持外部超链接，文中相关仓库附录：Netflix/Hystrix : https://github.com/Netflix/HystrixMetrics : https://github.com/dropwizard/metricsJCTools : https://github.com/JCTools/JCToolsinstruction_tables : https://www.agner.org/optimize/instruction_tables.pdf本文转载于：https://mp.weixin.qq.com/s/yAvJFZWxfKb38IDMjQd5zg?spm=a2c4e.11153940.blogcont651530.11.303e7bebu6FTOM]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java并发系统学习番外篇</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并发编程之基础知识]]></title>
    <url>%2F2019%2F05%2F21%2F%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[Lombox 简介Lombok项目是一个java库，可以自动插入到您的编辑器和构建工具中，让您的java变得更加精彩。切勿再次写入另一个getter或equals方法。提前访问未来的Java功能val，等等。 除了官方介绍中，并不多相关文章，特意挑了 一篇文章中相关内容 lombok 提供了简单的注解的形式来帮助我们简化消除一些必须有但显得很臃肿的 java 代码。特别是相对于 POJO。 简单来说，比如我们新建了一个类，然后在其中写了几个字段，然后通常情况下我们需要手动去建立getter和setter方法啊，构造函数啊之类的，lombok的作用就是为了省去我们手动创建这些代码的麻烦，它能够在我们编译源码的时候自动帮我们生成这些方法。 lombok能够达到的效果就是在源码中不需要写一些通用的方法，但是在编译生成的字节码文件中会帮我们生成这些方法，这就是lombok的神奇作用。 虽然有人可能会说IDE里面都自带自动生成这些方法的功能，但是使用lombok会使你的代码看起来更加简洁，写起来也更加方便。 常用的注解@slf4j、@Setter、@Getter、@NoArgsConstructor(注解在类上：为类提供一个无参的构造方法)、@AllArgsConstructor(注解在类上；为类提供一个全参的构造方法) @NoArgsConstructor //注解在类上：为类提供一个无参的构造方法 @AllArgsConstructor//注解在类上；为类提供一个全参的构造方法 public class Person { //@Getter @Setter 注解在属性上；为属性提供 setting 方法 getting方法 @Setter @Getter private int pid; @Setter @Getter private String pname; @Setter @Getter private int sage; } 基础知识讲解与核心知识准备并发与高并发基本概念概念并发：同时拥有两个或者多个线程，如果程序在单核处理器运行，多个线程将交替地换入或者换出内存，这些线程是同时&quot;存在&quot;的，每个线程都处于执行过程中的某个状态，如果运行在多核处理器上，此时，程序中的每个线程都将会分配到一个处理器核上，因此可以同时运行 并行：系统中有多个任务同时存在可称之为“并发”，系统内有多个任务同时执行可称之为“并行”；并发是并行的子集。如果说并发就是在一台处理器上&quot;同时&quot;处理多个任务，那么并行就是在多台处理器上同时处理多个任务；个人理解是，在单核CPU系统上，并行是无法实现的，只可能存在并发而不可能存在并行。 高并发：高并发（High Concurrency）是互联网分布式系统架构设计中必须考虑的因素之一，它通常指，通过设计保证系统能够同时并行处理很多请求。 对比：并发：多个线程操作相同的资源，保证线程安全，合理使用资源 高并发：服务能同时处理很多请求，提高程序性能；如系统集中收到大量的请求（12306的抢票系统），导致系统在某段时间类执行大量的操作，包括对资源的请求、数据库的操作等等，如果高并发处理不好，不仅仅降低用户的体验度，请求时间变长，同时也可能导致系统宕机，甚至导致OOM（Out Of Memory）异常，如果想要系统适应高并发状态，就要有多个方面进行系统优化，包括硬件、网络、系统架构、开发语言的选取、数据结构的应用、算法的优化等等，这个时候谈论的是如何提供现有程序的性能，对高并发场景提供一些解决方案、手段等等 CPU多级缓存在多线程并发环境下，如果不采取特殊手段，普通的累加结果很可能是错的。错的原因可能涉及到计算机原理以及JAVA方面的一些知识。 Main Memory : 主存 Cache : 高速缓存，数据的读取和存储都经过此高速缓存 CPU Core : CPU核心 Bus : 系统总线 CUP Core 与 Cache 之间有一条快速通道，Main Memory 与 Cache 关联在 Bus 上，同时 Bus 还用于其他组件 的通信，在Cache出现不久后，系统变得更加复杂，Cache与Main Memory中速度的差异拉大，直到加入另一级的Cache，新加入的Cache 比 一级 Cache 更大，但是更慢，由于从加大一级Cache的做法，从经济上是行不通的，所以有了二级Cache，甚至已经有三级 Cache 为什么需要CPU CACHE?CPU的频率太快了，快到主存跟不上，这样在处理器时钟周期内，CPU常常需要等待主存，浪费资源，这样会使CPU花费很长时间等待数据到来或把数据写入内存。所以Cache的出现，是为了缓解CPU和内存之间速度的不匹配问题（结构：CPU - &gt; CACHE - &gt; MEMORY） CPU CACHE 意义缓存的容量远远小于主存，因此出现缓存不命中的情况在所难免，既然缓存不能包含CPU所需要的所有数据，那么Cache的存在真的有意义吗? CPU缓存存在的意义分两点（局部性原理）： 时间局部性：如果某个数据被访问，那么在不久的将来它很可能被再次访问 空间局限性：如果某个数据被访问，那么与它相邻的数据很快也可能被访问 缓存的工作原理是当CPU要读取一个数据时，首先从缓存中查找，如果找到就立即读取并运送给CPU处理；如果没有找到，就用相对慢的速度内存中读取并运送给CPU处理，同时把这个数据所在的数据块调入缓存中，可以使得以后对整块数据的读取都从缓存中进行，不必再调用内存。 正是这样的读取机制使CPU读取缓存的命中率非常高（大多数CPU可达90%左右），也就是说CPU下一次要读取的数据90%都在缓存中，大约10%需要从内存读取。 缓存一致性（MESI）缓存一致性用于保证多个CPU Cache之间缓存共享数据的一致性，定义了Cache Line四种状态，而CPU对Cache的四种操作，可能会产生不一致的状态，因此缓存控制器监听到本地操作和远程操作的时候 ，需要对Cache Line作出相应的修改，从而保证数据在多个缓存之间的一致性 Cache Line ： 是cache与内存数据交换的最小单位，根据操作系统一般是32byte或64byte。在MESI协议中，状态可以是M、E、S、I，地址则是cache line中映射的内存地址，数据则是从内存中读取的数据。 MESI其实是四种状态的缩写：M（modify）修改、E（exclusive）独占、S（shared）共享、I（invalid）失效。 Cache 操作： MESI协议中，每个cache的控制器不仅知道自己的操作（local read和local write），通过监听也知道其他CPU中cache的操作（remote read和remote write）。对于自己本地缓存有的数据，CPU仅需要发起local操作，否则发起remote操作，从主存中读取数据，cache控制器通过总线监听，仅能够知道其他CPU发起的remote操作，但是如果local操作会导致数据不一致性，cache控制器会通知其他CPU的cache控制器修改状态。 乱序执行优化处理器为提高运算速度而做出违背代码原有顺序的优化 举个例子： 计算 a * b ，a =10 ，b = 200 ，则 result = a * b = 2000 代码编写顺序：a=10 -&gt; b=200 -&gt; result = a * b CPU乱序执行优化可能会发生执行顺序为：b=200 -&gt; a=10 -&gt; result = a * b CPU乱序执行优化不会对结果造成影响，在单核时代，处理器保证做出的优化，不会导致执行的结果远离预期的目标，但是在多核环境下并非如此。首先在多核环境中，同时会有多个核执行指令，每个核的指定都可能会被乱序优化，另外，处理器还引用了L1、L2等缓存机制，每个核都有自己的缓存，这就导致了逻辑次序上后写入内存的数据，未必真的最后写入，最终带来了这样的一个问题：如果我们不做任何防护措施，处理器最终得到的结果和我们逻辑得出的结果大不相同。比如我们在其中的一个核中执行数据写入操作，并在最后写一个标记，用来标记数据已经准备好了，然后从另外一个核上，通过那个标志，来判断数据是否已经就绪，这种做法它就存在一定的风险，标记位先被写入，但数据操作并未完成（可能是计算为完成、也可能是数据没有从缓存刷新到主存当中）， 最终导致另外的核使用了错误的数据。 Java 内存模型（Java Memory Model，JMM）CPU缓存一致性和乱序执行优化，在多核多并发下，需要额外做很多的事情，才能保证程序的执行，符合我们的预期。那么JVM（Java Virtual Machine (Java虚拟机)）是如何解决这些问题的?为了屏蔽掉各种硬件和操作系统的内存访问差异，实现让Java程序在各种平台下都能达到一致的并发效果，JMV规范中定义了JMM （Java Memory Model (Java 内存模型)）。 JMM是一种规范，它规范了JVM与计算机内存是如何协同工作的，它规定一个线程如何和何时可以看到其他线程修改过的共享变量的值，以及在必须时如何同步的访问共享变量。 JVM内存分配概念 JVM内存分配的两个概念：Stack（栈）和Heap（堆）。 Java中的Heap是运行时数据区，由垃圾回收负责，它的优势是动态的分配内存大小，生存期也不必事先告诉编译器，在运行时动态分配内存，Java的垃圾收集器，会自动回收不再使用的数据。但是也有缺点，由于是要在运行时动态分配内存，因此存取速度相对较慢。 Java中的Stack优势是存取速度比Heap要快，仅次于计算机中的寄存器，栈中的数据是可以共享的，但是它的缺点是，存在栈中数据的大小和生存期必须是确定的，缺乏灵活性，主要存放一些基本类型的变量。 JMM要求调用栈和本地变量存放在线程栈中，对象存放在堆上。一个本地变量可能指向一个对象的引用，引用这个本地变量是存放在线程栈上，而对象本身是存放在堆上的。一个对象可能包含方法，这些方法可能包含本地变量，这些本地变量还是存放在线程栈中，即使这些方法所属的对象存放在堆上。一个对象的成员变量可能会随着这个对象自身存放在堆上，不管这个成员对象是原始类型还是引用类型，静态成员变量跟随着类的定义一起存放在堆上。存放在堆上的对象，可以被所持有对这个对象引用线程的访问。 当一个线程可以访问一个对象的时候，它也可以访问该对象的成员变量，如果两个线程同时调用同一个对象的同一个方法，将会都访问该对象的成员变量，但是每一个线程都拥有了这个成员变量的私有拷贝。 计算机内存硬件架构 CPU，一台现代计算机拥有两个或多个CPU，其中一些CPU还有多核，从这一点可以看出，在一个有两个或多个CPU的现代计算机上，同时运行多个线程是非常有可能的，而且每个CPU在某一个时刻，运行一个线程是肯定没有问题的，这意味着，如果Java程序是多线程的，在Java程序中，每个CPU上一个线程是可能同时并发执行的。 CPU Refisters（寄存器），每个CPU都包含一系列的寄存器，它们是CPU内存的基础，CPU在寄存器中执行操作的速度远大于在主存上执行的速度，这是因为CPU访问寄存器的速度远大于主存。 Cache（高速缓存），由于计算机的存储设备与处理器运算速度之间有着几个数量级的差距，所以现代计算机系统都不得不加入一层读写速度尽可能接近处理器运算速度的高级缓存来作为内存与处理器之间的缓冲，将运算需要使用到的数据复制到缓存中，让运算能快速的进行，当运算结束后，在从缓存同步到内存中。这样处理器就无需等待缓慢的内存读写，CPU访问缓存层的速度快于访问主存的速度，但通常比访问内部寄存器的速度要慢。 Main Memory（主存），随机存取存储器（random access memory，RAM）又称作“随机存储器&quot;，一个计算机包含一个主存，所有的CPU都可以访问主存，主存通常比CPU中的缓存大得多。 JVM 与 Computer JVM 与 Computer 内存架构存在差异，硬件内存并无区分栈与堆，对于硬件而言，所有的栈和堆都分布在主内存中，可能会出现在高速缓存、寄存器中。 内存模型抽象结构 Java内存模型 - 同步八种操作 lock（锁定）：作用于主内存的变量，把一个变量标识为一条线程独占状态 unlock（解锁）：作用于主内存的变量，把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定 read（读取）：作用于主内存的变量，把一个变量值从主内存传输到线程的工作内存中，以便随后的load动作使用 load（载入）：作用于工作内存的变量，它把read操作从主内存中得到的变量值存放工作内存的变量副本中 use（使用）：作用于工作内存的变量，把工作内存中的一个变量值传递给执行引擎 assign（赋值）：作用于工作内存的变量，它把一个从执行引擎接收到的值赋值给工作内存的变量 store（存储）：作用于工作内存的变量，把工作内存中的一个变量的值传递到主内存中，以便随后的write的操作 write（写入）：作用于主内存的变量，它把store操作从工作内存中的一个变量的值传送到主内存的变量中 Java内存模型 - 同步规则 如果要把一个变量从主内存中复制到工作内存，就需要按顺序地执行read和load操作，如果把变量从工作内存中同步回主内存中，就要按顺序地执行store和write操作，但Java内存模型只要求上述操作必须按顺序执行，而没有保证是连续执行 不允许read和load、store和write操作之一单独出现 不允许一个线程丢弃它的最近assign的操作，即变量在工作内存中改变了之后必须同步到主内存中 不允许一个线程无原因地（没有发生过任何assign操作）把数据从工作内存同步回主内存中 一个新的变量只能在主内存中诞生，不允许在工作内存中直接使用一个未被初始化（load或assign）的变量。即就是对一个变量实施use和store操作之前，必须先执行过了assign和load操作 一个变量在同一时刻只允许一条线程对其进行lock操作，但lock操作可以被同一条线程重复执行多次，多次与执行lock后，只有执行相同次数的unlock，变量才会被解锁。lock和unlock必须成对出现 如果一个变量执行lock操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量前需要重新执行load或assign操作初始化变量的值 如果一个变量事先没有被lock操作锁定，则不允许对它执行unlock操作；也不允许去unlock一个被其他线程锁定的变量 对一个变量执行unlock操作之前，必须先把变量同步到主内存中（执行store和write操作） Java 内存模型 - 同步操作与规则 并发的优势与风险 并发编程与线程安全代码所在的进程，有多个线程同时运行，而这些线程可能会同时运行同一段代码，如果每次运行结果和单线程预期结果一致，变量值也和预期一致，则认为这是线程安全的。简单的说，就是并发环境下，得到我们期望正确的结果。对应的一个概念就是线程不安全，就是不提供数据访问保护，有可能出现多个线程，先后更改数据，造成所得到的数据是脏数据，也可能是计算错误。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java并发系统学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[时光荏苒，蹉跎了谁的年华]]></title>
    <url>%2F2019%2F05%2F18%2F%E6%97%B6%E5%85%89%E8%8D%8F%E8%8B%92%EF%BC%8C%E8%B9%89%E8%B7%8E%E4%BA%86%E8%B0%81%E7%9A%84%E5%B9%B4%E5%8D%8E%2F</url>
    <content type="text"><![CDATA[当清晨的一缕阳光透过窗帘上的空隙映照在沉睡的脸庞时，微微张开的双眼朦胧地注视着周遭的一切，新的一天悄然而至。 ——题记 时光的单车飞快驶去，岁月的倒影也将消失，白天与黑夜不停的交替，轮回的四季斑驳了谁的岁月，蹉跎了谁的年华。一个人静静地与岁月交错，于平淡之中细细体会生活的深意，去注视，去聆听，去感受那些带着希望的别离以及那些经受沧桑的相逢，不论时光如何飞转，那些落花一样的往事，依然鲜活地存在于我的脑海之中。当岁月和美丽的回忆已成为风中的叹息，我们伤感的眼里也许依然残存旧时的泪痕，模糊了视线，不敢轻易触碰。 生活的列车慢慢的前进，有些人下去，也有人上去，不慌不忙的过着行云流水的日子，有的人知道自己的前方在哪里停靠，生活充实而安逸，有些人庸庸碌碌的过着不起波澜的日子，每天无头鸟似的瞎忙，朦胧的眼神向世界宣告着昏暗思想，一个个皮囊悬浮在空气中，没有生机的灵魂过着糜烂的时间。没有归属，无处生根。有时我们在迷茫青春的时候，日子也慢慢地溜走，不留一点痕迹。 时光不可阻挡，岁月交错中总要有些思量。人生只有在不短的思考中才会有所进步，有所追求，有了目标的人生才不会孤独和无助，只有让自己的心静下来时一些前方的东西才会明朗的展现在我们的面前。让我们不再迷惑于为所谓的挣扎中，谁的年华没有色彩，谁的青春没有耀眼的光芒，只是在岁月的长河里我们的选择不同，所得到的结局就不同，每个人都需要努力才会得到一切自己所要追求的东西和梦想。 生命无常，人生苦短，记忆的时光中我们匆匆走过，走过喧嚣，走过孤寂，时光无情地带走了我们的青春年少，还好我们都在坚持着内心的宁静，岁月的年轮缓缓的从我们身边碾过，往事一幕幕铺陈，让我的生活回忆不至于那么的枯燥，一些美好的记忆还依然鲜活地根植在我的脑海之中。消逝不去，本不该怀旧的年纪，可是我们学不会遗忘，日日夜夜的想念，带着些许的小寂寞，心有不甘常常在无人的街角大声的长啸，发泄着内心的声音，有时候我们会选择相信宿命，认为人与人之间的相遇，就像是上天早已做了安排，人谁也逃不过岁月时光刻下的印迹。 时光荏苒，蹉跎了谁的年华，匆匆行走的岁月长河中，有些人只顾着追寻他人的脚步，忘记了自己的方向，忘记了自己的目标和理想，有些人几顾思量不敢走出自己的道路，因而迷失了方向。迷失了自己。有些人默默坚守，把青春的岁月包裹在温热的怀里，载着它踏上梦想的征途，不留一丝遗憾。不留一点别人靠近的距离，就像是陈孝正为自己规划的一厘米的差距，人生没有从头来过的权利。亦没有后悔的权利，做过的事情，不管有些怎样的结局都会成为过往，我们纵使一味的活在过去的时光里也不会改变一点点发生的故事，向着远方，努力的看看前方的路才是对我们自己的肯定，只有心存希望，才会有拼搏的勇气，才有希望去走更远的路，因为值得，所以一路前行， 那一路上的心酸往事，慢慢的沉淀在内心平和的深处！]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>生活</tag>
      </tags>
  </entry>
</search>
