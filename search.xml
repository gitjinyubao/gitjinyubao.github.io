<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[hexo 保持后台持续运行]]></title>
    <url>%2F2019%2F06%2F14%2Fhexo-%E4%BF%9D%E6%8C%81%E5%90%8E%E5%8F%B0%E6%8C%81%E7%BB%AD%E8%BF%90%E8%A1%8C%2F</url>
    <content type="text"><![CDATA[官方说用\$ hexo s &amp; 但是我在用的时候还是进程莫名奇妙的死掉了 今天给大家介绍一个方法 那就是 用pm2 来接管hexo的进程 开始操作安装pm2 复制 1npm install -g pm2 写一个执行脚本在博客根目录下面创建一个hexo_run.js 复制 12345678910//runconst &#123; exec &#125; = require(&apos;child_process&apos;)exec(&apos;hexo server&apos;,(error, stdout, stderr) =&gt; &#123; if(error)&#123; console.log(&apos;exec error: $&#123;error&#125;&apos;) return &#125; console.log(&apos;stdout: $&#123;stdout&#125;&apos;); console.log(&apos;stderr: $&#123;stderr&#125;&apos;);&#125;) -运行脚本 在根目录下 复制1pm2 start hexo_run.js]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>生活</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[集群]]></title>
    <url>%2F2019%2F06%2F14%2F%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[前言在前面的文章中，已经介绍了Redis的几种高可用技术：持久化、主从复制和哨兵，但这些方案仍有不足，其中最主要的问题是存储能力受单机限制，以及无法实现写操作的负载均衡。 Redis集群解决了上述问题，实现了较为完善的高可用方案。本文将详细介绍集群，主要内容包括：集群的作用；集群的搭建方法及设计方案；集群的基本原理；客户端访问集群的方法；以及其他实践中需要的集群知识（集群扩容、故障转移、参数优化等）。 一、集群的作用集群，即Redis Cluster，是Redis 3.0开始引入的分布式存储方案。 集群由多个节点(Node)组成，Redis的数据分布在这些节点中。集群中的节点分为主节点和从节点：只有主节点负责读写请求和集群信息的维护；从节点只进行主节点数据和状态信息的复制。 集群的作用，可以归纳为两点： 1、数据分区：数据分区(或称数据分片)是集群最核心的功能。 集群将数据分散到多个节点，一方面突破了Redis单机内存大小的限制，存储容量大大增加；另一方面每个主节点都可以对外提供读服务和写服务，大大提高了集群的响应能力。 Redis单机内存大小受限问题，在介绍持久化和主从复制时都有提及；例如，如果单机内存太大，bgsave和bgrewriteaof的fork操作可能导致主进程阻塞，主从环境下主机切换时可能导致从节点长时间无法提供服务，全量复制阶段主节点的复制缓冲区可能溢出……。 2、高可用：集群支持主从复制和主节点的自动故障转移（与哨兵类似）；当任一节点发生故障时，集群仍然可以对外提供服务。 本文内容基于Redis 3.0.6。 二、集群的搭建这一部分我们将搭建一个简单的集群：共6个节点，3主3从。方便起见：所有节点在同一台服务器上，以端口号进行区分；配置从简。3个主节点端口号：7000/7001/7002，对应的从节点端口号：8000/8001/8002。 集群的搭建有两种方式：（1）手动执行Redis命令，一步步完成搭建；（2）使用Ruby脚本搭建。二者搭建的原理是一样的，只是Ruby脚本将Redis命令进行了打包封装；在实际应用中推荐使用脚本方式，简单快捷不容易出错。下面分别介绍这两种方式。 执行Redis命令搭建集群 集群的搭建可以分为四步：（1）启动节点：将节点以集群模式启动，此时节点是独立的，并没有建立联系；（2）节点握手：让独立的节点连成一个网络；（3）分配槽：将16384个槽分配给主节点；（4）指定主从关系：为从节点指定主节点。 实际上，前三步完成后集群便可以对外提供服务；但指定从节点后，集群才能够提供真正高可用的服务。 （1）启动节点集群节点的启动仍然是使用redis-server命令，但需要使用集群模式启动。下面是7000节点的配置文件（只列出了节点正常工作关键配置，其他配置(如开启AOF)可以参照单机节点进行）： 1234567#redis-7000.confport 7000cluster-enabled yescluster-config-file &quot;node-7000.conf&quot;logfile &quot;log-7000.log&quot;dbfilename &quot;dump-7000.rdb&quot;daemonize yes 其中的cluster-enabled和cluster-config-file是与集群相关的配置。 cluster-enabledyes：Redis实例可以分为单机模式(standalone)和集群模式(cluster)；cluster-enabledyes可以启动集群模式。在单机模式下启动的Redis实例，如果执行infoserver命令，可以发现redis_mode一项为standalone，如下图所示： 集群模式下的节点，其redis_mode为cluster，如下图所示： cluster-config-file：该参数指定了集群配置文件的位置。每个节点在运行过程中，会维护一份集群配置文件；每当集群信息发生变化时（如增减节点），集群内所有节点会将最新信息更新到该配置文件；当节点重启后，会重新读取该配置文件，获取集群信息，可以方便的重新加入到集群中。也就是说，当Redis节点以集群模式启动时，会首先寻找是否有集群配置文件，如果有则使用文件中的配置启动，如果没有，则初始化配置并将配置保存到文件中。集群配置文件由Redis节点维护，不需要人工修改。 编辑好配置文件后，使用redis-server命令启动该节点： 1redis-server redis-7000.conf 节点启动以后，通过cluster nodes命令可以查看节点的情况，如下图所示。 其中返回值第一项表示节点id，由40个16进制字符串组成，节点id与 主从复制 一文中提到的runId不同：Redis每次启动runId都会重新创建，但是节点id只在集群初始化时创建一次，然后保存到集群配置文件中，以后节点重新启动时会直接在集群配置文件中读取。 其他节点使用相同办法启动，不再赘述。需要特别注意，在启动节点阶段，节点是没有主从关系的，因此从节点不需要加slaveof配置。 （2）节点握手节点启动以后是相互独立的，并不知道其他节点存在；需要进行节点握手，将独立的节点组成一个网络。 节点握手使用cluster meet {ip} {port}命令实现，例如在7000节点中执行cluster meet192.168.72.1287001，可以完成7000节点和7001节点的握手；注意ip使用的是局域网ip而不是localhost或127.0.0.1，是为了其他机器上的节点或客户端也可以访问。此时再使用clusternodes查看： 在7001节点下也可以类似查看： 同理，在7000节点中使用cluster meet命令，可以将所有节点加入到集群，完成节点握手： 1234cluster meet 192.168.72.128 7002cluster meet 192.168.72.128 8000cluster meet 192.168.72.128 8001cluster meet 192.168.72.128 8002 执行完上述命令后，可以看到7000节点已经感知到了所有其他节点： 通过节点之间的通信，每个节点都可以感知到所有其他节点，以8000节点为例： （3）分配槽在Redis集群中，借助槽实现数据分区，具体原理后文会介绍。集群有16384个槽，槽是数据管理和迁移的基本单位。当数据库中的16384个槽都分配了节点时，集群处于上线状态（ok）；如果有任意一个槽没有分配节点，则集群处于下线状态（fail）。 cluster info命令可以查看集群状态，分配槽之前状态为fail： 分配槽使用cluster addslots命令，执行下面的命令将槽（编号0-16383）全部分配完毕： 123redis-cli -p 7000 cluster addslots &#123;0..5461&#125;redis-cli -p 7001 cluster addslots &#123;5462..10922&#125;redis-cli -p 7002 cluster addslots &#123;10923..16383&#125; 此时查看集群状态，显示所有槽分配完毕，集群进入上线状态： （4）指定主从关系集群中指定主从关系不再使用slaveof命令，而是使用clusterreplicate命令；参数使用节点id。 通过clusternodes获得几个主节点的节点id后，执行下面的命令为每个从节点指定主节点： 123redis-cli -p 8000 cluster replicate be816eba968bc16c884b963d768c945e86ac51aeredis-cli -p 8001 cluster replicate 788b361563acb175ce8232569347812a12f1fdb4redis-cli -p 8002 cluster replicate a26f1624a3da3e5197dde267de683d61bb2dcbf1 此时执行cluster nodes查看各个节点的状态，可以看到主从关系已经建立。 至此，集群搭建完毕。 使用Ruby脚本搭建集群 在{REDIS_HOME}/src目录下可以看到redis-trib.rb文件，这是一个Ruby脚本，可以实现自动化的集群搭建。 （1）安装Ruby环境 以Ubuntu为例，如下操作即可安装Ruby环境： 12apt-get install ruby #安装ruby环境gem install redis #gem是ruby的包管理工具，该命令可以安装ruby-redis依赖 （2）启动节点 与第一种方法中的“启动节点”完全相同。 （3）搭建集群 redis-trib.rb脚本提供了众多命令，其中create用于搭建集群，使用方法如下： 1./redis-trib.rb create --replicas 1 192.168.72.128:7000 192.168.72.128:7001 192.168.72.128:7002 192.168.72.128:8000 192.168.72.128:8001 192.168.72.128:8002 其中：–replicas=1表示每个主节点有1个从节点；后面的多个{ip:port}表示节点地址，前面的做主节点，后面的做从节点。使用redis-trib.rb搭建集群时，要求节点不能包含任何槽和数据。 执行创建命令后，脚本会给出创建集群的计划，如下图所示；计划包括哪些是主节点，哪些是从节点，以及如何分配槽。 输入yes确认执行计划，脚本便开始按照计划执行，如下图所示。 至此，集群搭建完毕。 集群方案设计 设计集群方案时，至少要考虑以下因素： （1）高可用要求：根据故障转移的原理，至少需要3个主节点才能完成故障转移，且3个主节点不应在同一台物理机上；每个主节点至少需要1个从节点，且主从节点不应在一台物理机上；因此高可用集群至少包含6个节点。 （2）数据量和访问量：估算应用需要的数据量和总访问量(考虑业务发展，留有冗余)，结合每个主节点的容量和能承受的访问量(可以通过benchmark得到较准确估计)，计算需要的主节点数量。 （3）节点数量限制：Redis官方给出的节点数量限制为1000，主要是考虑节点间通信带来的消耗。在实际应用中应尽量避免大集群；如果节点数量不足以满足应用对Redis数据量和访问量的要求，可以考虑：(1)业务分割，大集群分为多个小集群；(2)减少不必要的数据；(3)调整数据过期策略等。 （4）适度冗余：Redis可以在不影响集群服务的情况下增加节点，因此节点数量适当冗余即可，不用太大。 三、集群的基本原理上一章介绍了集群的搭建方法和设计方案，下面将进一步深入，介绍集群的原理。集群最核心的功能是数据分区，因此首先介绍数据的分区规则；然后介绍集群实现的细节：通信机制和数据结构；最后以clustermeet(节点握手)、clusteraddslots(槽分配)为例，说明节点是如何利用上述数据结构和通信机制实现集群命令的。 数据分区方案 数据分区有顺序分区、哈希分区等，其中哈希分区由于其天然的随机性，使用广泛；集群的分区方案便是哈希分区的一种。 哈希分区的基本思路是：对数据的特征值（如key）进行哈希，然后根据哈希值决定数据落在哪个节点。常见的哈希分区包括：哈希取余分区、一致性哈希分区、带虚拟节点的一致性哈希分区等。 衡量数据分区方法好坏的标准有很多，其中比较重要的两个因素是(1)数据分布是否均匀(2)增加或删减节点对数据分布的影响。由于哈希的随机性，哈希分区基本可以保证数据分布均匀；因此在比较哈希分区方案时，重点要看增减节点对数据分布的影响。 （1）哈希取余分区 哈希取余分区思路非常简单：计算key的hash值，然后对节点数量进行取余，从而决定数据映射到哪个节点上。该方案最大的问题是，当新增或删减节点时，节点数量发生变化，系统中所有的数据都需要重新计算映射关系，引发大规模数据迁移。 （2）一致性哈希分区 一致性哈希算法将整个哈希值空间组织成一个虚拟的圆环，如下图所示，范围为0-2\^32-1；对于每个数据，根据key计算hash值，确定数据在环上的位置，然后从此位置沿环顺时针行走，找到的第一台服务器就是其应该映射到的服务器。 图片来源：https://www.cnblogs.com/lpfuture/p/5796398.html 与哈希取余分区相比，一致性哈希分区将增减节点的影响限制在相邻节点。以上图为例，如果在node1和node2之间增加node5，则只有node2中的一部分数据会迁移到node5；如果去掉node2，则原node2中的数据只会迁移到node4中，只有node4会受影响。 一致性哈希分区的主要问题在于，当节点数量较少时，增加或删减节点，对单个节点的影响可能很大，造成数据的严重不平衡。还是以上图为例，如果去掉node2，node4中的数据由总数据的1/4左右变为1/2左右，与其他节点相比负载过高。 （3）带虚拟节点的一致性哈希分区 该方案在一致性哈希分区的基础上，引入了虚拟节点的概念。Redis集群使用的便是该方案，其中的虚拟节点称为槽（slot）。槽是介于数据和实际节点之间的虚拟概念；每个实际节点包含一定数量的槽，每个槽包含哈希值在一定范围内的数据。引入槽以后，数据的映射关系由数据hash->实际节点，变成了数据hash->槽->实际节点。 在使用了槽的一致性哈希分区中，槽是数据管理和迁移的基本单位。槽解耦了数据和实际节点之间的关系，增加或删除节点对系统的影响很小。仍以上图为例，系统中有4个实际节点，假设为其分配16个槽(0-15)；槽0-3位于node1，4-7位于node2，以此类推。如果此时删除node2，只需要将槽4-7重新分配即可，例如槽4-5分配给node1，槽6分配给node3，槽7分配给node4；可以看出删除node2后，数据在其他节点的分布仍然较为均衡。 槽的数量一般远小于2\^32，远大于实际节点的数量；在Redis集群中，槽的数量为16384。 下面这张图很好的总结了Redis集群将数据映射到实际节点的过程： 图片来源：https://blog.csdn.net/yejingtao703/article/details/78484151 （1）Redis对数据的特征值（一般是key）计算哈希值，使用的算法是CRC16。 （2）根据哈希值，计算数据属于哪个槽。 （3）根据槽与节点的映射关系，计算数据属于哪个节点。 节点通信机制 集群要作为一个整体工作，离不开节点之间的通信。 两个端口在哨兵系统中，节点分为数据节点和哨兵节点：前者存储数据，后者实现额外的控制功能。在集群中，没有数据节点与非数据节点之分：所有的节点都存储数据，也都参与集群状态的维护。为此，集群中的每个节点，都提供了两个TCP端口： 普通端口：即我们在前面指定的端口(7000等)。普通端口主要用于为客户端提供服务（与单机节点类似）；但在节点间数据迁移时也会使用。 集群端口：端口号是普通端口+10000（10000是固定值，无法改变），如7000节点的集群端口为17000。集群端口只用于节点之间的通信，如搭建集群、增减节点、故障转移等操作时节点间的通信；不要使用客户端连接集群接口。为了保证集群可以正常工作，在配置防火墙时，要同时开启普通端口和集群端口。 Gossip协议节点间通信，按照通信协议可以分为几种类型：单对单、广播、Gossip协议等。重点是广播和Gossip的对比。 广播是指向集群内所有节点发送消息；优点是集群的收敛速度快(集群收敛是指集群内所有节点获得的集群信息是一致的)，缺点是每条消息都要发送给所有节点，CPU、带宽等消耗较大。 Gossip协议的特点是：在节点数量有限的网络中，每个节点都“随机”的与部分节点通信（并不是真正的随机，而是根据特定的规则选择通信的节点），经过一番杂乱无章的通信，每个节点的状态很快会达到一致。Gossip协议的优点有负载(比广播)低、去中心化、容错性高(因为通信有冗余)等；缺点主要是集群的收敛速度慢。 消息类型集群中的节点采用固定频率（每秒10次）的定时任务进行通信相关的工作：判断是否需要发送消息及消息类型、确定接收节点、发送消息等。如果集群状态发生了变化，如增减节点、槽状态变更，通过节点间的通信，所有节点会很快得知整个集群的状态，使集群收敛。 节点间发送的消息主要分为5种：meet消息、ping消息、pong消息、fail消息、publish消息。不同的消息类型，通信协议、发送的频率和时机、接收节点的选择等是不同的。 MEET消息：在节点握手阶段，当节点收到客户端的CLUSTERMEET命令时，会向新加入的节点发送MEET消息，请求新节点加入到当前集群；新节点收到MEET消息后会回复一个PONG消息。 PING消息：集群里每个节点每秒钟会选择部分节点发送PING消息，接收者收到消息后会回复一个PONG消息。PING消息的内容是自身节点和部分其他节点的状态信息；作用是彼此交换信息，以及检测节点是否在线。PING消息使用Gossip协议发送，接收节点的选择兼顾了收敛速度和带宽成本，具体规则如下：(1)随机找5个节点，在其中选择最久没有通信的1个节点(2)扫描节点列表，选择最近一次收到PONG消息时间大于cluster_node_timeout/2的所有节点，防止这些节点长时间未更新。 PONG消息：PONG消息封装了自身状态数据。可以分为两种：第一种是在接到MEET/PING消息后回复的PONG消息；第二种是指节点向集群广播PONG消息，这样其他节点可以获知该节点的最新信息，例如故障恢复后新的主节点会广播PONG消息。 FAIL消息：当一个主节点判断另一个主节点进入FAIL状态时，会向集群广播这一FAIL消息；接收节点会将这一FAIL消息保存起来，便于后续的判断。 PUBLISH消息：节点收到PUBLISH命令后，会先执行该命令，然后向集群广播这一消息，接收节点也会执行该PUBLISH命令。 数据结构 节点需要专门的数据结构来存储集群的状态。所谓集群的状态，是一个比较大的概念，包括：集群是否处于上线状态、集群中有哪些节点、节点是否可达、节点的主从状态、槽的分布…… 节点为了存储集群状态而提供的数据结构中，最关键的是clusterNode和clusterState结构：前者记录了一个节点的状态，后者记录了集群作为一个整体的状态。 clusterNodeclusterNode结构保存了一个节点的当前状态，包括创建时间、节点id、ip和端口号等。每个节点都会用一个clusterNode结构记录自己的状态，并为集群内所有其他节点都创建一个clusterNode结构来记录节点状态。 下面列举了clusterNode的部分字段，并说明了字段的含义和作用：1234567891011121314151617181920212223242526typedef struct clusterNode &#123; //节点创建时间 mstime_t ctime; //节点id char name[REDIS_CLUSTER_NAMELEN]; //节点的ip和端口号 char ip[REDIS_IP_STR_LEN]; int port; //节点标识：整型，每个bit都代表了不同状态，如节点的主从状态、是否在线、是否在握手等 int flags; //配置纪元：故障转移时起作用，类似于哨兵的配置纪元 uint64_t configEpoch; //槽在该节点中的分布：占用16384/8个字节，16384个比特；每个比特对应一个槽：比特值为1，则该比特对应的槽在节点中；比特值为0，则该比特对应的槽不在节点中 unsigned char slots[16384/8]; //节点中槽的数量 int numslots; ………… &#125; clusterNode; 除了上述字段，clusterNode还包含节点连接、主从复制、故障发现和转移需要的信息等。 clusterStateclusterState结构保存了在当前节点视角下，集群所处的状态。主要字段包括：1234567891011121314151617181920212223typedef struct clusterState &#123; //自身节点 clusterNode *myself; //配置纪元 uint64_t currentEpoch; //集群状态：在线还是下线 int state; //集群中至少包含一个槽的节点数量 int size; //哈希表，节点名称-&gt;clusterNode节点指针 dict *nodes; //槽分布信息：数组的每个元素都是一个指向clusterNode结构的指针；如果槽还没有分配给任何节点，则为NULL clusterNode *slots[16384]; ………… &#125; clusterState; 除此之外，clusterState还包括故障转移、槽迁移等需要的信息。 集群命令的实现 这一部分将以cluster meet(节点握手)、clusteraddslots(槽分配)为例，说明节点是如何利用上述数据结构和通信机制实现集群命令的。 cluster meet假设要向A节点发送clustermeet命令，将B节点加入到A所在的集群，则A节点收到命令后，执行的操作如下： 1) A为B创建一个clusterNode结构，并将其添加到clusterState的nodes字典中 2) A向B发送MEET消息 3) B收到MEET消息后，会为A创建一个clusterNode结构，并将其添加到clusterState的nodes字典中 4) B回复A一个PONG消息 5) A收到B的PONG消息后，便知道B已经成功接收自己的MEET消息 6) 然后，A向B返回一个PING消息 7) B收到A的PING消息后，便知道A已经成功接收自己的PONG消息，握手完成 8) 之后，A通过Gossip协议将B的信息广播给集群内其他节点，其他节点也会与B握手；一段时间后，集群收敛，B成为集群内的一个普通节点 通过上述过程可以发现，集群中两个节点的握手过程与TCP类似，都是三次握手：A向B发送MEET；B向A发送PONG；A向B发送PING。 cluster addslots集群中槽的分配信息，存储在clusterNode的slots数组和clusterState的slots数组中，两个数组的结构前面已做介绍；二者的区别在于：前者存储的是该节点中分配了哪些槽，后者存储的是集群中所有槽分别分布在哪个节点。 cluster addslots命令接收一个槽或多个槽作为参数，例如在A节点上执行clusteraddslots {0..10}命令，是将编号为0-10的槽分配给A节点，具体执行过程如下： 1) 遍历输入槽，检查它们是否都没有分配，如果有一个槽已分配，命令执行失败；方法是检查输入槽在clusterState.slots[]中对应的值是否为NULL。 2) 遍历输入槽，将其分配给节点A；方法是修改clusterNode.slots[]中对应的比特为1，以及clusterState.slots[]中对应的指针指向A节点 3) A节点执行完成后，通过节点通信机制通知其他节点，所有节点都会知道0-10的槽分配给了A节点 四、客户端访问集群在集群中，数据分布在不同的节点中，客户端通过某节点访问数据时，数据可能不在该节点中；下面介绍集群是如何处理这个问题的。 redis-cli 当节点收到redis-cli发来的命令(如set/get)时，过程如下： （1）计算key属于哪个槽：CRC16(key) &amp; 16383 集群提供的cluster keyslot命令也是使用上述公式实现，如： （2）判断key所在的槽是否在当前节点：假设key位于第i个槽，clusterState.slots[i]则指向了槽所在的节点，如果clusterState.slots[i]==clusterState.myself，说明槽在当前节点，可以直接在当前节点执行命令；否则，说明槽不在当前节点，则查询槽所在节点的地址(clusterState.slots[i].ip/port)，并将其包装到MOVED错误中返回给redis-cli。 （3）redis-cli收到MOVED错误后，根据返回的ip和port重新发送请求。 下面的例子展示了redis-cli和集群的互动过程：在7000节点中操作key1，但key1所在的槽9189在节点7001中，因此节点返回MOVED错误(包含7001节点的ip和port)给redis-cli，redis-cli重新向7001发起请求。 上例中，redis-cli通过-c指定了集群模式，如果没有指定，redis-cli无法处理MOVED错误： Smart客户端 redis-cli这一类客户端称为Dummy客户端，因为它们在执行命令前不知道数据在哪个节点，需要借助MOVED错误重新定向。与Dummy客户端相对应的是Smart客户端。 Smart客户端（以Java的JedisCluster为例）的基本原理： （1）JedisCluster初始化时，在内部维护slot->node的缓存，方法是连接任一节点，执行clusterslots命令，该命令返回如下所示： （2）此外，JedisCluster为每个节点创建连接池(即JedisPool)。 （3）当执行命令时，JedisCluster根据key->slot->node选择需要连接的节点，发送命令。如果成功，则命令执行完毕。如果执行失败，则会随机选择其他节点进行重试，并在出现MOVED错误时，使用clusterslots重新同步slot->node的映射关系。 下面代码演示了如何使用JedisCluster访问集群(未考虑资源释放、异常处理等)： 123456789101112public static void test() &#123; Set&lt;HostAndPort&gt; nodes = new HashSet&lt;&gt;(); nodes.add(new HostAndPort(&quot;192.168.72.128&quot;, 7000)); nodes.add(new HostAndPort(&quot;192.168.72.128&quot;, 7001)); nodes.add(new HostAndPort(&quot;192.168.72.128&quot;, 7002)); nodes.add(new HostAndPort(&quot;192.168.72.128&quot;, 8000)); nodes.add(new HostAndPort(&quot;192.168.72.128&quot;, 8001)); nodes.add(new HostAndPort(&quot;192.168.72.128&quot;, 8002)); JedisCluster cluster = new JedisCluster(nodes); System.out.println(cluster.get(&quot;key1&quot;)); cluster.close();&#125; 注意事项如下： （1）JedisCluster中已经包含所有节点的连接池，因此JedisCluster要使用单例。 （2）客户端维护了slot->node映射关系以及为每个节点创建了连接池，当节点数量较多时，应注意客户端内存资源和连接资源的消耗。 （3）Jedis较新版本针对JedisCluster做了一些性能方面的优化，如clusterslots缓存更新和锁阻塞等方面的优化，应尽量使用2.8.2及以上版本的Jedis。 五、实践须知前面介绍了集群正常运行和访问的方法和原理，下面是一些重要的补充内容。 集群伸缩 实践中常常需要对集群进行伸缩，如访问量增大时的扩容操作。Redis集群可以在不影响对外服务的情况下实现伸缩；伸缩的核心是槽迁移：修改槽与节点的对应关系，实现槽(即数据)在节点之间的移动。例如，如果槽均匀分布在集群的3个节点中，此时增加一个节点，则需要从3个节点中分别拿出一部分槽给新节点，从而实现槽在4个节点中的均匀分布。 增加节点假设要增加7003和8003节点，其中8003是7003的从节点；步骤如下： （1）启动节点：方法参见集群搭建 （2）节点握手：可以使用clustermeet命令，但在生产环境中建议使用redis-trib.rb的add-node工具，其原理也是clustermeet，但它会先检查新节点是否已加入其它集群或者存在数据，避免加入到集群后带来混乱。 12redis-trib.rb add-node 192.168.72.128:7003 192.168.72.128 7000redis-trib.rb add-node 192.168.72.128:8003 192.168.72.128 7000 （3）迁移槽：推荐使用redis-trib.rb的reshard工具实现。reshard自动化程度很高，只需要输入redis-trib.rbreshard ip:port(ip和port可以是集群中的任一节点)，然后按照提示输入以下信息，槽迁移会自动完成： 待迁移的槽数量：16384个槽均分给4个节点，每个节点4096个槽，因此待迁移槽数量为4096 目标节点id：7003节点的id 源节点的id：7000/7001/7002节点的id （4）指定主从关系：方法参见集群搭建 减少节点假设要下线7000/8000节点，可以分为两步： （1）迁移槽：使用reshard将7000节点中的槽均匀迁移到7001/7002/7003节点 （2）下线节点：使用redis-trib.rbdel-node工具；应先下线从节点再下线主节点，因为若主节点先下线，从节点会被指向其他主节点，造成不必要的全量复制。 12redis-trib.rb del-node 192.168.72.128:7001 &#123;节点8000的id&#125;redis-trib.rb del-node 192.168.72.128:7001 &#123;节点7000的id&#125; ASK错误集群伸缩的核心是槽迁移。在槽迁移过程中，如果客户端向源节点发送命令，源节点执行流程如下： 图片来源：《Redis设计与实现》 客户端收到ASK错误后，从中读取目标节点的地址信息，并向目标节点重新发送请求，就像收到MOVED错误时一样。但是二者有很大区别：ASK错误说明数据正在迁移，不知道何时迁移完成，因此重定向是临时的，SMART客户端不会刷新slots缓存；MOVED错误重定向则是(相对)永久的，SMART客户端会刷新slots缓存。 故障转移 在 哨兵 一文中，介绍了哨兵实现故障发现和故障转移的原理。虽然细节上有很大不同，但集群的实现与哨兵思路类似：通过定时任务发送PING消息检测其他节点状态；节点下线分为主观下线和客观下线；客观下线后选取从节点进行故障转移。 与哨兵一样，集群只实现了主节点的故障转移；从节点故障时只会被下线，不会进行故障转移。因此，使用集群时，应谨慎使用读写分离技术，因为从节点故障会导致读服务不可用，可用性变差。 这里不再详细介绍故障转移的细节，只对重要事项进行说明： 节点数量：在故障转移阶段，需要由主节点投票选出哪个从节点成为新的主节点；从节点选举胜出需要的票数为N/2+1；其中N为主节点数量(包括故障主节点)，但故障主节点实际上不能投票。因此为了能够在故障发生时顺利选出从节点，集群中至少需要3个主节点(且部署在不同的物理机上)。 故障转移时间：从主节点故障发生到完成转移，所需要的时间主要消耗在主观下线识别、主观下线传播、选举延迟等几个环节；具体时间与参数cluster-node-timeout有关，一般来说： 故障转移时间(毫秒) ≤ 1.5 * cluster-node-timeout + 1000 cluster-node-timeout的默认值为15000ms(15s)，因此故障转移时间会在20s量级。 集群的限制及应对方法 由于集群中的数据分布在不同节点中，导致一些功能受限，包括： （1）key批量操作受限：例如mget、mset操作，只有当操作的key都位于一个槽时，才能进行。针对该问题，一种思路是在客户端记录槽与key的信息，每次针对特定槽执行mget/mset；另外一种思路是使用HashTag，将在下一小节介绍。 （2）keys/flushall等操作：keys/flushall等操作可以在任一节点执行，但是结果只针对当前节点，例如keys操作只返回当前节点的所有键。针对该问题，可以在客户端使用clusternodes获取所有节点信息，并对其中的所有主节点执行keys/flushall等操作。 （3）事务/Lua脚本：集群支持事务及Lua脚本，但前提条件是所涉及的key必须在同一个节点。HashTag可以解决该问题。 （4）数据库：单机Redis节点可以支持16个数据库，集群模式下只支持一个，即db0。 （5）复制结构：只支持一层复制结构，不支持嵌套。 Hash Tag Hash Tag原理是：当一个key包含 {} 的时候，不对整个key做hash，而仅对{} 包括的字符串做hash。 HashTag可以让不同的key拥有相同的hash值，从而分配在同一个槽里；这样针对不同key的批量操作(mget/mset等)，以及事务、Lua脚本等都可以支持。不过HashTag可能会带来数据分配不均的问题，这时需要：(1)调整不同节点中槽的数量，使数据分布尽量均匀；(2)避免对热点数据使用HashTag，导致请求分布不均。 下面是使用Hash Tag的一个例子；通过对product加HashTag，可以将所有产品信息放到同一个槽中，便于操作。 参数优化 cluster_node_timeoutcluster_node_timeout参数在前面已经初步介绍；它的默认值是15s，影响包括： （1）影响PING消息接收节点的选择：值越大对延迟容忍度越高，选择的接收节点越少，可以降低带宽，但会降低收敛速度；应根据带宽情况和应用要求进行调整。 （2）影响故障转移的判定和时间：值越大，越不容易误判，但完成转移消耗时间越长；应根据网络状况和应用要求进行调整。 cluster-require-full-coverage前面提到，只有当16384个槽全部分配完毕时，集群才能上线。这样做是为了保证集群的完整性，但同时也带来了新的问题：当主节点发生故障而故障转移尚未完成，原主节点中的槽不在任何节点中，此时会集群处于下线状态，无法响应客户端的请求。 cluster-require-full-coverage参数可以改变这一设定：如果设置为no，则当槽没有完全分配时，集群仍可以上线。参数默认值为yes，如果应用对可用性要求较高，可以修改为no，但需要自己保证槽全部分配。 redis-trib.rb redis-trib.rb提供了众多实用工具：创建集群、增减节点、槽迁移、检查完整性、数据重新平衡等；通过help命令可以查看详细信息。在实践中如果能使用redis-trib.rb工具则尽量使用，不但方便快捷，还可以大大降低出错概率。 参考文献《Redis开发与运维》 《Redis设计与实现》 https://redis.io/topics/cluster-tutorial https://redis.io/topics/cluster-spec https://mp.weixin.qq.com/s/d6hzmk31o7VBsMYaLdQ5mw https://www.cnblogs.com/lpfuture/p/5796398.html http://www.zsythink.net/archives/1182/ https://www.cnblogs.com/xxdfly/p/5641719.html]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>redis深入系统学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[哨兵]]></title>
    <url>%2F2019%2F06%2F14%2F%E5%93%A8%E5%85%B5%2F</url>
    <content type="text"><![CDATA[前言在 深入学习Redis（3）：主从复制 中曾提到，Redis主从复制的作用有数据热备、负载均衡、故障恢复等；但主从复制存在的一个问题是故障恢复无法自动化。本文将要介绍的哨兵，它基于Redis主从复制，主要作用便是解决主节点故障恢复的自动化问题，进一步提高系统的高可用性。 文章主要内容如下：首先介绍哨兵的作用和架构；然后讲述哨兵系统的部署方法，以及通过客户端访问哨兵系统的方法；然后简要说明哨兵实现的基本原理；最后给出关于哨兵实践的一些建议。文章内容基于Redis3.0版本。 一、作用和架构 作用 在介绍哨兵之前，首先从宏观角度回顾一下Redis实现高可用相关的技术。它们包括：持久化、复制、哨兵和集群，其主要作用和解决的问题是： 持久化：持久化是最简单的高可用方法(有时甚至不被归为高可用的手段)，主要作用是数据备份，即将数据存储在硬盘，保证数据不会因进程退出而丢失。 复制：复制是高可用Redis的基础，哨兵和集群都是在复制基础上实现高可用的。复制主要实现了数据的多机备份，以及对于读操作的负载均衡和简单的故障恢复。缺陷：故障恢复无法自动化；写操作无法负载均衡；存储能力受到单机的限制。 哨兵：在复制的基础上，哨兵实现了自动化的故障恢复。缺陷：写操作无法负载均衡；存储能力受到单机的限制。 集群：通过集群，Redis解决了写操作无法负载均衡，以及存储能力受到单机限制的问题，实现了较为完善的高可用方案。 下面说回哨兵。 Redis Sentinel，即Redis哨兵，在Redis2.8版本开始引入。哨兵的核心功能是主节点的自动故障转移。下面是Redis官方文档对于哨兵功能的描述： 监控（Monitoring）：哨兵会不断地检查主节点和从节点是否运作正常。 自动故障转移（Automaticfailover）：当主节点不能正常工作时，哨兵会开始自动故障转移操作，它会将失效主节点的其中一个从节点升级为新的主节点，并让其他从节点改为复制新的主节点。 配置提供者（Configurationprovider）：客户端在初始化时，通过连接哨兵来获得当前Redis服务的主节点地址。 通知（Notification）：哨兵可以将故障转移的结果发送给客户端。 其中，监控和自动故障转移功能，使得哨兵可以及时发现主节点故障并完成转移；而配置提供者和通知功能，则需要在与客户端的交互中才能体现。 这里对“客户端”一词在文章中的用法做一个说明：在前面的文章中，只要通过API访问redis服务器，都会称作客户端，包括redis-cli、Java客户端Jedis等；为了便于区分说明，本文中的客户端并不包括redis-cli，而是比redis-cli更加复杂：redis-cli使用的是redis提供的底层接口，而客户端则对这些接口、功能进行了封装，以便充分利用哨兵的配置提供者和通知功能。 架构 典型的哨兵架构图如下所示： 它由两部分组成，哨兵节点和数据节点： 哨兵节点：哨兵系统由一个或多个哨兵节点组成，哨兵节点是特殊的redis节点，不存储数据。 数据节点：主节点和从节点都是数据节点。 二、部署这一部分将部署一个简单的哨兵系统，包含1个主节点、2个从节点和3个哨兵节点。方便起见：所有这些节点都部署在一台机器上（局域网IP：192.168.92.128），使用端口号区分；节点的配置尽可能简化。 部署主从节点 哨兵系统中的主从节点，与普通的主从节点配置是一样的，并不需要做任何额外配置。下面分别是主节点（port=6379）和2个从节点（port=6380/6381）的配置文件，配置都比较简单，不再详述。12345678910111213141516171819#redis-6379.confport 6379daemonize yeslogfile &quot;6379.log&quot;dbfilename &quot;dump-6379.rdb&quot; #redis-6380.confport 6380daemonize yeslogfile &quot;6380.log&quot;dbfilename &quot;dump-6380.rdb&quot;slaveof 192.168.92.128 6379 #redis-6381.confport 6381daemonize yeslogfile &quot;6381.log&quot;dbfilename &quot;dump-6381.rdb&quot;slaveof 192.168.92.128 6379 配置完成后，依次启动主节点和从节点：123redis-server redis-6379.confredis-server redis-6380.confredis-server redis-6381.conf 节点启动后，连接主节点查看主从状态是否正常，如下图所示： 部署哨兵节点 哨兵节点本质上是特殊的Redis节点。 3个哨兵节点的配置几乎是完全一样的，主要区别在于端口号的不同（26379/26380/26381），下面以26379节点为例介绍节点的配置和启动方式；配置部分尽量简化，更多配置会在后面介绍。12345#sentinel-26379.confport 26379daemonize yeslogfile &quot;26379.log&quot;sentinel monitor mymaster 192.168.92.128 6379 2 其中，sentinel monitor mymaster 192.168.92.128 6379 2配置的含义是：该哨兵节点监控192.168.92.128:6379这个主节点，该主节点的名称是mymaster，最后的2的含义与主节点的故障判定有关：至少需要2个哨兵节点同意，才能判定主节点故障并进行故障转移。 哨兵节点的启动有两种方式，二者作用是完全相同的： 12redis-sentinel sentinel-26379.confredis-server sentinel-26379.conf --sentinel 按照上述方式配置和启动之后，整个哨兵系统就启动完毕了。可以通过redis-cli连接哨兵节点进行验证，如下图所示：可以看出26379哨兵节点已经在监控mymaster主节点(即192.168.92.128:6379)，并发现了其2个从节点和另外2个哨兵节点。 此时如果查看哨兵节点的配置文件，会发现一些变化，以26379为例： 其中，dir只是显式声明了数据和日志所在的目录（在哨兵语境下只有日志）；known-slave和known-sentinel显示哨兵已经发现了从节点和其他哨兵；带有epoch的参数与配置纪元有关（配置纪元是一个从0开始的计数器，每进行一次领导者哨兵选举，都会+1；领导者哨兵选举是故障转移阶段的一个操作，在后文原理部分会介绍）。 演示故障转移 哨兵的4个作用中，配置提供者和通知需要客户端的配合，本文将在下一章介绍客户端访问哨兵系统的方法时详细介绍。这一小节将演示当主节点发生故障时，哨兵的监控和自动故障转移功能。 （1）首先，使用kill命令杀掉主节点： （2）如果此时立即在哨兵节点中使用infoSentinel命令查看，会发现主节点还没有切换过来，因为哨兵发现主节点故障并转移，需要一段时间。 （3）一段时间以后，再次在哨兵节点中执行infoSentinel查看，发现主节点已经切换成6380节点。 但是同时可以发现，哨兵节点认为新的主节点仍然有2个从节点，这是因为哨兵在将6380切换成主节点的同时，将6379节点置为其从节点；虽然6379从节点已经挂掉，但是由于哨兵并不会对从节点进行客观下线（其含义将在原理部分介绍），因此认为该从节点一直存在。当6379节点重新启动后，会自动变成6380节点的从节点。下面验证一下。 （4）重启6379节点：可以看到6379节点成为了6380节点的从节点。 （5）在故障转移阶段，哨兵和主从节点的配置文件都会被改写。 对于主从节点，主要是slaveof配置的变化：新的主节点没有了slaveof配置，其从节点则slaveof新的主节点。 对于哨兵节点，除了主从节点信息的变化，纪元(epoch)也会变化，下图中可以看到纪元相关的参数都+1了。 总结 哨兵系统的搭建过程，有几点需要注意： （1）哨兵系统中的主从节点，与普通的主从节点并没有什么区别，故障发现和转移是由哨兵来控制和完成的。 （2）哨兵节点本质上是redis节点。 （3）每个哨兵节点，只需要配置监控主节点，便可以自动发现其他的哨兵节点和从节点。 （4）在哨兵节点启动和故障转移阶段，各个节点的配置文件会被重写(config rewrite)。 （5）本章的例子中，一个哨兵只监控了一个主节点；实际上，一个哨兵可以监控多个主节点，通过配置多条sentinelmonitor即可实现。 三、客户端访问哨兵系统上一小节演示了哨兵的两大作用：监控和自动故障转移，本小节则结合客户端演示哨兵的另外两个作用：配置提供者和通知。 代码示例 在介绍客户端的原理之前，先以Java客户端Jedis为例，演示一下使用方法：下面代码可以连接我们刚刚搭建的哨兵系统，并进行各种读写操作（代码中只演示如何连接哨兵，异常处理、资源关闭等未考虑）。 123456789101112public static void testSentinel() throws Exception &#123; String masterName = &quot;mymaster&quot;; Set&lt;String&gt; sentinels = new HashSet&lt;&gt;(); sentinels.add(&quot;192.168.92.128:26379&quot;); sentinels.add(&quot;192.168.92.128:26380&quot;); sentinels.add(&quot;192.168.92.128:26381&quot;); JedisSentinelPool pool = new JedisSentinelPool(masterName, sentinels); //初始化过程做了很多工作 Jedis jedis = pool.getResource(); jedis.set(&quot;key1&quot;, &quot;value1&quot;); pool.close();&#125; 客户端原理 Jedis客户端对哨兵提供了很好的支持。如上述代码所示，我们只需要向Jedis提供哨兵节点集合和masterName，构造JedisSentinelPool对象；然后便可以像使用普通redis连接池一样来使用了：通过pool.getResource()获取连接，执行具体的命令。 在整个过程中，我们的代码不需要显式的指定主节点的地址，就可以连接到主节点；代码中对故障转移没有任何体现，就可以在哨兵完成故障转移后自动的切换主节点。之所以可以做到这一点，是因为在JedisSentinelPool的构造器中，进行了相关的工作；主要包括以下两点： （1）遍历哨兵节点，获取主节点信息：遍历哨兵节点，通过其中一个哨兵节点+masterName获得主节点的信息；该功能是通过调用哨兵节点的sentinelget-master-addr-by-name命令实现，该命令示例如下： 一旦获得主节点信息，停止遍历（因此一般来说遍历到第一个哨兵节点，循环就停止了）。 （2）增加对哨兵的监听：这样当发生故障转移时，客户端便可以收到哨兵的通知，从而完成主节点的切换。具体做法是：利用redis提供的发布订阅功能，为每一个哨兵节点开启一个单独的线程，订阅哨兵节点的+switch-master频道，当收到消息时，重新初始化连接池。 总结 通过客户端原理的介绍，可以加深对哨兵功能的理解： （1）配置提供者：客户端可以通过哨兵节点+masterName获取主节点信息，在这里哨兵起到的作用就是配置提供者。 需要注意的是，哨兵只是配置提供者，而不是代理。二者的区别在于：如果是配置提供者，客户端在通过哨兵获得主节点信息后，会直接建立到主节点的连接，后续的请求(如set/get)会直接发向主节点；如果是代理，客户端的每一次请求都会发向哨兵，哨兵再通过主节点处理请求。 举一个例子可以很好的理解哨兵的作用是配置提供者，而不是代理。在前面部署的哨兵系统中，将哨兵节点的配置文件进行如下修改： 123sentinel monitor mymaster 192.168.92.128 6379 2改为sentinel monitor mymaster 127.0.0.1 6379 2 然后，将前述客户端代码在局域网的另外一台机器上运行，会发现客户端无法连接主节点；这是因为哨兵作为配置提供者，客户端通过它查询到主节点的地址为127.0.0.1:6379，客户端会向127.0.0.1:6379建立redis连接，自然无法连接。如果哨兵是代理，这个问题就不会出现了。 （2）通知：哨兵节点在故障转移完成后，会将新的主节点信息发送给客户端，以便客户端及时切换主节点。 四、基本原理前面介绍了哨兵部署、使用的基本方法，本部分介绍哨兵实现的基本原理。 哨兵节点支持的命令 哨兵节点作为运行在特殊模式下的redis节点，其支持的命令与普通的redis节点不同。在运维中，我们可以通过这些命令查询或修改哨兵系统；不过更重要的是，哨兵系统要实现故障发现、故障转移等各种功能，离不开哨兵节点之间的通信，而通信的很大一部分是通过哨兵节点支持的命令来实现的。下面介绍哨兵节点支持的主要命令。 （1）基础查询：通过这些命令，可以查询哨兵系统的拓扑结构、节点信息、配置信息等。 info sentinel：获取监控的所有主节点的基本信息 sentinel masters：获取监控的所有主节点的详细信息 sentinel master mymaster：获取监控的主节点mymaster的详细信息 sentinel slaves mymaster：获取监控的主节点mymaster的从节点的详细信息 sentinel sentinels mymaster：获取监控的主节点mymaster的哨兵节点的详细信息 sentinel get-master-addr-by-namemymaster：获取监控的主节点mymaster的地址信息，前文已有介绍 sentinelis-master-down-by-addr：哨兵节点之间可以通过该命令询问主节点是否下线，从而对是否客观下线做出判断 （2）增加/移除对主节点的监控 sentinel monitor mymaster2 192.168.92.128 163792：与部署哨兵节点时配置文件中的sentinel monitor功能完全一样，不再详述 sentinel remove mymaster2：取消当前哨兵节点对主节点mymaster2的监控 （3）强制故障转移 sentinel failovermymaster：该命令可以强制对mymaster执行故障转移，即便当前的主节点运行完好；例如，如果当前主节点所在机器即将报废，便可以提前通过failover命令进行故障转移。 基本原理 关于哨兵的原理，关键是了解以下几个概念。 （1）定时任务：每个哨兵节点维护了3个定时任务。定时任务的功能分别如下：通过向主从节点发送info命令获取最新的主从结构；通过发布订阅功能获取其他哨兵节点的信息；通过向其他节点发送ping命令进行心跳检测，判断是否下线。 （2）主观下线：在心跳检测的定时任务中，如果其他节点超过一定时间没有回复，哨兵节点就会将其进行主观下线。顾名思义，主观下线的意思是一个哨兵节点“主观地”判断下线；与主观下线相对应的是客观下线。 （3）客观下线：哨兵节点在对主节点进行主观下线后，会通过sentinelis-master-down-by-addr命令询问其他哨兵节点该主节点的状态；如果判断主节点下线的哨兵数量达到一定数值，则对该主节点进行客观下线。 需要特别注意的是，客观下线是主节点才有的概念；如果从节点和哨兵节点发生故障，被哨兵主观下线后，不会再有后续的客观下线和故障转移操作。 （4）选举领导者哨兵节点：当主节点被判断客观下线以后，各个哨兵节点会进行协商，选举出一个领导者哨兵节点，并由该领导者节点对其进行故障转移操作。 监视该主节点的所有哨兵都有可能被选为领导者，选举使用的算法是Raft算法；Raft算法的基本思路是先到先得：即在一轮选举中，哨兵A向B发送成为领导者的申请，如果B没有同意过其他哨兵，则会同意A成为领导者。选举的具体过程这里不做详细描述，一般来说，哨兵选择的过程很快，谁先完成客观下线，一般就能成为领导者。 （5）故障转移：选举出的领导者哨兵，开始进行故障转移操作，该操作大体可以分为3个步骤： 在从节点中选择新的主节点：选择的原则是，首先过滤掉不健康的从节点；然后选择优先级最高的从节点(由slave-priority指定)；如果优先级无法区分，则选择复制偏移量最大的从节点；如果仍无法区分，则选择runid最小的从节点。 更新主从状态：通过slaveof noone命令，让选出来的从节点成为主节点；并通过slaveof命令让其他节点成为其从节点。 将已经下线的主节点(即6379)设置为新的主节点的从节点，当6379重新上线后，它会成为新的主节点的从节点。 通过上述几个关键概念，可以基本了解哨兵的工作原理。为了更形象的说明，下图展示了领导者哨兵节点的日志，包括从节点启动到完成故障转移。 五、配置与实践建议 配置 下面介绍与哨兵相关的几个配置。 （1） sentinel monitor {masterName} {masterIp} {masterPort} {quorum} sentinelmonitor是哨兵最核心的配置，在前文讲述部署哨兵节点时已说明，其中：masterName指定了主节点名称，masterIp和masterPort指定了主节点地址，quorum是判断主节点客观下线的哨兵数量阈值：当判定主节点下线的哨兵数量达到quorum时，对主节点进行客观下线。建议取值为哨兵数量的一半加1。 （2） sentinel down-after-milliseconds {masterName} {time} sentineldown-after-milliseconds与主观下线的判断有关：哨兵使用ping命令对其他节点进行心跳检测，如果其他节点超过down-after-milliseconds配置的时间没有回复，哨兵就会将其进行主观下线。该配置对主节点、从节点和哨兵节点的主观下线判定都有效。 down-after-milliseconds的默认值是30000，即30s；可以根据不同的网络环境和应用要求来调整：值越大，对主观下线的判定会越宽松，好处是误判的可能性小，坏处是故障发现和故障转移的时间变长，客户端等待的时间也会变长。例如，如果应用对可用性要求较高，则可以将值适当调小，当故障发生时尽快完成转移；如果网络环境相对较差，可以适当提高该阈值，避免频繁误判。 （3） sentinel parallel-syncs {masterName} {number} sentinelparallel-syncs与故障转移之后从节点的复制有关：它规定了每次向新的主节点发起复制操作的从节点个数。例如，假设主节点切换完成之后，有3个从节点要向新的主节点发起复制；如果parallel-syncs=1，则从节点会一个一个开始复制；如果parallel-syncs=3，则3个从节点会一起开始复制。 parallel-syncs取值越大，从节点完成复制的时间越快，但是对主节点的网络负载、硬盘负载造成的压力也越大；应根据实际情况设置。例如，如果主节点的负载较低，而从节点对服务可用的要求较高，可以适量增加parallel-syncs取值。parallel-syncs的默认值是1。 （4） sentinel failover-timeout {masterName} {time} sentinelfailover-timeout与故障转移超时的判断有关，但是该参数不是用来判断整个故障转移阶段的超时，而是其几个子阶段的超时，例如如果主节点晋升从节点时间超过timeout，或从节点向新的主节点发起复制操作的时间(不包括复制数据的时间)超过timeout，都会导致故障转移超时失败。 failover-timeout的默认值是180000，即180s；如果超时，则下一次该值会变为原来的2倍。 （5）除上述几个参数外，还有一些其他参数，如安全验证相关的参数，这里不做介绍。 实践建议 （1）哨兵节点的数量应不止一个，一方面增加哨兵节点的冗余，避免哨兵本身成为高可用的瓶颈；另一方面减少对下线的误判。此外，这些不同的哨兵节点应部署在不同的物理机上。 （2）哨兵节点的数量应该是奇数，便于哨兵通过投票做出“决策”：领导者选举的决策、客观下线的决策等。 （3）各个哨兵节点的配置应一致，包括硬件、参数等；此外，所有节点都应该使用ntp或类似服务，保证时间准确、一致。 （4）哨兵的配置提供者和通知客户端功能，需要客户端的支持才能实现，如前文所说的Jedis；如果开发者使用的库未提供相应支持，则可能需要开发者自己实现。 （5）当哨兵系统中的节点在docker（或其他可能进行端口映射的软件）中部署时，应特别注意端口映射可能会导致哨兵系统无法正常工作，因为哨兵的工作基于与其他节点的通信，而docker的端口映射可能导致哨兵无法连接到其他节点。例如，哨兵之间互相发现，依赖于它们对外宣称的IP和port，如果某个哨兵A部署在做了端口映射的docker中，那么其他哨兵使用A宣称的port无法连接到A。 六、总结本文首先介绍了哨兵的作用：监控、故障转移、配置提供者和通知；然后讲述了哨兵系统的部署方法，以及通过客户端访问哨兵系统的方法；再然后简要说明了哨兵实现的基本原理；最后给出了关于哨兵实践的一些建议。 在主从复制的基础上，哨兵引入了主节点的自动故障转移，进一步提高了Redis的高可用性；但是哨兵的缺陷同样很明显：哨兵无法对从节点进行自动故障转移，在读写分离场景下，从节点故障会导致读服务不可用，需要我们对从节点做额外的监控、切换操作。 此外，哨兵仍然没有解决写操作无法负载均衡、及存储能力受到单机限制的问题；这些问题的解决需要使用集群，我将在后面的文章中介绍，欢迎关注。 参考文献https://redis.io/topics/sentinel http://www.redis.cn/ 《Redis开发与运维》 《Redis设计与实现》]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>redis深入系统学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[主从复制]]></title>
    <url>%2F2019%2F06%2F14%2F%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%2F</url>
    <content type="text"><![CDATA[前言在前面的两篇文章中，分别介绍了Redis的内存模型和Redis的持久化。 在Redis的持久化中曾提到，Redis高可用的方案包括持久化、主从复制（及读写分离）、哨兵和集群。其中持久化侧重解决的是Redis数据的单机备份问题（从内存到硬盘的备份）；而主从复制则侧重解决数据的多机热备。此外，主从复制还可以实现负载均衡和故障恢复。 这篇文章中，将详细介绍Redis主从复制的方方面面，包括：如何使用主从复制、主从复制的原理（重点是全量复制和部分复制、以及心跳机制）、实际应用中需要注意的问题（如数据不一致问题、复制超时问题、复制缓冲区溢出问题）、主从复制相关的配置（重点是repl-timeout、client-output-buffer-limitslave）等。 一、主从复制概述主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(master)，后者称为从节点(slave)；数据的复制是单向的，只能由主节点到从节点。 默认情况下，每台Redis服务器都是主节点；且一个主节点可以有多个从节点(或没有从节点)，但一个从节点只能有一个主节点。 主从复制的作用 主从复制的作用主要包括： 数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。 故障恢复：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余。 负载均衡：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务（即写Redis数据时应用连接主节点，读Redis数据时应用连接从节点），分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。 高可用基石：除了上述作用以外，主从复制还是哨兵和集群能够实施的基础，因此说主从复制是Redis高可用的基础。 二、如何使用主从复制为了更直观的理解主从复制，在介绍其内部原理之前，先说明我们需要如何操作才能开启主从复制。 建立复制 需要注意，主从复制的开启，完全是在从节点发起的；不需要我们在主节点做任何事情。 从节点开启主从复制，有3种方式： （1）配置文件 在从服务器的配置文件中加入：slaveof \&lt;masterip> \&lt;masterport> （2）启动命令 redis-server启动命令后加入 –slaveof \&lt;masterip> \&lt;masterport> （3）客户端命令 Redis服务器启动后，直接通过客户端执行命令：slaveof \&lt;masterip>\&lt;masterport>，则该Redis实例成为从节点。 上述3种方式是等效的，下面以客户端命令的方式为例，看一下当执行了slaveof后，Redis主节点和从节点的变化。 实例 准备工作：启动两个节点方便起见，实验所使用的主从节点是在一台机器上的不同Redis实例，其中主节点监听6379端口，从节点监听6380端口；从节点监听的端口号可以在配置文件中修改： 启动后可以看到： 两个Redis节点启动后（分别称为6379节点和6380节点），默认都是主节点。 建立复制此时在6380节点执行slaveof命令，使之变为从节点： 观察效果下面验证一下，在主从复制建立后，主节点的数据会复制到从节点中。 （1）首先在从节点查询一个不存在的key： （2）然后在主节点中增加这个key： （3）此时在从节点中再次查询这个key，会发现主节点的操作已经同步至从节点： （4）然后在主节点删除这个key： （5）此时在从节点中再次查询这个key，会发现主节点的操作已经同步至从节点： 断开复制 通过slaveof \&lt;masterip> \&lt;masterport>命令建立主从复制关系以后，可以通过slaveofnoone断开。需要注意的是，从节点断开复制后，不会删除已有的数据，只是不再接受主节点新的数据变化。 从节点执行slaveof noone后，打印日志如下所示；可以看出断开复制后，从节点又变回为主节点。 主节点打印日志如下： 三、主从复制的实现原理上面一节中，介绍了如何操作可以建立主从关系；本小节将介绍主从复制的实现原理。 主从复制过程大体可以分为3个阶段：连接建立阶段（即准备阶段）、数据同步阶段、命令传播阶段；下面分别进行介绍。 连接建立阶段 该阶段的主要作用是在主从节点之间建立连接，为数据同步做好准备。 步骤1：保存主节点信息从节点服务器内部维护了两个字段，即masterhost和masterport字段，用于存储主节点的ip和port信息。 需要注意的是，slaveof是异步命令，从节点完成主节点ip和port的保存后，向发送slaveof命令的客户端直接返回OK，实际的复制操作在这之后才开始进行。 这个过程中，可以看到从节点打印日志如下： 步骤2：建立socket连接从节点每秒1次调用复制定时函数replicationCron()，如果发现了有主节点可以连接，便会根据主节点的ip和port，创建socket连接。如果连接成功，则： 从节点：为该socket建立一个专门处理复制工作的文件事件处理器，负责后续的复制工作，如接收RDB文件、接收命令传播等。 主节点：接收到从节点的socket连接后（即accept之后），为该socket创建相应的客户端状态，并将从节点看做是连接到主节点的一个客户端，后面的步骤会以从节点向主节点发送命令请求的形式来进行。 这个过程中，从节点打印日志如下： 步骤3：发送ping命令从节点成为主节点的客户端之后，发送ping命令进行首次请求，目的是：检查socket连接是否可用，以及主节点当前是否能够处理请求。 从节点发送ping命令后，可能出现3种情况： （1）返回pong：说明socket连接正常，且主节点当前可以处理请求，复制过程继续。 （2）超时：一定时间后从节点仍未收到主节点的回复，说明socket连接不可用，则从节点断开socket连接，并重连。 （3）返回pong以外的结果：如果主节点返回其他结果，如正在处理超时运行的脚本，说明主节点当前无法处理命令，则从节点断开socket连接，并重连。 在主节点返回pong情况下，从节点打印日志如下： 步骤4：身份验证如果从节点中设置了masterauth选项，则从节点需要向主节点进行身份验证；没有设置该选项，则不需要验证。从节点进行身份验证是通过向主节点发送auth命令进行的，auth命令的参数即为配置文件中的masterauth的值。 如果主节点设置密码的状态，与从节点masterauth的状态一致（一致是指都存在，且密码相同，或者都不存在），则身份验证通过，复制过程继续；如果不一致，则从节点断开socket连接，并重连。 步骤5：发送从节点端口信息身份验证之后，从节点会向主节点发送其监听的端口号（前述例子中为6380），主节点将该信息保存到该从节点对应的客户端的slave_listening_port字段中；该端口信息除了在主节点中执行infoReplication时显示以外，没有其他作用。 数据同步阶段 主从节点之间的连接建立以后，便可以开始进行数据同步，该阶段可以理解为从节点数据的初始化。具体执行的方式是：从节点向主节点发送psync命令（Redis2.8以前是sync命令），开始同步。 数据同步阶段是主从复制最核心的阶段，根据主从节点当前状态的不同，可以分为全量复制和部分复制，下面会有一章专门讲解这两种复制方式以及psync命令的执行过程，这里不再详述。 需要注意的是，在数据同步阶段之前，从节点是主节点的客户端，主节点不是从节点的客户端；而到了这一阶段及以后，主从节点互为客户端。原因在于：在此之前，主节点只需要响应从节点的请求即可，不需要主动发请求，而在数据同步阶段和后面的命令传播阶段，主节点需要主动向从节点发送请求（如推送缓冲区中的写命令），才能完成复制。 命令传播阶段 数据同步阶段完成后，主从节点进入命令传播阶段；在这个阶段主节点将自己执行的写命令发送给从节点，从节点接收命令并执行，从而保证主从节点数据的一致性。 在命令传播阶段，除了发送写命令，主从节点还维持着心跳机制：PING和REPLCONFACK。由于心跳机制的原理涉及部分复制，因此将在介绍了部分复制的相关内容后单独介绍该心跳机制。 延迟与不一致 需要注意的是，命令传播是异步的过程，即主节点发送写命令后并不会等待从节点的回复；因此实际上主从节点之间很难保持实时的一致性，延迟在所难免。数据不一致的程度，与主从节点之间的网络状况、主节点写命令的执行频率、以及主节点中的repl-disable-tcp-nodelay配置等有关。 repl-disable-tcp-nodelayno：该配置作用于命令传播阶段，控制主节点是否禁止与从节点的TCP_NODELAY；默认no，即不禁止TCP_NODELAY。当设置为yes时，TCP会对包进行合并从而减少带宽，但是发送的频率会降低，从节点数据延迟增加，一致性变差；具体发送频率与Linux内核的配置有关，默认配置为40ms。当设置为no时，TCP会立马将主节点的数据发送给从节点，带宽增加但延迟变小。 一般来说，只有当应用对Redis数据不一致的容忍度较高，且主从节点之间网络状况不好时，才会设置为yes；多数情况使用默认值no。 四、【数据同步阶段】全量复制和部分复制在Redis2.8以前，从节点向主节点发送sync命令请求同步数据，此时的同步方式是全量复制；在Redis2.8及以后，从节点可以发送psync命令请求同步数据，此时根据主从节点当前状态的不同，同步方式可能是全量复制或部分复制。后文介绍以Redis2.8及以后版本为例。 全量复制：用于初次复制或其他无法进行部分复制的情况，将主节点中的所有数据都发送给从节点，是一个非常重型的操作。 部分复制：用于网络中断等情况后的复制，只将中断期间主节点执行的写命令发送给从节点，与全量复制相比更加高效。需要注意的是，如果网络中断时间过长，导致主节点没有能够完整地保存中断期间执行的写命令，则无法进行部分复制，仍使用全量复制。 全量复制 Redis通过psync命令进行全量复制的过程如下： （1）从节点判断无法进行部分复制，向主节点发送全量复制的请求；或从节点发送部分复制的请求，但主节点判断无法进行全量复制；具体判断过程需要在讲述了部分复制原理后再介绍。 （2）主节点收到全量复制的命令后，执行bgsave，在后台生成RDB文件，并使用一个缓冲区（称为复制缓冲区）记录从现在开始执行的所有写命令 （3）主节点的bgsave执行完成后，将RDB文件发送给从节点；从节点首先清除自己的旧数据，然后载入接收的RDB文件，将数据库状态更新至主节点执行bgsave时的数据库状态 （4）主节点将前述复制缓冲区中的所有写命令发送给从节点，从节点执行这些写命令，将数据库状态更新至主节点的最新状态 （5）如果从节点开启了AOF，则会触发bgrewriteaof的执行，从而保证AOF文件更新至主节点的最新状态 下面是执行全量复制时，主从节点打印的日志；可以看出日志内容与上述步骤是完全对应的。 主节点的打印日志如下： 从节点打印日志如下图所示： 其中，有几点需要注意：从节点接收了来自主节点的89260个字节的数据；从节点在载入主节点的数据之前要先将老数据清除；从节点在同步完数据后，调用了bgrewriteaof。 通过全量复制的过程可以看出，全量复制是非常重型的操作： （1）主节点通过bgsave命令fork子进程进行RDB持久化，该过程是非常消耗CPU、内存(页表复制)、硬盘IO的；关于bgsave的性能问题，可以参考 深入学习Redis（2）：持久化 （2）主节点通过网络将RDB文件发送给从节点，对主从节点的带宽都会带来很大的消耗 （3）从节点清空老数据、载入新RDB文件的过程是阻塞的，无法响应客户端的命令；如果从节点执行bgrewriteaof，也会带来额外的消耗 部分复制 由于全量复制在主节点数据量较大时效率太低，因此Redis2.8开始提供部分复制，用于处理网络中断时的数据同步。 部分复制的实现，依赖于三个重要的概念： （1）复制偏移量主节点和从节点分别维护一个复制偏移量（offset），代表的是主节点向从节点传递的字节数；主节点每次向从节点传播N个字节数据时，主节点的offset增加N；从节点每次收到主节点传来的N个字节数据时，从节点的offset增加N。 offset用于判断主从节点的数据库状态是否一致：如果二者offset相同，则一致；如果offset不同，则不一致，此时可以根据两个offset找出从节点缺少的那部分数据。例如，如果主节点的offset是1000，而从节点的offset是500，那么部分复制就需要将offset为501-1000的数据传递给从节点。而offset为501-1000的数据存储的位置，就是下面要介绍的复制积压缓冲区。 （2）复制积压缓冲区复制积压缓冲区是由主节点维护的、固定长度的、先进先出(FIFO)队列，默认大小1MB；当主节点开始有从节点时创建，其作用是备份主节点最近发送给从节点的数据。注意，无论主节点有一个还是多个从节点，都只需要一个复制积压缓冲区。 在命令传播阶段，主节点除了将写命令发送给从节点，还会发送一份给复制积压缓冲区，作为写命令的备份；除了存储写命令，复制积压缓冲区中还存储了其中的每个字节对应的复制偏移量（offset）。由于复制积压缓冲区定长且是先进先出，所以它保存的是主节点最近执行的写命令；时间较早的写命令会被挤出缓冲区。 由于该缓冲区长度固定且有限，因此可以备份的写命令也有限，当主从节点offset的差距过大超过缓冲区长度时，将无法执行部分复制，只能执行全量复制。反过来说，为了提高网络中断时部分复制执行的概率，可以根据需要增大复制积压缓冲区的大小(通过配置repl-backlog-size)；例如如果网络中断的平均时间是60s，而主节点平均每秒产生的写命令(特定协议格式)所占的字节数为100KB，则复制积压缓冲区的平均需求为6MB，保险起见，可以设置为12MB，来保证绝大多数断线情况都可以使用部分复制。 从节点将offset发送给主节点后，主节点根据offset和缓冲区大小决定能否执行部分复制： 如果offset偏移量之后的数据，仍然都在复制积压缓冲区里，则执行部分复制； 如果offset偏移量之后的数据已不在复制积压缓冲区中（数据已被挤出），则执行全量复制。 （3）服务器运行ID(runid)每个Redis节点(无论主从)，在启动时都会自动生成一个随机ID(每次启动都不一样)，由40个随机的十六进制字符组成；runid用来唯一识别一个Redis节点。通过infoServer命令，可以查看节点的runid： 主从节点初次复制时，主节点将自己的runid发送给从节点，从节点将这个runid保存起来；当断线重连时，从节点会将这个runid发送给主节点；主节点根据runid判断能否进行部分复制： 如果从节点保存的runid与主节点现在的runid相同，说明主从节点之前同步过，主节点会继续尝试使用部分复制(到底能不能部分复制还要看offset和复制积压缓冲区的情况)； 如果从节点保存的runid与主节点现在的runid不同，说明从节点在断线前同步的Redis节点并不是当前的主节点，只能进行全量复制。 psync命令的执行 在了解了复制偏移量、复制积压缓冲区、节点运行id之后，本节将介绍psync命令的参数和返回值，从而说明psync命令执行过程中，主从节点是如何确定使用全量复制还是部分复制的。 psync命令的执行过程可以参见下图（图片来源：《Redis设计与实现》）： （1）首先，从节点根据当前状态，决定如何调用psync命令： 如果从节点之前未执行过slaveof或最近执行了slaveof noone，则从节点发送命令为psync ? -1，向主节点请求全量复制； 如果从节点之前执行了slaveof，则发送命令为psync \&lt;runid>\&lt;offset>，其中runid为上次复制的主节点的runid，offset为上次复制截止时从节点保存的复制偏移量。 （2）主节点根据收到的psync命令，及当前服务器状态，决定执行全量复制还是部分复制： 如果主节点版本低于Redis2.8，则返回-ERR回复，此时从节点重新发送sync命令执行全量复制； 如果主节点版本够新，且runid与从节点发送的runid相同，且从节点发送的offset之后的数据在复制积压缓冲区中都存在，则回复+CONTINUE，表示将进行部分复制，从节点等待主节点发送其缺少的数据即可； 如果主节点版本够新，但是runid与从节点发送的runid不同，或从节点发送的offset之后的数据已不在复制积压缓冲区中(在队列中被挤出了)，则回复+FULLRESYNC\&lt;runid>\&lt;offset>，表示要进行全量复制，其中runid表示主节点当前的runid，offset表示主节点当前的offset，从节点保存这两个值，以备使用。 部分复制演示 在下面的演示中，网络中断几分钟后恢复，断开连接的主从节点进行了部分复制；为了便于模拟网络中断，本例中的主从节点在局域网中的两台机器上。 网络中断 网络中断一段时间后，主节点和从节点都会发现失去了与对方的连接（关于主从节点对超时的判断机制，后面会有说明）；此后，从节点便开始执行对主节点的重连，由于此时网络还没有恢复，重连失败，从节点会一直尝试重连。 主节点日志如下： 从节点日志如下： 网络恢复 网络恢复后，从节点连接主节点成功，并请求进行部分复制，主节点接收请求后，二者进行部分复制以同步数据。 主节点日志如下： 从节点日志如下： 五、【命令传播阶段】心跳机制在命令传播阶段，除了发送写命令，主从节点还维持着心跳机制：PING和REPLCONFACK。心跳机制对于主从复制的超时判断、数据安全等有作用。 1.主->从：PING每隔指定的时间，主节点会向从节点发送PING命令，这个PING命令的作用，主要是为了让从节点进行超时判断。 PING发送的频率由repl-ping-slave-period参数控制，单位是秒，默认值是10s。 关于该PING命令究竟是由主节点发给从节点，还是相反，有一些争议；因为在Redis的官方文档中，对该参数的注释中说明是从节点向主节点发送PING命令，如下图所示： 但是根据该参数的名称(含有ping-slave)，以及代码实现，我认为该PING命令是主节点发给从节点的。相关代码如下： 从->主：REPLCONF ACK 在命令传播阶段，从节点会向主节点发送REPLCONFACK命令，频率是每秒1次；命令格式为：REPLCONF ACK{offset}，其中offset指从节点保存的复制偏移量。REPLCONF ACK命令的作用包括： （1）实时监测主从节点网络状态：该命令会被主节点用于复制超时的判断。此外，在主节点中使用infoReplication，可以看到其从节点的状态中的lag值，代表的是主节点上次收到该REPLCONFACK命令的时间间隔，在正常情况下，该值应该是0或1，如下图所示： （2）检测命令丢失：从节点发送了自身的offset，主节点会与自己的offset对比，如果从节点数据缺失（如网络丢包），主节点会推送缺失的数据（这里也会利用复制积压缓冲区）。注意，offset和复制积压缓冲区，不仅可以用于部分复制，也可以用于处理命令丢失等情形；区别在于前者是在断线重连后进行的，而后者是在主从节点没有断线的情况下进行的。 （3）辅助保证从节点的数量和延迟：Redis主节点中使用min-slaves-to-write和min-slaves-max-lag参数，来保证主节点在不安全的情况下不会执行写命令；所谓不安全，是指从节点数量太少，或延迟过高。例如min-slaves-to-write和min-slaves-max-lag分别是3和10，含义是如果从节点数量小于3个，或所有从节点的延迟值都大于10s，则主节点拒绝执行写命令。而这里从节点延迟值的获取，就是通过主节点接收到REPLCONFACK命令的时间来判断的，即前面所说的info Replication中的lag值。 六、应用中的问题 读写分离及其中的问题 在主从复制基础上实现的读写分离，可以实现Redis的读负载均衡：由主节点提供写服务，由一个或多个从节点提供读服务（多个从节点既可以提高数据冗余程度，也可以最大化读负载能力）；在读负载较大的应用场景下，可以大大提高Redis服务器的并发量。下面介绍在使用Redis读写分离时，需要注意的问题。 （1）延迟与不一致问题前面已经讲到，由于主从复制的命令传播是异步的，延迟与数据的不一致不可避免。如果应用对数据不一致的接受程度程度较低，可能的优化措施包括：优化主从节点之间的网络环境（如在同机房部署）；监控主从节点延迟（通过offset）判断，如果从节点延迟过大，通知应用不再通过该从节点读取数据；使用集群同时扩展写负载和读负载等。 在命令传播阶段以外的其他情况下，从节点的数据不一致可能更加严重，例如连接在数据同步阶段，或从节点失去与主节点的连接时等。从节点的slave-serve-stale-data参数便与此有关：它控制这种情况下从节点的表现；如果为yes（默认值），则从节点仍能够响应客户端的命令，如果为no，则从节点只能响应info、slaveof等少数命令。该参数的设置与应用对数据一致性的要求有关；如果对数据一致性要求很高，则应设置为no。 （2）数据过期问题在单机版Redis中，存在两种删除策略： 惰性删除：服务器不会主动删除数据，只有当客户端查询某个数据时，服务器判断该数据是否过期，如果过期则删除。 定期删除：服务器执行定时任务删除过期数据，但是考虑到内存和CPU的折中（删除会释放内存，但是频繁的删除操作对CPU不友好），该删除的频率和执行时间都受到了限制。 在主从复制场景下，为了主从节点的数据一致性，从节点不会主动删除数据，而是由主节点控制从节点中过期数据的删除。由于主节点的惰性删除和定期删除策略，都不能保证主节点及时对过期数据执行删除操作，因此，当客户端通过Redis从节点读取数据时，很容易读取到已经过期的数据。 Redis3.2中，从节点在读取数据时，增加了对数据是否过期的判断：如果该数据已过期，则不返回给客户端；将Redis升级到3.2可以解决数据过期问题。 （3）故障切换问题在没有使用哨兵的读写分离场景下，应用针对读和写分别连接不同的Redis节点；当主节点或从节点出现问题而发生更改时，需要及时修改应用程序读写Redis数据的连接；连接的切换可以手动进行，或者自己写监控程序进行切换，但前者响应慢、容易出错，后者实现复杂，成本都不算低。 （4）总结在使用读写分离之前，可以考虑其他方法增加Redis的读负载能力：如尽量优化主节点（减少慢查询、减少持久化等其他情况带来的阻塞等）提高负载能力；使用Redis集群同时提高读负载能力和写负载能力等。如果使用读写分离，可以使用哨兵，使主从节点的故障切换尽可能自动化，并减少对应用程序的侵入。 复制超时问题 主从节点复制超时是导致复制中断的最重要的原因之一，本小节单独说明超时问题，下一小节说明其他会导致复制中断的问题。 超时判断意义 在复制连接建立过程中及之后，主从节点都有机制判断连接是否超时，其意义在于： （1）如果主节点判断连接超时，其会释放相应从节点的连接，从而释放各种资源，否则无效的从节点仍会占用主节点的各种资源（输出缓冲区、带宽、连接等）；此外连接超时的判断可以让主节点更准确的知道当前有效从节点的个数，有助于保证数据安全（配合前面讲到的min-slaves-to-write等参数）。 （2）如果从节点判断连接超时，则可以及时重新建立连接，避免与主节点数据长期的不一致。 判断机制 主从复制超时判断的核心，在于repl-timeout参数，该参数规定了超时时间的阈值（默认60s），对于主节点和从节点同时有效；主从节点触发超时的条件分别如下： （1）主节点：每秒1次调用复制定时函数replicationCron()，在其中判断当前时间距离上次收到各个从节点REPLCONFACK的时间，是否超过了repl-timeout值，如果超过了则释放相应从节点的连接。 （2）从节点：从节点对超时的判断同样是在复制定时函数中判断，基本逻辑是： 如果当前处于连接建立阶段，且距离上次收到主节点的信息的时间已超过repl-timeout，则释放与主节点的连接； 如果当前处于数据同步阶段，且收到主节点的RDB文件的时间超时，则停止数据同步，释放连接； 如果当前处于命令传播阶段，且距离上次收到主节点的PING命令或数据的时间已超过repl-timeout值，则释放与主节点的连接。 主从节点判断连接超时的相关源代码如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/* Replication cron function, called 1 time per second. */void replicationCron(void) &#123; static long long replication_cron_loops = 0; /* Non blocking connection timeout? */ if (server.masterhost &amp;&amp; (server.repl_state == REDIS_REPL_CONNECTING || slaveIsInHandshakeState()) &amp;&amp; (time(NULL)-server.repl_transfer_lastio) &gt; server.repl_timeout) &#123; redisLog(REDIS_WARNING,&quot;Timeout connecting to the MASTER...&quot;); undoConnectWithMaster(); &#125; /* Bulk transfer I/O timeout? */ if (server.masterhost &amp;&amp; server.repl_state == REDIS_REPL_TRANSFER &amp;&amp; (time(NULL)-server.repl_transfer_lastio) &gt; server.repl_timeout) &#123; redisLog(REDIS_WARNING,&quot;Timeout receiving bulk data from MASTER... If the problem persists try to set the &apos;repl-timeout&apos; parameter in redis.conf to a larger value.&quot;); replicationAbortSyncTransfer(); &#125; /* Timed out master when we are an already connected slave? */ if (server.masterhost &amp;&amp; server.repl_state == REDIS_REPL_CONNECTED &amp;&amp; (time(NULL)-server.master-&gt;lastinteraction) &gt; server.repl_timeout) &#123; redisLog(REDIS_WARNING,&quot;MASTER timeout: no data nor PING received...&quot;); freeClient(server.master); &#125; //此处省略无关代码…… /* Disconnect timedout slaves. */ if (listLength(server.slaves)) &#123; listIter li; listNode *ln; listRewind(server.slaves,&amp;li); while((ln = listNext(&amp;li))) &#123; redisClient *slave = ln-&gt;value; if (slave-&gt;replstate != REDIS_REPL_ONLINE) continue; if (slave-&gt;flags &amp; REDIS_PRE_PSYNC) continue; if ((server.unixtime - slave-&gt;repl_ack_time) &gt; server.repl_timeout) &#123; redisLog(REDIS_WARNING, &quot;Disconnecting timedout slave: %s&quot;, replicationGetSlaveName(slave)); freeClient(slave); &#125; &#125; &#125; //此处省略无关代码…… &#125; 需要注意的坑 下面介绍与复制阶段连接超时有关的一些实际问题： （1）数据同步阶段：在主从节点进行全量复制bgsave时，主节点需要首先fork子进程将当前数据保存到RDB文件中，然后再将RDB文件通过网络传输到从节点。如果RDB文件过大，主节点在fork子进程+保存RDB文件时耗时过多，可能会导致从节点长时间收不到数据而触发超时；此时从节点会重连主节点，然后再次全量复制，再次超时，再次重连……这是个悲伤的循环。为了避免这种情况的发生，除了注意Redis单机数据量不要过大，另一方面就是适当增大repl-timeout值，具体的大小可以根据bgsave耗时来调整。 （2）命令传播阶段：如前所述，在该阶段主节点会向从节点发送PING命令，频率由repl-ping-slave-period控制；该参数应明显小于repl-timeout值(后者至少是前者的几倍)。否则，如果两个参数相等或接近，网络抖动导致个别PING命令丢失，此时恰巧主节点也没有向从节点发送数据，则从节点很容易判断超时。 （3）慢查询导致的阻塞：如果主节点或从节点执行了一些慢查询（如keys*或者对大数据的hgetall等），导致服务器阻塞；阻塞期间无法响应复制连接中对方节点的请求，可能导致复制超时。 复制中断问题 主从节点超时是复制中断的原因之一，除此之外，还有其他情况可能导致复制中断，其中最主要的是复制缓冲区溢出问题。 复制缓冲区溢出前面曾提到过，在全量复制阶段，主节点会将执行的写命令放到复制缓冲区中，该缓冲区存放的数据包括了以下几个时间段内主节点执行的写命令：bgsave生成RDB文件、RDB文件由主节点发往从节点、从节点清空老数据并载入RDB文件中的数据。当主节点数据量较大，或者主从节点之间网络延迟较大时，可能导致该缓冲区的大小超过了限制，此时主节点会断开与从节点之间的连接；这种情况可能引起全量复制->复制缓冲区溢出导致连接中断->重连->全量复制->复制缓冲区溢出导致连接中断……的循环。 复制缓冲区的大小由client-output-buffer-limit slave {hard limit} {soft limit}{soft seconds}配置，默认值为client-output-buffer-limit slave 256MB 64MB60，其含义是：如果buffer大于256MB，或者连续60s大于64MB，则主节点会断开与该从节点的连接。该参数是可以通过configset命令动态配置的（即不重启Redis也可以生效）。 当复制缓冲区溢出时，主节点打印日志如下所示： 需要注意的是，复制缓冲区是客户端输出缓冲区的一种，主节点会为每一个从节点分别分配复制缓冲区；而复制积压缓冲区则是一个主节点只有一个，无论它有多少个从节点。 各场景下复制的选择及优化技巧 在介绍了Redis复制的种种细节之后，现在我们可以来总结一下，在下面常见的场景中，何时使用部分复制，以及需要注意哪些问题。 （1）第一次建立复制此时全量复制不可避免，但仍有几点需要注意：如果主节点的数据量较大，应该尽量避开流量的高峰期，避免造成阻塞；如果有多个从节点需要建立对主节点的复制，可以考虑将几个从节点错开，避免主节点带宽占用过大。此外，如果从节点过多，也可以调整主从复制的拓扑结构，由一主多从结构变为树状结构（中间的节点既是其主节点的从节点，也是其从节点的主节点）；但使用树状结构应该谨慎：虽然主节点的直接从节点减少，降低了主节点的负担，但是多层从节点的延迟增大，数据一致性变差；且结构复杂，维护相当困难。 （2）主节点重启主节点重启可以分为两种情况来讨论，一种是故障导致宕机，另一种则是有计划的重启。 主节点宕机 主节点宕机重启后，runid会发生变化，因此不能进行部分复制，只能全量复制。 实际上在主节点宕机的情况下，应进行故障转移处理，将其中的一个从节点升级为主节点，其他从节点从新的主节点进行复制；且故障转移应尽量的自动化，后面文章将要介绍的哨兵便可以进行自动的故障转移。 安全重启：debug reload 在一些场景下，可能希望对主节点进行重启，例如主节点内存碎片率过高，或者希望调整一些只能在启动时调整的参数。如果使用普通的手段重启主节点，会使得runid发生变化，可能导致不必要的全量复制。 为了解决这个问题，Redis提供了debugreload的重启方式：重启后，主节点的runid和offset都不受影响，避免了全量复制。 如下图所示，debug reload重启后runid和offset都未受影响： 但debugreload是一柄双刃剑：它会清空当前内存中的数据，重新从RDB文件中加载，这个过程会导致主节点的阻塞，因此也需要谨慎。 （3）从节点重启从节点宕机重启后，其保存的主节点的runid会丢失，因此即使再次执行slaveof，也无法进行部分复制。 （4）网络中断如果主从节点之间出现网络问题，造成短时间内网络中断，可以分为多种情况讨论。 第一种情况：网络问题时间极为短暂，只造成了短暂的丢包，主从节点都没有判定超时（未触发repl-timeout）；此时只需要通过REPLCONFACK来补充丢失的数据即可。 第二种情况：网络问题时间很长，主从节点判断超时（触发了repl-timeout），且丢失的数据过多，超过了复制积压缓冲区所能存储的范围；此时主从节点无法进行部分复制，只能进行全量复制。为了尽可能避免这种情况的发生，应该根据实际情况适当调整复制积压缓冲区的大小；此外及时发现并修复网络中断，也可以减少全量复制。 第三种情况：介于前述两种情况之间，主从节点判断超时，且丢失的数据仍然都在复制积压缓冲区中；此时主从节点可以进行部分复制。 复制相关的配置 这一节总结一下与复制有关的配置，说明这些配置的作用、起作用的阶段，以及配置方法等；通过了解这些配置，一方面加深对Redis复制的了解，另一方面掌握这些配置的方法，可以优化Redis的使用，少走坑。 配置大致可以分为主节点相关配置、从节点相关配置以及与主从节点都有关的配置，下面分别说明。 （1）与主从节点都有关的配置首先介绍最特殊的配置，它决定了该节点是主节点还是从节点： 1) slaveof \&lt;masterip>\&lt;masterport>：Redis启动时起作用；作用是建立复制关系，开启了该配置的Redis服务器在启动后成为从节点。该注释默认注释掉，即Redis服务器默认都是主节点。 2) repl-timeout 60：与各个阶段主从节点连接超时判断有关，见前面的介绍。 （2）主节点相关配置1) repl-diskless-syncno：作用于全量复制阶段，控制主节点是否使用diskless复制（无盘复制）。所谓diskless复制，是指在全量复制时，主节点不再先把数据写入RDB文件，而是直接写入slave的socket中，整个过程中不涉及硬盘；diskless复制在磁盘IO很慢而网速很快时更有优势。需要注意的是，截至Redis3.0，diskless复制处于实验阶段，默认是关闭的。 2) repl-diskless-sync-delay5：该配置作用于全量复制阶段，当主节点使用diskless复制时，该配置决定主节点向从节点发送之前停顿的时间，单位是秒；只有当diskless复制打开时有效，默认5s。之所以设置停顿时间，是基于以下两个考虑：(1)向slave的socket的传输一旦开始，新连接的slave只能等待当前数据传输结束，才能开始新的数据传输(2)多个从节点有较大的概率在短时间内建立主从复制。 3) client-output-buffer-limit slave 256MB 64MB60：与全量复制阶段主节点的缓冲区大小有关，见前面的介绍。 4) repl-disable-tcp-nodelay no：与命令传播阶段的延迟有关，见前面的介绍。 5) masterauth\&lt;master-password>：与连接建立阶段的身份验证有关，见前面的介绍。 6) repl-ping-slave-period10：与命令传播阶段主从节点的超时判断有关，见前面的介绍。 7) repl-backlog-size 1mb：复制积压缓冲区的大小，见前面的介绍。 8) repl-backlog-ttl3600：当主节点没有从节点时，复制积压缓冲区保留的时间，这样当断开的从节点重新连进来时，可以进行全量复制；默认3600s。如果设置为0，则永远不会释放复制积压缓冲区。 9) min-slaves-to-write 3与min-slaves-max-lag10：规定了主节点的最小从节点数目，及对应的最大延迟，见前面的介绍。 （3）从节点相关配置1) slave-serve-stale-datayes：与从节点数据陈旧时是否响应客户端命令有关，见前面的介绍。 2) slave-read-onlyyes：从节点是否只读；默认是只读的。由于从节点开启写操作容易导致主从节点的数据不一致，因此该配置尽量不要修改。 单机内存大小限制 在 深入学习Redis（2）：持久化 一文中，讲到了fork操作对Redis单机内存大小的限制。实际上在Redis的使用中，限制单机内存大小的因素非常之多，下面总结一下在主从复制中，单机内存过大可能造成的影响： （1）切主：当主节点宕机时，一种常见的容灾策略是将其中一个从节点提升为主节点，并将其他从节点挂载到新的主节点上，此时这些从节点只能进行全量复制；如果Redis单机内存达到10GB，一个从节点的同步时间在几分钟的级别；如果从节点较多，恢复的速度会更慢。如果系统的读负载很高，而这段时间从节点无法提供服务，会对系统造成很大的压力。 （2）从库扩容：如果访问量突然增大，此时希望增加从节点分担读负载，如果数据量过大，从节点同步太慢，难以及时应对访问量的暴增。 （3）缓冲区溢出：（1）和（2）都是从节点可以正常同步的情形（虽然慢），但是如果数据量过大，导致全量复制阶段主节点的复制缓冲区溢出，从而导致复制中断，则主从节点的数据同步会全量复制->复制缓冲区溢出导致复制中断->重连->全量复制->复制缓冲区溢出导致复制中断……的循环。 （4）超时：如果数据量过大，全量复制阶段主节点fork+保存RDB文件耗时过大，从节点长时间接收不到数据触发超时，主从节点的数据同步同样可能陷入全量复制->超时导致复制中断->重连->全量复制->超时导致复制中断……的循环。 此外，主节点单机内存除了绝对量不能太大，其占用主机内存的比例也不应过大：最好只使用50%-65%的内存，留下30%-45%的内存用于执行bgsave命令和创建复制缓冲区等。 info Replication 在Redis客户端通过infoReplication可以查看与复制相关的状态，对于了解主从节点的当前状态，以及解决出现的问题都会有帮助。 主节点： 从节点： 对于从节点，上半部分展示的是其作为从节点的状态，从connectd_slaves开始，展示的是其作为潜在的主节点的状态。 info Replication中展示的大部分内容在文章中都已经讲述，这里不再详述。 七、总结下面回顾一下本文的主要内容： 1、主从复制的作用：宏观的了解主从复制是为了解决什么样的问题，即数据冗余、故障恢复、读负载均衡等。 2、主从复制的操作：即slaveof命令。 3、主从复制的原理：主从复制包括了连接建立阶段、数据同步阶段、命令传播阶段；其中数据同步阶段，有全量复制和部分复制两种数据同步方式；命令传播阶段，主从节点之间有PING和REPLCONFACK命令互相进行心跳检测。 4、应用中的问题：包括读写分离的问题（数据不一致问题、数据过期问题、故障切换问题等）、复制超时问题、复制中断问题等，然后总结了主从复制相关的配置，其中repl-timeout、client-output-buffer-limitslave等对解决Redis主从复制中出现的问题可能会有帮助。 主从复制虽然解决或缓解了数据冗余、故障恢复、读负载均衡等问题，但其缺陷仍很明显：故障恢复无法自动化；写操作无法负载均衡；存储能力受到单机的限制；这些问题的解决，需要哨兵和集群的帮助，我将在后面的文章中介绍，欢迎关注。 参考文献《Redis开发与运维》 《Redis设计与实现》 《Redis实战》 http://mdba.cn/2015/03/16/redis复制中断问题-慢查询/ https://redislabs.com/blog/top-redis-headaches-for-devops-replication-buffer/ http://mdba.cn/2015/03/17/redis主从复制（2）-replication-buffer与replication-backlog/ https://github.com/antirez/redis/issues/918 https://blog.csdn.net/qbw2010/article/details/50496982 https://mp.weixin.qq.com/s?__biz=MzIxMzEzMjM5NQ==&amp;mid=2651029484&amp;idx=1&amp;sn=5882f4c7c390a0a0e4f6dfd872e203b5&amp;chksm=8c4caae8bb3b23fe77909e307d45a071186f55069e5207602c61383eab573885615c1d835904&amp;mpshare=1&amp;scene=1&amp;srcid=0327SokqtxEY3WojWNDMHLYl\#rd]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>redis深入系统学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[持久化]]></title>
    <url>%2F2019%2F06%2F14%2F%E6%8C%81%E4%B9%85%E5%8C%96%2F</url>
    <content type="text"><![CDATA[前言 在上一篇文章中，介绍了Redis的内存模型，从这篇文章开始，将依次介绍Redis高可用相关的知识——持久化、复制(及读写分离)、哨兵、以及集群。 本文将先说明上述几种技术分别解决了Redis高可用的什么问题；然后详细介绍Redis的持久化技术，主要是RDB和AOF两种持久化方案；在介绍RDB和AOF方案时，不仅介绍其作用及操作方法，同时介绍持久化实现的一些原理细节及需要注意的问题。最后，介绍在实际使用中，持久化方案的选择，以及经常遇到的问题等。 目录 一、Redis高可用概述 二、Redis持久化概述 三、RDB持久化 [1. 触发条件]() [2. 执行流程]() [3. RDB文件]() [4. 启动时加载]() *5. RDB常用配置总结* 四、AOF持久化 [1. 开启AOF]() [2. 执行流程]() [3. 启动时加载]() [4. AOF常用配置总结]() 五、方案选择与常见问题 *1. RDB和AOF的优缺点* [2. 持久化策略选择]() 3. fork阻塞：CPU的阻塞 4.AOF追加阻塞：硬盘的阻塞 *5. info命令与持久化* 六、总结 一、Redis高可用概述 在介绍Redis高可用之前，先说明一下在Redis的语境中高可用的含义。 我们知道，在web服务器中，高可用是指服务器可以正常访问的时间，衡量的标准是在多长时间内可以提供正常服务（99.9%、99.99%、99.999%等等）。但是在Redis语境中，高可用的含义似乎要宽泛一些，除了保证提供正常服务(如主从分离、快速容灾技术)，还需要考虑数据容量的扩展、数据安全不会丢失等。 在Redis中，实现高可用的技术主要包括持久化、复制、哨兵和集群，下面分别说明它们的作用，以及解决了什么样的问题。 持久化：持久化是最简单的高可用方法(有时甚至不被归为高可用的手段)，主要作用是数据备份，即将数据存储在硬盘，保证数据不会因进程退出而丢失。 复制：复制是高可用Redis的基础，哨兵和集群都是在复制基础上实现高可用的。复制主要实现了数据的多机备份，以及对于读操作的负载均衡和简单的故障恢复。缺陷：故障恢复无法自动化；写操作无法负载均衡；存储能力受到单机的限制。 哨兵：在复制的基础上，哨兵实现了自动化的故障恢复。缺陷：写操作无法负载均衡；存储能力受到单机的限制。 集群：通过集群，Redis解决了写操作无法负载均衡，以及存储能力受到单机限制的问题，实现了较为完善的高可用方案。 二、Redis持久化概述 持久化的功能：Redis是内存数据库，数据都是存储在内存中，为了避免进程退出导致数据的永久丢失，需要定期将Redis中的数据以某种形式(数据或命令)从内存保存到硬盘；当下次Redis重启时，利用持久化文件实现数据恢复。除此之外，为了进行灾难备份，可以将持久化文件拷贝到一个远程位置。 Redis持久化分为RDB持久化和AOF持久化：前者将当前数据保存到硬盘，后者则是将每次执行的写命令保存到硬盘（类似于MySQL的binlog）；由于AOF持久化的实时性更好，即当进程意外退出时丢失的数据更少，因此AOF是目前主流的持久化方式，不过RDB持久化仍然有其用武之地。 下面依次介绍RDB持久化和AOF持久化；由于Redis各个版本之间存在差异，如无特殊说明，以Redis3.0为准。 三、RDB持久化 RDB持久化是将当前进程中的数据生成快照保存到硬盘(因此也称作快照持久化)，保存的文件后缀是rdb；当Redis重新启动时，可以读取快照文件恢复数据。 1. 触发条件 RDB持久化的触发分为手动触发和自动触发两种。 1) 手动触发 save命令和bgsave命令都可以生成RDB文件。 save命令会阻塞Redis服务器进程，直到RDB文件创建完毕为止，在Redis服务器阻塞期间，服务器不能处理任何命令请求。 而bgsave命令会创建一个子进程，由子进程来负责创建RDB文件，父进程(即Redis主进程)则继续处理请求。 此时服务器执行日志如下： bgsave命令执行过程中，只有fork子进程时会阻塞服务器，而对于save命令，整个过程都会阻塞服务器，因此save已基本被废弃，线上环境要杜绝save的使用；后文中也将只介绍bgsave命令。此外，在自动触发RDB持久化时，Redis也会选择bgsave而不是save来进行持久化；下面介绍自动触发RDB持久化的条件。 2) 自动触发 save m n 自动触发最常见的情况是在配置文件中通过save mn，指定当m秒内发生n次变化时，会触发bgsave。 例如，查看redis的默认配置文件(Linux下为redis根目录下的redis.conf)，可以看到如下配置信息： 其中save 9001的含义是：当时间到900秒时，如果redis数据发生了至少1次变化，则执行bgsave；save300 10和save 60 10000同理。当三个save条件满足任意一个时，都会引起bgsave的调用。 save m n的实现原理 Redis的save m n，是通过serverCron函数、dirty计数器、和lastsave时间戳来实现的。 serverCron是Redis服务器的周期性操作函数，默认每隔100ms执行一次；该函数对服务器的状态进行维护，其中一项工作就是检查save m n 配置的条件是否满足，如果满足就执行bgsave。 dirty计数器是Redis服务器维持的一个状态，记录了上一次执行bgsave/save命令后，服务器状态进行了多少次修改(包括增删改)；而当save/bgsave执行完成后，会将dirty重新置为0。 例如，如果Redis执行了set mykey helloworld，则dirty值会+1；如果执行了sadd mysetv1 v2v3，则dirty值会+3；注意dirty记录的是服务器进行了多少次修改，而不是客户端执行了多少修改数据的命令。 lastsave时间戳也是Redis服务器维持的一个状态，记录的是上一次成功执行save/bgsave的时间。 save m n的原理如下：每隔100ms，执行serverCron函数；在serverCron函数中，遍历savem n配置的保存条件，只要有一个条件满足，就进行bgsave。对于每一个save mn条件，只有下面两条同时满足时才算满足： （1）当前时间-lastsave > m （2）dirty >= n save m n 执行日志 下图是save m n触发bgsave执行时，服务器打印日志的情况： 其他自动触发机制 除了save m n 以外，还有一些其他情况会触发bgsave： 在主从复制场景下，如果从节点执行全量复制操作，则主节点会执行bgsave命令，并将rdb文件发送给从节点 执行shutdown命令时，自动执行rdb持久化，如下图所示： 2. 执行流程 前面介绍了触发bgsave的条件，下面将说明bgsave命令的执行流程，如下图所示(图片来源：https://blog.csdn.net/a1007720052/article/details/79126253)： 图片中的5个步骤所进行的操作如下： 1)Redis父进程首先判断：当前是否在执行save，或bgsave/bgrewriteaof（后面会详细介绍该命令）的子进程，如果在执行则bgsave命令直接返回。bgsave/bgrewriteaof的子进程不能同时执行，主要是基于性能方面的考虑：两个并发的子进程同时执行大量的磁盘写操作，可能引起严重的性能问题。 2)父进程执行fork操作创建子进程，这个过程中父进程是阻塞的，Redis不能执行来自客户端的任何命令 3) 父进程fork后，bgsave命令返回”Background savingstarted”信息并不再阻塞父进程，并可以响应其他命令 4)子进程创建RDB文件，根据父进程内存快照生成临时快照文件，完成后对原有文件进行原子替换 5) 子进程发送信号给父进程表示完成，父进程更新统计信息 3. RDB文件 RDB文件是经过压缩的二进制文件，下面介绍关于RDB文件的一些细节。 存储路径 RDB文件的存储路径既可以在启动前配置，也可以通过命令动态设定。 配置：dir配置指定目录，dbfilename指定文件名。默认是Redis根目录下的dump.rdb文件。 动态设定：Redis启动后也可以动态修改RDB存储路径，在磁盘损害或空间不足时非常有用；执行命令为configset dir {newdir}和config set dbfilename {newFileName}。如下所示(Windows环境)： RDB文件格式 RDB文件格式如下图所示（图片来源：《Redis设计与实现》）： 其中各个字段的含义说明如下： 1) REDIS：常量，保存着”REDIS”5个字符。 2) db_version：RDB文件的版本号，注意不是Redis的版本号。 3) SELECTDB 0 pairs：表示一个完整的数据库(0号数据库)，同理SELECTDB 3pairs表示完整的3号数据库；只有当数据库中有键值对时，RDB文件中才会有该数据库的信息(上图所示的Redis中只有0号和3号数据库有键值对)；如果Redis中所有的数据库都没有键值对，则这一部分直接省略。其中：SELECTDB是一个常量，代表后面跟着的是数据库号码；0和3是数据库号码；pairs则存储了具体的键值对信息，包括key、value值，及其数据类型、内部编码、过期时间、压缩信息等等。 4) EOF：常量，标志RDB文件正文内容结束。 5)check_sum：前面所有内容的校验和；Redis在载入RBD文件时，会计算前面的校验和并与check_sum值比较，判断文件是否损坏。 压缩 Redis默认采用LZF算法对RDB文件进行压缩。虽然压缩耗时，但是可以大大减小RDB文件的体积，因此压缩默认开启；可以通过命令关闭： 需要注意的是，RDB文件的压缩并不是针对整个文件进行的，而是对数据库中的字符串进行的，且只有在字符串达到一定长度(20字节)时才会进行。 4. 启动时加载 RDB文件的载入工作是在服务器启动时自动执行的，并没有专门的命令。但是由于AOF的优先级更高，因此当AOF开启时，Redis会优先载入AOF文件来恢复数据；只有当AOF关闭时，才会在Redis服务器启动时检测RDB文件，并自动载入。服务器载入RDB文件期间处于阻塞状态，直到载入完成为止。 Redis启动日志中可以看到自动载入的执行： Redis载入RDB文件时，会对RDB文件进行校验，如果文件损坏，则日志中会打印错误，Redis启动失败。 5. RDB常用配置总结 下面是RDB常用的配置项，以及默认值；前面介绍过的这里不再详细介绍。 save m n：bgsave自动触发的条件；如果没有save mn配置，相当于自动的RDB持久化关闭，不过此时仍可以通过其他方式触发 stop-writes-on-bgsave-erroryes：当bgsave出现错误时，Redis是否停止执行写命令；设置为yes，则当硬盘出现问题时，可以及时发现，避免数据的大量丢失；设置为no，则Redis无视bgsave的错误继续执行写命令，当对Redis服务器的系统(尤其是硬盘)使用了监控时，该选项考虑设置为no rdbcompression yes：是否开启RDB文件压缩 rdbchecksumyes：是否开启RDB文件的校验，在写入文件和读取文件时都起作用；关闭checksum在写入文件和启动文件时大约能带来10%的性能提升，但是数据损坏时无法发现 dbfilename dump.rdb：RDB文件名 dir ./：RDB文件和AOF文件所在目录 四、AOF持久化 RDB持久化是将进程数据写入文件，而AOF持久化(即Append OnlyFile持久化)，则是将Redis执行的每次写命令记录到单独的日志文件中（有点像MySQL的binlog）；当Redis重启时再次执行AOF文件中的命令来恢复数据。 与RDB相比，AOF的实时性更好，因此已成为主流的持久化方案。 1. 开启AOF Redis服务器默认开启RDB，关闭AOF；要开启AOF，需要在配置文件中配置： appendonly yes 2. 执行流程 由于需要记录Redis的每条写命令，因此AOF不需要触发，下面介绍AOF的执行流程。 AOF的执行流程包括： 命令追加(append)：将Redis的写命令追加到缓冲区aof_buf； 文件写入(write)和文件同步(sync)：根据不同的同步策略将aof_buf中的内容同步到硬盘； 文件重写(rewrite)：定期重写AOF文件，达到压缩的目的。 1) 命令追加(append) Redis先将写命令追加到缓冲区，而不是直接写入文件，主要是为了避免每次有写命令都直接写入硬盘，导致硬盘IO成为Redis负载的瓶颈。 命令追加的格式是Redis命令请求的协议格式，它是一种纯文本格式，具有兼容性好、可读性强、容易处理、操作简单避免二次开销等优点；具体格式略。在AOF文件中，除了用于指定数据库的select命令（如select0 为选中0号数据库）是由Redis添加的，其他都是客户端发送来的写命令。 2) 文件写入(write)和文件同步(sync) Redis提供了多种AOF缓存区的同步文件策略，策略涉及到操作系统的write函数和fsync函数，说明如下： 为了提高文件写入效率，在现代操作系统中，当用户调用write函数将数据写入文件时，操作系统通常会将数据暂存到一个内存缓冲区里，当缓冲区被填满或超过了指定时限后，才真正将缓冲区的数据写入到硬盘里。这样的操作虽然提高了效率，但也带来了安全问题：如果计算机停机，内存缓冲区中的数据会丢失；因此系统同时提供了fsync、fdatasync等同步函数，可以强制操作系统立刻将缓冲区中的数据写入到硬盘里，从而确保数据的安全性。 AOF缓存区的同步文件策略由参数appendfsync控制，各个值的含义如下： always：命令写入aof_buf后立即调用系统fsync操作同步到AOF文件，fsync完成后线程返回。这种情况下，每次有写命令都要同步到AOF文件，硬盘IO成为性能瓶颈，Redis只能支持大约几百TPS写入，严重降低了Redis的性能；即便是使用固态硬盘（SSD），每秒大约也只能处理几万个命令，而且会大大降低SSD的寿命。 no：命令写入aof_buf后调用系统write操作，不对AOF文件做fsync同步；同步由操作系统负责，通常同步周期为30秒。这种情况下，文件同步的时间不可控，且缓冲区中堆积的数据会很多，数据安全性无法保证。 everysec：命令写入aof_buf后调用系统write操作，write完成后线程返回；fsync同步文件操作由专门的线程每秒调用一次。everysec是前述两种策略的折中，是性能和数据安全性的平衡，因此是Redis的默认配置，也是我们推荐的配置。 3) 文件重写(rewrite) 随着时间流逝，Redis服务器执行的写命令越来越多，AOF文件也会越来越大；过大的AOF文件不仅会影响服务器的正常运行，也会导致数据恢复需要的时间过长。 文件重写是指定期重写AOF文件，减小AOF文件的体积。需要注意的是，AOF重写是把Redis进程内的数据转化为写命令，同步到新的AOF文件；不会对旧的AOF文件进行任何读取、写入操作! 关于文件重写需要注意的另一点是：对于AOF持久化来说，文件重写虽然是强烈推荐的，但并不是必须的；即使没有文件重写，数据也可以被持久化并在Redis启动的时候导入；因此在一些实现中，会关闭自动的文件重写，然后通过定时任务在每天的某一时刻定时执行。 文件重写之所以能够压缩AOF文件，原因在于： 过期的数据不再写入文件 无效的命令不再写入文件：如有些数据被重复设值(set mykey v1, set mykeyv2)、有些数据被删除了(sadd myset v1, del myset)等等 多条命令可以合并为一个：如sadd myset v1, sadd myset v2, sadd mysetv3可以合并为sadd myset v1 v2v3。不过为了防止单条命令过大造成客户端缓冲区溢出，对于list、set、hash、zset类型的key，并不一定只使用一条命令；而是以某个常量为界将命令拆分为多条。这个常量在redis.h/REDIS_AOF_REWRITE_ITEMS_PER_CMD中定义，不可更改，3.0版本中值是64。 通过上述内容可以看出，由于重写后AOF执行的命令减少了，文件重写既可以减少文件占用的空间，也可以加快恢复速度。 文件重写的触发 文件重写的触发，分为手动触发和自动触发： 手动触发：直接调用bgrewriteaof命令，该命令的执行与bgsave有些类似：都是fork子进程进行具体的工作，且都只有在fork时阻塞。 此时服务器执行日志如下： 自动触发：根据auto-aof-rewrite-min-size和auto-aof-rewrite-percentage参数，以及aof_current_size和aof_base_size状态确定触发时机。 auto-aof-rewrite-min-size：执行AOF重写时，文件的最小体积，默认值为64MB。 auto-aof-rewrite-percentage：执行AOF重写时，当前AOF大小(即aof_current_size)和上一次重写时AOF大小(aof_base_size)的比值。 其中，参数可以通过config get命令查看： 状态可以通过info persistence查看： 只有当auto-aof-rewrite-min-size和auto-aof-rewrite-percentage两个参数同时满足时，才会自动触发AOF重写，即bgrewriteaof操作。 自动触发bgrewriteaof时，可以看到服务器日志如下： 文件重写的流程 文件重写流程如下图所示(图片来源：http://www.cnblogs.com/yangmingxianshen/p/8373205.html)： 关于文件重写的流程，有两点需要特别注意：(1)重写由父进程fork子进程进行；(2)重写期间Redis执行的写命令，需要追加到新的AOF文件中，为此Redis引入了aof_rewrite_buf缓存。 对照上图，文件重写的流程如下： 1) Redis父进程首先判断当前是否存在正在执行bgsave/bgrewriteaof的子进程，如果存在则bgrewriteaof命令直接返回，如果存在bgsave命令则等bgsave执行完成后再执行。前面曾介绍过，这个主要是基于性能方面的考虑。 2) 父进程执行fork操作创建子进程，这个过程中父进程是阻塞的。 3.1) 父进程fork后，bgrewriteaof命令返回”Background append only file rewritestarted”信息并不再阻塞父进程，并可以响应其他命令。Redis的所有写命令依然写入AOF缓冲区，并根据appendfsync策略同步到硬盘，保证原有AOF机制的正确。 3.2)由于fork操作使用写时复制技术，子进程只能共享fork操作时的内存数据。由于父进程依然在响应命令，因此Redis使用AOF重写缓冲区(图中的aof_rewrite_buf)保存这部分数据，防止新AOF文件生成期间丢失这部分数据。也就是说，bgrewriteaof执行期间，Redis的写命令同时追加到aof_buf和aof_rewirte_buf两个缓冲区。 4) 子进程根据内存快照，按照命令合并规则写入到新的AOF文件。 5.1)子进程写完新的AOF文件后，向父进程发信号，父进程更新统计信息，具体可以通过infopersistence查看。 5.2)父进程把AOF重写缓冲区的数据写入到新的AOF文件，这样就保证了新AOF文件所保存的数据库状态和服务器当前状态一致。 5.3) 使用新的AOF文件替换老文件，完成AOF重写。 3. 启动时加载 前面提到过，当AOF开启时，Redis启动时会优先载入AOF文件来恢复数据；只有当AOF关闭时，才会载入RDB文件恢复数据。 当AOF开启，且AOF文件存在时，Redis启动日志： 当AOF开启，但AOF文件不存在时，即使RDB文件存在也不会加载(更早的一些版本可能会加载，但3.0不会)，Redis启动日志如下： 文件校验 与载入RDB文件类似，Redis载入AOF文件时，会对AOF文件进行校验，如果文件损坏，则日志中会打印错误，Redis启动失败。但如果是AOF文件结尾不完整(机器突然宕机等容易导致文件尾部不完整)，且aof-load-truncated参数开启，则日志中会输出警告，Redis忽略掉AOF文件的尾部，启动成功。aof-load-truncated参数默认是开启的： 伪客户端 因为Redis的命令只能在客户端上下文中执行，而载入AOF文件时命令是直接从文件中读取的，并不是由客户端发送；因此Redis服务器在载入AOF文件之前，会创建一个没有网络连接的客户端，之后用它来执行AOF文件中的命令，命令执行的效果与带网络连接的客户端完全一样。 4. AOF常用配置总结 下面是AOF常用的配置项，以及默认值；前面介绍过的这里不再详细介绍。 appendonly no：是否开启AOF appendfilename “appendonly.aof”：AOF文件名 dir ./：RDB文件和AOF文件所在目录 appendfsync everysec：fsync持久化策略 no-appendfsync-on-rewriteno：AOF重写期间是否禁止fsync；如果开启该选项，可以减轻文件重写时CPU和硬盘的负载（尤其是硬盘），但是可能会丢失AOF重写期间的数据；需要在负载和安全性之间进行平衡 auto-aof-rewrite-percentage 100：文件重写触发条件之一 auto-aof-rewrite-min-size 64mb：文件重写触发提交之一 aof-load-truncated yes：如果AOF文件结尾损坏，Redis启动时是否仍载入AOF文件 五、方案选择与常见问题 前面介绍了RDB和AOF两种持久化方案的细节，下面介绍RDB和AOF的特点、如何选择持久化方案，以及在持久化过程中常遇到的问题等。 1. RDB和AOF的优缺点 RDB和AOF各有优缺点： RDB持久化 优点：RDB文件紧凑，体积小，网络传输快，适合全量复制；恢复速度比AOF快很多。当然，与AOF相比，RDB最重要的优点之一是对性能的影响相对较小。 缺点：RDB文件的致命缺点在于其数据快照的持久化方式决定了必然做不到实时持久化，而在数据越来越重要的今天，数据的大量丢失很多时候是无法接受的，因此AOF持久化成为主流。此外，RDB文件需要满足特定格式，兼容性差（如老版本的Redis不兼容新版本的RDB文件）。 AOF持久化 与RDB持久化相对应，AOF的优点在于支持秒级持久化、兼容性好，缺点是文件大、恢复速度慢、对性能影响大。 2. 持久化策略选择 在介绍持久化策略之前，首先要明白无论是RDB还是AOF，持久化的开启都是要付出性能方面代价的：对于RDB持久化，一方面是bgsave在进行fork操作时Redis主进程会阻塞，另一方面，子进程向硬盘写数据也会带来IO压力；对于AOF持久化，向硬盘写数据的频率大大提高(everysec策略下为秒级)，IO压力更大，甚至可能造成AOF追加阻塞问题（后面会详细介绍这种阻塞），此外，AOF文件的重写与RDB的bgsave类似，会有fork时的阻塞和子进程的IO压力问题。相对来说，由于AOF向硬盘中写数据的频率更高，因此对Redis主进程性能的影响会更大。 在实际生产环境中，根据数据量、应用对数据的安全要求、预算限制等不同情况，会有各种各样的持久化策略；如完全不使用任何持久化、使用RDB或AOF的一种，或同时开启RDB和AOF持久化等。此外，持久化的选择必须与Redis的主从策略一起考虑，因为主从复制与持久化同样具有数据备份的功能，而且主机master和从机slave可以独立的选择持久化方案。 下面分场景来讨论持久化策略的选择，下面的讨论也只是作为参考，实际方案可能更复杂更具多样性。 （1）如果Redis中的数据完全丢弃也没有关系（如Redis完全用作DB层数据的cache），那么无论是单机，还是主从架构，都可以不进行任何持久化。 （2）在单机环境下（对于个人开发者，这种情况可能比较常见），如果可以接受十几分钟或更多的数据丢失，选择RDB对Redis的性能更加有利；如果只能接受秒级别的数据丢失，应该选择AOF。 （3）但在多数情况下，我们都会配置主从环境，slave的存在既可以实现数据的热备，也可以进行读写分离分担Redis读请求，以及在master宕掉后继续提供服务。 在这种情况下，一种可行的做法是： master：完全关闭持久化（包括RDB和AOF），这样可以让master的性能达到最好 slave：关闭RDB，开启AOF（如果对数据安全要求不高，开启RDB关闭AOF也可以），并定时对持久化文件进行备份（如备份到其他文件夹，并标记好备份的时间）；然后关闭AOF的自动重写，然后添加定时任务，在每天Redis闲时（如凌晨12点）调用bgrewriteaof。 这里需要解释一下，为什么开启了主从复制，可以实现数据的热备份，还需要设置持久化呢？因为在一些特殊情况下，主从复制仍然不足以保证数据的安全，例如： master和slave进程同时停止：考虑这样一种场景，如果master和slave在同一栋大楼或同一个机房，则一次停电事故就可能导致master和slave机器同时关机，Redis进程停止；如果没有持久化，则面临的是数据的完全丢失。 master误重启：考虑这样一种场景，master服务因为故障宕掉了，如果系统中有自动拉起机制（即检测到服务停止后重启该服务）将master自动重启，由于没有持久化文件，那么master重启后数据是空的，slave同步数据也变成了空的；如果master和slave都没有持久化，同样会面临数据的完全丢失。需要注意的是，即便是使用了哨兵(关于哨兵后面会有文章介绍)进行自动的主从切换，也有可能在哨兵轮询到master之前，便被自动拉起机制重启了。因此，应尽量避免“自动拉起机制”和“不做持久化”同时出现。 （4）异地灾备：上述讨论的几种持久化策略，针对的都是一般的系统故障，如进程异常退出、宕机、断电等，这些故障不会损坏硬盘。但是对于一些可能导致硬盘损坏的灾难情况，如火灾地震，就需要进行异地灾备。例如对于单机的情形，可以定时将RDB文件或重写后的AOF文件，通过scp拷贝到远程机器，如阿里云、AWS等；对于主从的情形，可以定时在master上执行bgsave，然后将RDB文件拷贝到远程机器，或者在slave上执行bgrewriteaof重写AOF文件后，将AOF文件拷贝到远程机器上。一般来说，由于RDB文件文件小、恢复快，因此灾难恢复常用RDB文件；异地备份的频率根据数据安全性的需要及其他条件来确定，但最好不要低于一天一次。 3. fork阻塞：CPU的阻塞 在Redis的实践中，众多因素限制了Redis单机的内存不能过大，例如： 当面对请求的暴增，需要从库扩容时，Redis内存过大会导致扩容时间太长； 当主机宕机时，切换主机后需要挂载从库，Redis内存过大导致挂载速度过慢； 以及持久化过程中的fork操作，下面详细说明。 首先说明一下fork操作： 父进程通过fork操作可以创建子进程；子进程创建后，父子进程共享代码段，不共享进程的数据空间，但是子进程会获得父进程的数据空间的副本。在操作系统fork的实际实现中，基本都采用了写时复制技术，即在父/子进程试图修改数据空间之前，父子进程实际上共享数据空间；但是当父/子进程的任何一个试图修改数据空间时，操作系统会为修改的那一部分(内存的一页)制作一个副本。 虽然fork时，子进程不会复制父进程的数据空间，但是会复制内存页表（页表相当于内存的索引、目录）；父进程的数据空间越大，内存页表越大，fork时复制耗时也会越多。 在Redis中，无论是RDB持久化的bgsave，还是AOF重写的bgrewriteaof，都需要fork出子进程来进行操作。如果Redis内存过大，会导致fork操作时复制内存页表耗时过多；而Redis主进程在进行fork时，是完全阻塞的，也就意味着无法响应客户端的请求，会造成请求延迟过大。 对于不同的硬件、不同的操作系统，fork操作的耗时会有所差别，一般来说，如果Redis单机内存达到了10GB，fork时耗时可能会达到百毫秒级别（如果使用Xen虚拟机，这个耗时可能达到秒级别）。因此，一般来说Redis单机内存一般要限制在10GB以内；不过这个数据并不是绝对的，可以通过观察线上环境fork的耗时来进行调整。观察的方法如下：执行命令infostats，查看latest_fork_usec的值，单位为微秒。 为了减轻fork操作带来的阻塞问题，除了控制Redis单机内存的大小以外，还可以适度放宽AOF重写的触发条件、选用物理机或高效支持fork操作的虚拟化技术等，例如使用Vmware或KVM虚拟机，不要使用Xen虚拟机。 4. AOF追加阻塞：硬盘的阻塞 前面提到过，在AOF中，如果AOF缓冲区的文件同步策略为everysec，则：在主线程中，命令写入aof_buf后调用系统write操作，write完成后主线程返回；fsync同步文件操作由专门的文件同步线程每秒调用一次。 这种做法的问题在于，如果硬盘负载过高，那么fsync操作可能会超过1s；如果Redis主线程持续高速向aof_buf写入命令，硬盘的负载可能会越来越大，IO资源消耗更快；如果此时Redis进程异常退出，丢失的数据也会越来越多，可能远超过1s。 为此，Redis的处理策略是这样的：主线程每次进行AOF会对比上次fsync成功的时间；如果距上次不到2s，主线程直接返回；如果超过2s，则主线程阻塞直到fsync同步完成。因此，如果系统硬盘负载过大导致fsync速度太慢，会导致Redis主线程的阻塞；此外，使用everysec配置，AOF最多可能丢失2s的数据，而不是1s。 AOF追加阻塞问题定位的方法： （1）监控infoPersistence中的aof_delayed_fsync：当AOF追加阻塞发生时（即主线程等待fsync而阻塞），该指标累加。 （2）AOF阻塞时的Redis日志： Asynchronous AOF fsync is taking too long (disk is busy?). Writing the AOF buffer without waiting for fsync to complete, this may slow down Redis. （3）如果AOF追加阻塞频繁发生，说明系统的硬盘负载太大；可以考虑更换IO速度更快的硬盘，或者通过IO监控分析工具对系统的IO负载进行分析，如iostat（系统级io）、iotop（io版的top）、pidstat等。 5. info命令与持久化 前面提到了一些通过info命令查看持久化相关状态的方法，下面来总结一下。 （1）info Persistence 执行结果如下： 其中比较重要的包括： rdb_last_bgsave_status:上次bgsave 执行结果，可以用于发现bgsave错误 rdb_last_bgsave_time_sec:上次bgsave执行时间（单位是s），可以用于发现bgsave是否耗时过长 aof_enabled:AOF是否开启 aof_last_rewrite_time_sec:上次文件重写执行时间（单位是s），可以用于发现文件重写是否耗时过长 aof_last_bgrewrite_status: 上次bgrewrite执行结果，可以用于发现bgrewrite错误 aof_buffer_length和aof_rewrite_buffer_length:aof缓存区大小和aof重写缓冲区大小 aof_delayed_fsync:AOF追加阻塞情况的统计 （2）info stats 其中与持久化关系较大的是：latest_fork_usec，代表上次fork耗时，可以参见前面的讨论。 六、总结 本文主要内容可以总结如下： 1、持久化在Redis高可用中的作用：数据备份，与主从复制相比强调的是由内存到硬盘的备份。 2、RDB持久化：将数据快照备份到硬盘；介绍了其触发条件（包括手动出发和自动触发）、执行流程、RDB文件等，特别需要注意的是文件保存操作由fork出的子进程来进行。 3、AOF持久化：将执行的写命令备份到硬盘（类似于MySQL的binlog），介绍了其开启方法、执行流程等，特别需要注意的是文件同步策略的选择（everysec）、文件重写的流程。 4、一些现实的问题：包括如何选择持久化策略，以及需要注意的fork阻塞、AOF追加阻塞等。 参考文献 《Redis开发与运维》 《Redis设计与实现》 《Redis实战》 http://www.redis.cn/topics/persistence.html https://mp.weixin.qq.com/s/fpupqLp-wjR8fQvYSQhVLg https://mp.weixin.qq.com/s?__biz=MzI4NTA1MDEwNg==&amp;mid=2650764050&amp;idx=1&amp;sn=891287b9f99a8c1dd4ce9e1805646741&amp;chksm=f3f9c687c48e4f91c6631e7f5e36a9169c10549386bec541dbeef92ed0023a373f6ec25c2ef1&amp;mpshare=1&amp;scene=1&amp;srcid=0525xnHQxiFwpzFWSME2LQrb#rd https://mp.weixin.qq.com/s?__biz=MzI4NTA1MDEwNg==&amp;mid=2650763383&amp;idx=1&amp;sn=348a84605a7cdefe4e075c9f0310f257&amp;chksm=f3f9c5e2c48e4cf41bd3f708bce3f9a1302a699cf7defe611e9aea120fcb424944119e079362&amp;mpshare=1&amp;scene=1&amp;srcid=0525XIl8KXvHYvX42oaUcop0#rd https://blog.csdn.net/tonyxf121/article/details/8475603 http://heylinux.com/archives/1932.html https://www.m690.com/archives/380/]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>redis深入系统学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis内存模型]]></title>
    <url>%2F2019%2F06%2F14%2Fredis%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[前言 Redis是目前最火爆的内存数据库之一，通过在内存中读写数据，大大提高了读写速度，可以说Redis是实现网站高并发不可或缺的一部分。 我们使用Redis时，会接触Redis的5种对象类型（字符串、哈希、列表、集合、有序集合），丰富的类型是Redis相对于Memcached等的一大优势。在了解Redis的5种对象类型的用法和特点的基础上，进一步了解Redis的内存模型，对Redis的使用有很大帮助，例如： 1、估算Redis内存使用量。目前为止，内存的使用成本仍然相对较高，使用内存不能无所顾忌；根据需求合理的评估Redis的内存使用量，选择合适的机器配置，可以在满足需求的情况下节约成本。 2、优化内存占用。了解Redis内存模型可以选择更合适的数据类型和编码，更好的利用Redis内存。 3、分析解决问题。当Redis出现阻塞、内存占用等问题时，尽快发现导致问题的原因，便于分析解决问题。 这篇文章主要介绍Redis的内存模型（以3.0为例），包括Redis占用内存的情况及如何查询、不同的对象类型在内存中的编码方式、内存分配器(jemalloc)、简单动态字符串(SDS)、RedisObject等；然后在此基础上介绍几个Redis内存模型的应用。 在后面的文章中，会陆续介绍关于Redis高可用的内容，包括主从复制、哨兵、集群等等，欢迎关注。 目录 一、Redis内存统计 二、Redis内存划分 1、数据（或者称为对象） 2、进程本身运行需要的内存 3、缓冲内存 4、内存碎片 三、Redis数据存储的细节 1、概述 2、jemalloc 3、redisObject 4、SDS 四、Redis的对象类型与内部编码 1、字符串 2、列表 3、哈希 4、集合 5、有序集合 五、应用举例 1、估算Redis内存使用量 2、优化内存占用 3、关注内存碎片率 六、参考文献 一、Redis内存统计 工欲善其事必先利其器，在说明Redis内存之前首先说明如何统计Redis使用内存的情况。 在客户端通过redis-cli连接服务器后（后面如无特殊说明，客户端一律使用redis-cli），通过info命令可以查看内存使用情况： 其中，info命令可以显示redis服务器的许多信息，包括服务器基本信息、CPU、内存、持久化、客户端连接信息等等；memory是参数，表示只显示内存相关的信息。 返回结果中比较重要的几个说明如下： （1）used_memory：Redis分配器分配的内存总量（单位是字节），包括使用的虚拟内存（即swap）；Redis分配器后面会介绍。used_memory_human只是显示更友好。 （2）used_memory_rss：Redis进程占据操作系统的内存（单位是字节），与top及ps命令看到的值是一致的；除了分配器分配的内存之外，used_memory_rss还包括进程运行本身需要的内存、内存碎片等，但是不包括虚拟内存。 因此，used_memory和used_memory_rss，前者是从Redis角度得到的量，后者是从操作系统角度得到的量。二者之所以有所不同，一方面是因为内存碎片和Redis进程运行需要占用内存，使得前者可能比后者小，另一方面虚拟内存的存在，使得前者可能比后者大。 由于在实际应用中，Redis的数据量会比较大，此时进程运行占用的内存与Redis数据量和内存碎片相比，都会小得多；因此used_memory_rss和used_memory的比例，便成了衡量Redis内存碎片率的参数；这个参数就是mem_fragmentation_ratio。 （3）mem_fragmentation_ratio：内存碎片比率，该值是used_memory_rss /used_memory的比值。 mem_fragmentation_ratio一般大于1，且该值越大，内存碎片比例越大。mem_fragmentation_ratio\&lt;1，说明Redis使用了虚拟内存，由于虚拟内存的媒介是磁盘，比内存速度要慢很多，当这种情况出现时，应该及时排查，如果内存不足应该及时处理，如增加Redis节点、增加Redis服务器的内存、优化应用等。 一般来说，mem_fragmentation_ratio在1.03左右是比较健康的状态（对于jemalloc来说）；上面截图中的mem_fragmentation_ratio值很大，是因为还没有向Redis中存入数据，Redis进程本身运行的内存使得used_memory_rss比used_memory大得多。 （4）mem_allocator：Redis使用的内存分配器，在编译时指定；可以是 libc、jemalloc或者tcmalloc，默认是jemalloc；截图中使用的便是默认的jemalloc。 二、Redis内存划分 Redis作为内存数据库，在内存中存储的内容主要是数据（键值对）；通过前面的叙述可以知道，除了数据以外，Redis的其他部分也会占用内存。 Redis的内存占用主要可以划分为以下几个部分： 1、数据 作为数据库，数据是最主要的部分；这部分占用的内存会统计在used_memory中。 Redis使用键值对存储数据，其中的值（对象）包括5种类型，即字符串、哈希、列表、集合、有序集合。这5种类型是Redis对外提供的，实际上，在Redis内部，每种类型可能有2种或更多的内部编码实现；此外，Redis在存储对象时，并不是直接将数据扔进内存，而是会对对象进行各种包装：如redisObject、SDS等；这篇文章后面将重点介绍Redis中数据存储的细节。 2、进程本身运行需要的内存 Redis主进程本身运行肯定需要占用内存，如代码、常量池等等；这部分内存大约几兆，在大多数生产环境中与Redis数据占用的内存相比可以忽略。这部分内存不是由jemalloc分配，因此不会统计在used_memory中。 补充说明：除了主进程外，Redis创建的子进程运行也会占用内存，如Redis执行AOF、RDB重写时创建的子进程。当然，这部分内存不属于Redis进程，也不会统计在used_memory和used_memory_rss中。 3、缓冲内存 缓冲内存包括客户端缓冲区、复制积压缓冲区、AOF缓冲区等；其中，客户端缓冲存储客户端连接的输入输出缓冲；复制积压缓冲用于部分复制功能；AOF缓冲区用于在进行AOF重写时，保存最近的写入命令。在了解相应功能之前，不需要知道这些缓冲的细节；这部分内存由jemalloc分配，因此会统计在used_memory中。 4、内存碎片 内存碎片是Redis在分配、回收物理内存过程中产生的。例如，如果对数据的更改频繁，而且数据之间的大小相差很大，可能导致redis释放的空间在物理内存中并没有释放，但redis又无法有效利用，这就形成了内存碎片。内存碎片不会统计在used_memory中。 内存碎片的产生与对数据进行的操作、数据的特点等都有关；此外，与使用的内存分配器也有关系：如果内存分配器设计合理，可以尽可能的减少内存碎片的产生。后面将要说到的jemalloc便在控制内存碎片方面做的很好。 如果Redis服务器中的内存碎片已经很大，可以通过安全重启的方式减小内存碎片：因为重启之后，Redis重新从备份文件中读取数据，在内存中进行重排，为每个数据重新选择合适的内存单元，减小内存碎片。 三、Redis数据存储的细节 1、概述 关于Redis数据存储的细节，涉及到内存分配器（如jemalloc）、简单动态字符串（SDS）、5种对象类型及内部编码、redisObject。在讲述具体内容之前，先说明一下这几个概念之间的关系。 下图是执行set hello world时，所涉及到的数据模型。 图片来源：https://searchdatabase.techtarget.com.cn/7-20218/ （1）dictEntry：Redis是Key-Value数据库，因此对每个键值对都会有一个dictEntry，里面存储了指向Key和Value的指针；next指向下一个dictEntry，与本Key-Value无关。 （2）Key：图中右上角可见，Key（”hello”）并不是直接以字符串存储，而是存储在SDS结构中。 （3）redisObject：Value(“world”)既不是直接以字符串存储，也不是像Key一样直接存储在SDS中，而是存储在redisObject中。实际上，不论Value是5种类型的哪一种，都是通过redisObject来存储的；而redisObject中的type字段指明了Value对象的类型，ptr字段则指向对象所在的地址。不过可以看出，字符串对象虽然经过了redisObject的包装，但仍然需要通过SDS存储。 实际上，redisObject除了type和ptr字段以外，还有其他字段图中没有给出，如用于指定对象内部编码的字段；后面会详细介绍。 （4）jemalloc：无论是DictEntry对象，还是redisObject、SDS对象，都需要内存分配器（如jemalloc）分配内存进行存储。以DictEntry对象为例，有3个指针组成，在64位机器下占24个字节，jemalloc会为它分配32字节大小的内存单元。 下面来分别介绍jemalloc、redisObject、SDS、对象类型及内部编码。 2、jemalloc Redis在编译时便会指定内存分配器；内存分配器可以是 libc、jemalloc或者tcmalloc，默认是jemalloc。 jemalloc作为Redis的默认内存分配器，在减小内存碎片方面做的相对比较好。jemalloc在64位系统中，将内存空间划分为小、大、巨大三个范围；每个范围内又划分了许多小的内存块单位；当Redis存储数据时，会选择大小最合适的内存块进行存储。 jemalloc划分的内存单元如下图所示： 图片来源：http://blog.csdn.net/zhengpeitao/article/details/76573053 例如，如果需要存储大小为130字节的对象，jemalloc会将其放入160字节的内存单元中。 3、redisObject 前面说到，Redis对象有5种类型；无论是哪种类型，Redis都不会直接存储，而是通过redisObject对象进行存储。 redisObject对象非常重要，Redis对象的类型、内部编码、内存回收、共享对象等功能，都需要redisObject支持，下面将通过redisObject的结构来说明它是如何起作用的。 redisObject的定义如下（不同版本的Redis可能稍稍有所不同）： 1234567typedef struct redisObject &#123; unsigned type:4; unsigned encoding:4; unsigned lru:REDIS_LRU_BITS; /* lru time (relative to server.lruclock) */ int refcount; void *ptr;&#125; robj; redisObject的每个字段的含义和作用如下： （1）type type字段表示对象的类型，占4个比特；目前包括REDIS_STRING(字符串)、REDIS_LIST(列表)、REDIS_HASH(哈希)、REDIS_SET(集合)、REDIS_ZSET(有序集合)。 当我们执行type命令时，便是通过读取RedisObject的type字段获得对象的类型；如下图所示： （2）encoding encoding表示对象的内部编码，占4个比特。 对于Redis支持的每种类型，都有至少两种内部编码，例如对于字符串，有int、embstr、raw三种编码。通过encoding属性，Redis可以根据不同的使用场景来为对象设置不同的编码，大大提高了Redis的灵活性和效率。以列表对象为例，有压缩列表和双端链表两种编码方式；如果列表中的元素较少，Redis倾向于使用压缩列表进行存储，因为压缩列表占用内存更少，而且比双端链表可以更快载入；当列表对象元素较多时，压缩列表就会转化为更适合存储大量元素的双端链表。 通过object encoding命令，可以查看对象采用的编码方式，如下图所示： 5种对象类型对应的编码方式以及使用条件，将在后面介绍。 （3）lru lru记录的是对象最后一次被命令程序访问的时间，占据的比特数不同的版本有所不同（如4.0版本占24比特，2.6版本占22比特）。 通过对比lru时间与当前时间，可以计算某个对象的空转时间；objectidletime命令可以显示该空转时间（单位是秒）。objectidletime命令的一个特殊之处在于它不改变对象的lru值。 lru值除了通过objectidletime命令打印之外，还与Redis的内存回收有关系：如果Redis打开了maxmemory选项，且内存回收算法选择的是volatile-lru或allkeys—lru，那么当Redis内存占用超过maxmemory指定的值时，Redis会优先选择空转时间最长的对象进行释放。 （4）refcount refcount与共享对象 refcount记录的是该对象被引用的次数，类型为整型。refcount的作用，主要在于对象的引用计数和内存回收。当创建新对象时，refcount初始化为1；当有新程序使用该对象时，refcount加1；当对象不再被一个新程序使用时，refcount减1；当refcount变为0时，对象占用的内存会被释放。 Redis中被多次使用的对象(refcount>1)，称为共享对象。Redis为了节省内存，当有一些对象重复出现时，新的程序不会创建新的对象，而是仍然使用原来的对象。这个被重复使用的对象，就是共享对象。目前共享对象仅支持整数值的字符串对象。 共享对象的具体实现 Redis的共享对象目前只支持整数值的字符串对象。之所以如此，实际上是对内存和CPU（时间）的平衡：共享对象虽然会降低内存消耗，但是判断两个对象是否相等却需要消耗额外的时间。对于整数值，判断操作复杂度为O(1)；对于普通字符串，判断复杂度为O(n)；而对于哈希、列表、集合和有序集合，判断的复杂度为O(n\^2)。 虽然共享对象只能是整数值的字符串对象，但是5种类型都可能使用共享对象（如哈希、列表等的元素可以使用）。 就目前的实现来说，Redis服务器在初始化时，会创建10000个字符串对象，值分别是0~9999的整数值；当Redis需要使用值为0~9999的字符串对象时，可以直接使用这些共享对象。10000这个数字可以通过调整参数REDIS_SHARED_INTEGERS（4.0中是OBJ_SHARED_INTEGERS）的值进行改变。 共享对象的引用次数可以通过objectrefcount命令查看，如下图所示。命令执行的结果页佐证了只有0~9999之间的整数会作为共享对象。 （5）ptr ptr指针指向具体的数据，如前面的例子中，set helloworld，ptr指向包含字符串world的SDS。 （6）总结 综上所述，redisObject的结构与对象类型、编码、内存回收、共享对象都有关系；一个redisObject对象的大小为16字节： 4bit+4bit+24bit+4Byte+8Byte=16Byte。 4、SDS Redis没有直接使用C字符串(即以空字符’\0’结尾的字符数组)作为默认的字符串表示，而是使用了SDS。SDS是简单动态字符串(SimpleDynamic String)的缩写。 （1）SDS结构 sds的结构如下：12345struct sdshdr &#123; int len; int free; char buf[];&#125;; 其中，buf表示字节数组，用来存储字符串；len表示buf已使用的长度，free表示buf未使用的长度。下面是两个例子。 图片来源：《Redis设计与实现》 通过SDS的结构可以看出，buf数组的长度=free+len+1（其中1表示字符串结尾的空字符）；所以，一个SDS结构占据的空间为：free所占长度+len所占长度+buf数组的长度=4+4+free+len+1=free+len+9。 （2）SDS与C字符串的比较 SDS在C字符串的基础上加入了free和len字段，带来了很多好处： 获取字符串长度：SDS是O(1)，C字符串是O(n) 缓冲区溢出：使用C字符串的API时，如果字符串长度增加（如strcat操作）而忘记重新分配内存，很容易造成缓冲区的溢出；而SDS由于记录了长度，相应的API在可能造成缓冲区溢出时会自动重新分配内存，杜绝了缓冲区溢出。 修改字符串时内存的重分配：对于C字符串，如果要修改字符串，必须要重新分配内存（先释放再申请），因为如果没有重新分配，字符串长度增大时会造成内存缓冲区溢出，字符串长度减小时会造成内存泄露。而对于SDS，由于可以记录len和free，因此解除了字符串长度和空间数组长度之间的关联，可以在此基础上进行优化：空间预分配策略（即分配内存时比实际需要的多）使得字符串长度增大时重新分配内存的概率大大减小；惰性空间释放策略使得字符串长度减小时重新分配内存的概率大大减小。 存取二进制数据：SDS可以，C字符串不可以。因为C字符串以空字符作为字符串结束的标识，而对于一些二进制文件（如图片等），内容可能包括空字符串，因此C字符串无法正确存取；而SDS以字符串长度len来作为字符串结束标识，因此没有这个问题。 此外，由于SDS中的buf仍然使用了C字符串（即以’\0’结尾），因此SDS可以使用C字符串库中的部分函数；但是需要注意的是，只有当SDS用来存储文本数据时才可以这样使用，在存储二进制数据时则不行（’\0’不一定是结尾）。 （3）SDS与C字符串的应用 Redis在存储对象时，一律使用SDS代替C字符串。例如set helloworld命令，hello和world都是以SDS的形式存储的。而sadd myset member1 member2member3命令，不论是键（”myset”），还是集合中的元素（”member1”、”member2”和”member3”），都是以SDS的形式存储。除了存储对象，SDS还用于存储各种缓冲区。 只有在字符串不会改变的情况下，如打印日志时，才会使用C字符串。 四、Redis的对象类型与内部编码 前面已经说过，Redis支持5种对象类型，而每种结构都有至少两种编码；这样做的好处在于：一方面接口与实现分离，当需要增加或改变内部编码时，用户使用不受影响，另一方面可以根据不同的应用场景切换内部编码，提高效率。 Redis各种对象类型支持的内部编码如下图所示(图中版本是Redis3.0，Redis后面版本中又增加了内部编码，略过不提；本章所介绍的内部编码都是基于3.0的)： 图片来源：《Redis设计与实现》 关于Redis内部编码的转换，都符合以下规律：编码转换在Redis写入数据时完成，且转换过程不可逆，只能从小内存编码向大内存编码转换。 1、字符串 （1）概况 字符串是最基础的类型，因为所有的键都是字符串类型，且字符串之外的其他几种复杂类型的元素也是字符串。 字符串长度不能超过512MB。 （2）内部编码 字符串类型的内部编码有3种，它们的应用场景如下： int：8个字节的长整型。字符串值是整型时，这个值使用long整型表示。 embstr：\&lt;=39字节的字符串。embstr与raw都使用redisObject和sds保存数据，区别在于，embstr的使用只分配一次内存空间（因此redisObject和sds是连续的），而raw需要分配两次内存空间（分别为redisObject和sds分配空间）。因此与raw相比，embstr的好处在于创建时少分配一次空间，删除时少释放一次空间，以及对象的所有数据连在一起，寻找方便。而embstr的坏处也很明显，如果字符串的长度增加需要重新分配内存时，整个redisObject和sds都需要重新分配空间，因此redis中的embstr实现为只读。 raw：大于39个字节的字符串 示例如下图所示： embstr和raw进行区分的长度，是39；是因为redisObject的长度是16字节，sds的长度是9+字符串长度；因此当字符串长度是39时，embstr的长度正好是16+9+39=64，jemalloc正好可以分配64字节的内存单元。 （3）编码转换 当int数据不再是整数，或大小超过了long的范围时，自动转化为raw。 而对于embstr，由于其实现是只读的，因此在对embstr对象进行修改时，都会先转化为raw再进行修改，因此，只要是修改embstr对象，修改后的对象一定是raw的，无论是否达到了39个字节。示例如下图所示： 2、列表 （1）概况 列表（list）用来存储多个有序的字符串，每个字符串称为元素；一个列表可以存储2\^32-1个元素。Redis中的列表支持两端插入和弹出，并可以获得指定位置（或范围）的元素，可以充当数组、队列、栈等。 （2）内部编码 列表的内部编码可以是压缩列表（ziplist）或双端链表（linkedlist）。 双端链表：由一个list结构和多个listNode结构组成；典型结构如下图所示： 图片来源：《Redis设计与实现》 通过图中可以看出，双端链表同时保存了表头指针和表尾指针，并且每个节点都有指向前和指向后的指针；链表中保存了列表的长度；dup、free和match为节点值设置类型特定函数，所以链表可以用于保存各种不同类型的值。而链表中每个节点指向的是type为字符串的redisObject。 压缩列表：压缩列表是Redis为了节约内存而开发的，是由一系列特殊编码的连续内存块(而不是像双端链表一样每个节点是指针)组成的顺序型数据结构；具体结构相对比较复杂，略。与双端链表相比，压缩列表可以节省内存空间，但是进行修改或增删操作时，复杂度较高；因此当节点数量较少时，可以使用压缩列表；但是节点数量多时，还是使用双端链表划算。 压缩列表不仅用于实现列表，也用于实现哈希、有序列表；使用非常广泛。 （3）编码转换 只有同时满足下面两个条件时，才会使用压缩列表：列表中元素数量小于512个；列表中所有字符串对象都不足64字节。如果有一个条件不满足，则使用双端列表；且编码只可能由压缩列表转化为双端链表，反方向则不可能。 下图展示了列表编码转换的特点： 其中，单个字符串不能超过64字节，是为了便于统一分配每个节点的长度；这里的64字节是指字符串的长度，不包括SDS结构，因为压缩列表使用连续、定长内存块存储字符串，不需要SDS结构指明长度。后面提到压缩列表，也会强调长度不超过64字节，原理与这里类似。 3、哈希 （1）概况 哈希（作为一种数据结构），不仅是redis对外提供的5种对象类型的一种（与字符串、列表、集合、有序结合并列），也是Redis作为Key-Value数据库所使用的数据结构。为了说明的方便，在本文后面当使用“内层的哈希”时，代表的是redis对外提供的5种对象类型的一种；使用“外层的哈希”代指Redis作为Key-Value数据库所使用的数据结构。 （2）内部编码 内层的哈希使用的内部编码可以是压缩列表（ziplist）和哈希表（hashtable）两种；Redis的外层的哈希则只使用了hashtable。 压缩列表前面已介绍。与哈希表相比，压缩列表用于元素个数少、元素长度小的场景；其优势在于集中存储，节省空间；同时，虽然对于元素的操作复杂度也由O(1)变为了O(n)，但由于哈希中元素数量较少，因此操作的时间并没有明显劣势。 hashtable：一个hashtable由1个dict结构、2个dictht结构、1个dictEntry指针数组（称为bucket）和多个dictEntry结构组成。 正常情况下（即hashtable没有进行rehash时）各部分关系如下图所示： 图片改编自：《Redis设计与实现》 下面从底层向上依次介绍各个部分： dictEntry dictEntry结构用于保存键值对，结构定义如下：123456789typedef struct dictEntry&#123; void *key; union&#123; void *val; uint64_tu64; int64_ts64; &#125;v; struct dictEntry *next;&#125;dictEntry; 其中，各个属性的功能如下： key：键值对中的键； val：键值对中的值，使用union(即共用体)实现，存储的内容既可能是一个指向值的指针，也可能是64位整型，或无符号64位整型； next：指向下一个dictEntry，用于解决哈希冲突问题 在64位系统中，一个dictEntry对象占24字节（key/val/next各占8字节）。 bucket bucket是一个数组，数组的每个元素都是指向dictEntry结构的指针。redis中bucket数组的大小计算规则如下：大于dictEntry的、最小的2\^n；例如，如果有1000个dictEntry，那么bucket大小为1024；如果有1500个dictEntry，则bucket大小为2048。 dictht dictht结构如下： 123456typedef struct dictht&#123; dictEntry **table; unsigned long size; unsigned long sizemask; unsigned long used;&#125;dictht; 其中，各个属性的功能说明如下： table属性是一个指针，指向bucket； size属性记录了哈希表的大小，即bucket的大小； used记录了已使用的dictEntry的数量； sizemask属性的值总是为size-1，这个属性和哈希值一起决定一个键在table中存储的位置。 dict 一般来说，通过使用dictht和dictEntry结构，便可以实现普通哈希表的功能；但是Redis的实现中，在dictht结构的上层，还有一个dict结构。下面说明dict结构的定义及作用。 dict结构如下： 123456typedef struct dict&#123; dictType *type; void *privdata; dictht ht[2]; int trehashidx;&#125; dict; 其中，type属性和privdata属性是为了适应不同类型的键值对，用于创建多态字典。 ht属性和trehashidx属性则用于rehash，即当哈希表需要扩展或收缩时使用。ht是一个包含两个项的数组，每项都指向一个dictht结构，这也是Redis的哈希会有1个dict、2个dictht结构的原因。通常情况下，所有的数据都是存在放dict的ht[0]中，ht[1]只在rehash的时候使用。dict进行rehash操作的时候，将ht[0]中的所有数据rehash到ht[1]中。然后将ht[1]赋值给ht[0]，并清空ht[1]。 因此，Redis中的哈希之所以在dictht和dictEntry结构之外还有一个dict结构，一方面是为了适应不同类型的键值对，另一方面是为了rehash。 （3）编码转换 如前所述，Redis中内层的哈希既可能使用哈希表，也可能使用压缩列表。 只有同时满足下面两个条件时，才会使用压缩列表：哈希中元素数量小于512个；哈希中所有键值对的键和值字符串长度都小于64字节。如果有一个条件不满足，则使用哈希表；且编码只可能由压缩列表转化为哈希表，反方向则不可能。 下图展示了Redis内层的哈希编码转换的特点： 4、集合 （1）概况 集合（set）与列表类似，都是用来保存多个字符串，但集合与列表有两点不同：集合中的元素是无序的，因此不能通过索引来操作元素；集合中的元素不能有重复。 一个集合中最多可以存储2\^32-1个元素；除了支持常规的增删改查，Redis还支持多个集合取交集、并集、差集。 （2）内部编码 集合的内部编码可以是整数集合（intset）或哈希表（hashtable）。 哈希表前面已经讲过，这里略过不提；需要注意的是，集合在使用哈希表时，值全部被置为null。 整数集合的结构定义如下： 12345typedef struct intset&#123; uint32_t encoding; uint32_t length; int8_t contents[];&#125; intset; 其中，encoding代表contents中存储内容的类型，虽然contents（存储集合中的元素）是int8_t类型，但实际上其存储的值是int16_t、int32_t或int64_t，具体的类型便是由encoding决定的；length表示元素个数。 整数集合适用于集合所有元素都是整数且集合元素数量较小的时候，与哈希表相比，整数集合的优势在于集中存储，节省空间；同时，虽然对于元素的操作复杂度也由O(1)变为了O(n)，但由于集合数量较少，因此操作的时间并没有明显劣势。 （3）编码转换 只有同时满足下面两个条件时，集合才会使用整数集合：集合中元素数量小于512个；集合中所有元素都是整数值。如果有一个条件不满足，则使用哈希表；且编码只可能由整数集合转化为哈希表，反方向则不可能。 下图展示了集合编码转换的特点： 5、有序集合 （1）概况 有序集合与集合一样，元素都不能重复；但与集合不同的是，有序集合中的元素是有顺序的。与列表使用索引下标作为排序依据不同，有序集合为每个元素设置一个分数（score）作为排序依据。 （2）内部编码 有序集合的内部编码可以是压缩列表（ziplist）或跳跃表（skiplist）。ziplist在列表和哈希中都有使用，前面已经讲过，这里略过不提。 跳跃表是一种有序数据结构，通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的。除了跳跃表，实现有序数据结构的另一种典型实现是平衡树；大多数情况下，跳跃表的效率可以和平衡树媲美，且跳跃表实现比平衡树简单很多，因此redis中选用跳跃表代替平衡树。跳跃表支持平均O(logN)、最坏O(N)的复杂点进行节点查找，并支持顺序操作。Redis的跳跃表实现由zskiplist和zskiplistNode两个结构组成：前者用于保存跳跃表信息（如头结点、尾节点、长度等），后者用于表示跳跃表节点。具体结构相对比较复杂，略。 （3）编码转换 只有同时满足下面两个条件时，才会使用压缩列表：有序集合中元素数量小于128个；有序集合中所有成员长度都不足64字节。如果有一个条件不满足，则使用跳跃表；且编码只可能由压缩列表转化为跳跃表，反方向则不可能。 下图展示了有序集合编码转换的特点： 五、应用举例 了解Redis的内存模型之后，下面通过几个例子说明其应用。 1、估算Redis内存使用量 要估算redis中的数据占据的内存大小，需要对redis的内存模型有比较全面的了解，包括前面介绍的hashtable、sds、redisobject、各种对象类型的编码方式等。 下面以最简单的字符串类型来进行说明。 假设有90000个键值对，每个key的长度是7个字节，每个value的长度也是7个字节（且key和value都不是整数）；下面来估算这90000个键值对所占用的空间。在估算占据空间之前，首先可以判定字符串类型使用的编码方式：embstr。 90000个键值对占据的内存空间主要可以分为两部分：一部分是90000个dictEntry占据的空间；一部分是键值对所需要的bucket空间。 每个dictEntry占据的空间包括： 1) 一个dictEntry，24字节，jemalloc会分配32字节的内存块 2) 一个key，7字节，所以SDS(key)需要7+9=16个字节，jemalloc会分配16字节的内存块 3) 一个redisObject，16字节，jemalloc会分配16字节的内存块 4)一个value，7字节，所以SDS(value)需要7+9=16个字节，jemalloc会分配16字节的内存块 5) 综上，一个dictEntry需要32+16+16+16=80个字节。 bucket空间：bucket数组的大小为大于90000的最小的2\^n，是131072；每个bucket元素为8字节（因为64位系统中指针大小为8字节）。 因此，可以估算出这90000个键值对占据的内存大小为：90000*80 + 131072*8 =8248576。 下面写个程序在redis中验证一下： 123456789101112131415161718192021222324public class RedisTest &#123; public static Jedis jedis = new Jedis(&quot;localhost&quot;, 6379); public static void main(String[] args) throws Exception&#123; Long m1 = Long.valueOf(getMemory()); insertData(); Long m2 = Long.valueOf(getMemory()); System.out.println(m2 - m1); &#125; public static void insertData()&#123; for(int i = 10000; i &lt; 100000; i++)&#123; jedis.set(&quot;aa&quot; + i, &quot;aa&quot; + i); //key和value长度都是7字节，且不是整数 &#125; &#125; public static String getMemory()&#123; String memoryAllLine = jedis.info(&quot;memory&quot;); String usedMemoryLine = memoryAllLine.split(&quot;\r\n&quot;)[1]; String memory = usedMemoryLine.substring(usedMemoryLine.indexOf(&apos;:&apos;) + 1); return memory; &#125;&#125; 运行结果：8247552 理论值与结果值误差在万分之1.2，对于计算需要多少内存来说，这个精度已经足够了。之所以会存在误差，是因为在我们插入90000条数据之前redis已分配了一定的bucket空间，而这些bucket空间尚未使用。 作为对比将key和value的长度由7字节增加到8字节，则对应的SDS变为17个字节，jemalloc会分配32个字节，因此每个dictEntry占用的字节数也由80字节变为112字节。此时估算这90000个键值对占据内存大小为：90000*112 131072*8 = 11128576。 在redis中验证代码如下（只修改插入数据的代码）： 12345public static void insertData()&#123; for(int i = 10000; i &lt; 100000; i++)&#123; jedis.set(&quot;aaa&quot; + i, &quot;aaa&quot; + i); //key和value长度都是8字节，且不是整数 &#125;&#125; 运行结果：11128576；估算准确。 对于字符串类型之外的其他类型，对内存占用的估算方法是类似的，需要结合具体类型的编码方式来确定。 2、优化内存占用 了解redis的内存模型，对优化redis内存占用有很大帮助。下面介绍几种优化场景。 （1）利用jemalloc特性进行优化 上一小节所讲述的90000个键值便是一个例子。由于jemalloc分配内存时数值是不连续的，因此key/value字符串变化一个字节，可能会引起占用内存很大的变动；在设计时可以利用这一点。 例如，如果key的长度如果是8个字节，则SDS为17字节，jemalloc分配32字节；此时将key长度缩减为7个字节，则SDS为16字节，jemalloc分配16字节；则每个key所占用的空间都可以缩小一半。 （2）使用整型/长整型 如果是整型/长整型，Redis会使用int类型（8字节）存储来代替字符串，可以节省更多空间。因此在可以使用长整型/整型代替字符串的场景下，尽量使用长整型/整型。 （3）共享对象 利用共享对象，可以减少对象的创建（同时减少了redisObject的创建），节省内存空间。目前redis中的共享对象只包括10000个整数（0-9999）；可以通过调整REDIS_SHARED_INTEGERS参数提高共享对象的个数；例如将REDIS_SHARED_INTEGERS调整到20000，则0-19999之间的对象都可以共享。 考虑这样一种场景：论坛网站在redis中存储了每个帖子的浏览数，而这些浏览数绝大多数分布在0-20000之间，这时候通过适当增大REDIS_SHARED_INTEGERS参数，便可以利用共享对象节省内存空间。 （4）避免过度设计 然而需要注意的是，不论是哪种优化场景，都要考虑内存空间与设计复杂度的权衡；而设计复杂度会影响到代码的复杂度、可维护性。 如果数据量较小，那么为了节省内存而使得代码的开发、维护变得更加困难并不划算；还是以前面讲到的90000个键值对为例，实际上节省的内存空间只有几MB。但是如果数据量有几千万甚至上亿，考虑内存的优化就比较必要了。 3、关注内存碎片率 内存碎片率是一个重要的参数，对redis 内存的优化有重要意义。 如果内存碎片率过高（jemalloc在1.03左右比较正常），说明内存碎片多，内存浪费严重；这时便可以考虑重启redis服务，在内存中对数据进行重排，减少内存碎片。 如果内存碎片率小于1，说明redis内存不足，部分数据使用了虚拟内存（即swap）；由于虚拟内存的存取速度比物理内存差很多（2-3个数量级），此时redis的访问速度可能会变得很慢。因此必须设法增大物理内存（可以增加服务器节点数量，或提高单机内存），或减少redis中的数据。 要减少redis中的数据，除了选用合适的数据类型、利用共享对象等，还有一点是要设置合理的数据回收策略（maxmemory-policy），当内存达到一定量后，根据不同的优先级对内存进行回收。 六、参考文献 《Redis开发与运维》 《Redis设计与实现》 https://redis.io/documentation http://redisdoc.com/server/info.html qqqq/lhcpig/p/4769397.html https://searchdatabase.techtarget.com.cn/7-20218/ http://www.cnblogs.com/mushroom/p/4738170.html http://www.imooc.com/article/3645 http://blog.csdn.net/zhengpeitao/article/details/76573053]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>redis深入系统学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F05%2F31%2Fhello-world%2F</url>
    <content type="text"><![CDATA[welcome here !]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>生活</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ThreadLocal及ThreadLocal内存溢出分析]]></title>
    <url>%2F2019%2F05%2F24%2FThreadLocal%E5%8F%8AThreadLocal%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[ThreadLocal 定义，以及是否可能引起的内存泄露(threadlocalMap的Key是弱引用，用线程池有可能泄露)ThreadLocal 也可以跟踪一个请求，从接收请求，处理请求，到返回请求，只要线程不销毁，就可以在线程的任何地方，调用这个参数，这是百度二面的题目，参考：1Threadlocal 传递参数(百度二面) ： https://www.cnblogs.com/aspirant/p/9183920.html 12345总结：1. JVM利用设置ThreadLocalMap的Key为弱引用，来避免内存泄露。2. JVM利用调用remove、get、set方法的时候，回收弱引用。3. 当ThreadLocal存储很多Key为null的Entry的时候，而不再去调用remove、get、set方法，那么将导致内存泄漏。4. 当使用static ThreadLocal的时候，延长ThreadLocal的生命周期，那也可能导致内存泄漏。因为，static变量在类未加载的时候，它就已经加载，当线程结束的时候，static变量不一定会回收。那么，比起普通成员变量使用的时候才加载，static的生命周期加长将更容易导致内存泄漏危机。http://www.importnew.com/22039.html 那么如何有效的避免呢？ 事实上，在ThreadLocalMap中的set/getEntry方法中，会对key为null（也即是ThreadLocal为null）进行判断，如果为null的话，那么是会对value置为null的。我们也可以通过调用ThreadLocal的remove方法进行释放！ threadlocal里面使用了一个存在弱引用的map,当释放掉threadlocal的强引用以后,map里面的value却没有被回收.而这块value永远不会被访问到了. 所以存在着内存泄露. 最好的做法是将调用threadlocal的remove方法. 在threadlocal的生命周期中,都存在这些引用. 看下图: 实线代表强引用,虚线代表弱引用.每个thread中都存在一个map, map的类型是ThreadLocal.ThreadLocalMap. Map中的key为一个threadlocal实例. 这个Map的确使用了弱引用,不过弱引用只是针对key. 每个key都弱引用指向threadlocal. 当把threadlocal实例置为null以后,没有任何强引用指向threadlocal实例,所以threadlocal将会被gc回收. 但是,我们的value却不能回收,因为存在一条从current thread连接过来的强引用. 只有当前thread结束以后, current thread就不会存在栈中,强引用断开, Current Thread, Map, value将全部被GC回收. 所以得出一个结论就是只要这个线程对象被gc回收，就不会出现内存泄露，但在threadLocal设为null和线程结束这段时间不会被回收的，就发生了我们认为的内存泄露.其实这是一个对概念理解的不一致，也没什么好争论的。最要命的是线程对象不被回收的情况，这就发生了真正意义上的内存泄露。比如使用线程池的时候，线程结束是不会销毁的，会再次使用的。就可能出现内存泄露。 PS.Java为了最小化减少内存泄露的可能性和影响，在ThreadLocal的get,set的时候都会清除线程Map里所有key为null的value。所以最怕的情况就是，threadLocal对象设null了，开始发生“内存泄露”，然后使用线程池，这个线程结束，线程放回线程池中不销毁，这个线程一直不被使用，或者分配使用了又不再调用get,set方法，那么这个期间就会发生真正的内存泄露。 应用场景最常见的ThreadLocal使用场景为 用来解决 数据库连接、Session管理等。如1234567891011121314151617181920212223private static ThreadLocal &lt; Connection &gt; connectionHolder = new ThreadLocal &lt; Connection &gt; () &#123; public Connection initialValue() &#123; return DriverManager.getConnection(DB_URL); &#125;&#125;;public static Connection getConnection() &#123; return connectionHolder.get();&#125;private static final ThreadLocal threadSession = new ThreadLocal();public static Session getSession() throws InfrastructureException &#123; Session s = (Session) threadSession.get(); try &#123; if (s == null) &#123; s = getSessionFactory().openSession(); threadSession.set(s); &#125; &#125; catch (HibernateException ex) &#123; throw new InfrastructureException(ex); &#125; return s;&#125; ThreadLocal是什么？有什么用？引入话题：在并发条件下，如何正确获得共享数据？举例：假设有多个用户需要获取用户信息，一个线程对应一个用户。在mybatis中，session用于操作数据库，那么设置、获取操作分别是session.set()、session.get()，如何保证每个线程都能正确操作达到想要的结果？ 12345678910111213141516171819202122232425262728293031323334/** * 回顾synchronized在多线程共享线程的问题 * @author qiuyongAaron */public class ThreadLocalOne &#123; volatile Person person=new Person(); public synchronized String setAndGet(String name)&#123; //System.out.print(Thread.currentThread().getName()+":"); person.name=name; //模拟网络延迟 try &#123; TimeUnit.SECONDS.sleep(2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return person.name; &#125; public static void main(String[] args) &#123; ThreadLocalOne threadLocal=new ThreadLocalOne(); new Thread(()-&gt;System.out.println(threadLocal.setAndGet("arron")),"t1").start(); new Thread(()-&gt;System.out.println(threadLocal.setAndGet("tony")),"t2").start(); &#125;&#125; class Person&#123; String name="tom"; public Person(String name) &#123; this.name=name; &#125; public Person()&#123;&#125;&#125; 12345678运行结果：无synchronized：t1:tonyt2:tony 有synchronized：t1:arront2:tony 步骤分析:1. 无synchronized的时候，因为非原子操作，显然不是预想结果，可参考我关于synchronized的讨论。 2. 现在，我们的需求是：每个线程独立的设置获取person信息，不被线程打扰。 3. 因为，person是共享数据，用同步互斥锁synchronized，当一个线程访问共享数据的时候，其他线程堵塞，不再多余赘述。 通过举例问题，可能大家又会很疑惑？mybatis、hibernate是如何实现的呢？synchronized不会很消耗资源，当成千上万个操作的时候，承受并发不说，数据返回延迟如何确保用户体验？ ThreadLocal是什么？有什么用？ 12345678910111213141516171819202122/** * 谈谈ThreadLocal的作用 * @author qiuyongAaron */public class ThreadLocalThree &#123; ThreadLocal&lt;Person&gt; threadLocal=new ThreadLocal&lt;Person&gt;(); public String setAndGet(String name)&#123; threadLocal.set(new Person(name)); try &#123; TimeUnit.SECONDS.sleep(2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return threadLocal.get().name; &#125; public static void main(String[] args) &#123; ThreadLocalThree threadLocal=new ThreadLocalThree(); new Thread(()-&gt;System.out.println("t1:"+threadLocal.setAndGet("arron")),"t1").start(); new Thread(()-&gt;System.out.println("t2:"+threadLocal.setAndGet("tony")),"t2").start(); &#125;&#125; 123运行结果：t1:arront2:tony 分析：1、根据预期结果，那ThreadLocal到底是什么？回顾Java内存模型： 在虚拟机中，堆内存用于存储共享数据（实例对象），堆内存也就是这里说的主内存。 每个线程将会在堆内存中开辟一块空间叫做线程的工作内存，附带一块缓存区用于存储共享数据副本。那么，共享数据在堆内存当中，线程通信就是通过主内存为中介，线程在本地内存读并且操作完共享变量操作完毕以后，把值写入主内存。 1. ThreadLocal被称为线程局部变量，说白了，他就是线程工作内存的一小块内存，用于存储数据。 2. 那么，ThreadLocal.set()、ThreadLocal.get()方法，就相当于把数据存储于线程本地，取也是在本地内存读取。就不会像synchronized需要频繁的修改主内存的数据，再把数据复制到工作内存，也大大提高访问效率。 2、ThreadLocal到底有什么用？ 1. 回到最开始的举例，也就等价于mabatis、hibernate为什么要使用threadlocal来存储session？ 2. 作用一：因为线程间的数据交互是通过工作内存与主存的频繁读写完成通信，然而存储于线程本地内存，提高访问效率，避免线程阻塞造成cpu吞吐率下降。 3. 作用二：在多线程中，每一个线程都需要维护session，轻易完成对线程独享资源的操作。 总结： Threadlocal是什么？在堆内存中，每个线程对应一块工作内存，threadlocal就是工作内存的一小块内存。 Threadlocal有什么用？threadlocal用于存取线程独享数据，提高访问效率。 ThreadLocal源码简要总结？那有同学可能还是有点云里雾里，感觉还是没有吃透？那线程内部如何去保证线程独享数据呢？在这里，我只做简要总结，若有兴趣，可参考文章尾部的文章链接。重点看get、set方法。12345678public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); &#125; 分析 一个线程对应一个ThreadLocalMap ，可以存储多个ThreadLocal对象。 ThreadLocal对象作为key、独享数据作为value。 ThreadLocalMap可参考HashMap，在ThreadMap里面存在Entry数组也就是一个Entry一个键值对。 12345678910111213public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(&quot;unchecked&quot;) T result = (T)e.value; return result; &#125; &#125; return setInitialValue(); &#125; 分析 一个线程对应一个ThreadLocalMap，get()就是当前线程获取自己的ThreadLocalMap。 线程根据使用那一小块的threadlocal，根据ThreadLocal对象作为key，去获取存储于ThreadLocalMap中的值。 总结回顾一下，我们在单线程中如何使用HashMap的？hashMap根据数组+链表来实现HashMap，一个key对应一个value。那么，我们抽象一下，Threadlocal也相当于在多线程中的一种HashMap用法，相当于对ThradLocal的操作也就如单线程操作一样。总之，ThreadLocal就是堆内存的一块小内存，它用ThreadLocalMap维护ThreadLocal对象作为key，独享数据作为value的东西。 ThreadLocal为什么会导致内存泄漏？synchronized是用时间换空间(牺牲时间)、ThreadLocal是用空间换时间(牺牲空间)，为什么这么说？因为synchronized操作数据，只需要在主存存一个变量即可，就阻塞等共享变量，而ThreadLocal是每个线程都创建一块小的堆工作内存。显然，印证了上面的说法。 一个线程对应一块工作内存，线程可以存储多个ThreadLocal。那么假设，开启1万个线程，每个线程创建1万个ThreadLocal，也就是每个线程维护1万个ThreadLocal小内存空间，而且当线程执行结束以后，假设这些ThreadLocal里的Entry还不会被回收，那么将很容易导致堆内存溢出。 怎么办？难道JVM就没有提供什么解决方案吗？ThreadLocal当然有想到，所以他们把ThreadLocal里的Entry设置为弱引用，当垃圾回收的时候，回收ThreadLocal。什么是弱引用？ Key使用强引用：也就是上述说的情况，引用ThreadLocal的对象被回收了，ThreadLocal的引用ThreadLocalMap的Key为强引用并没有被回收，如果不手动回收的话，ThreadLocal将不会回收那么将导致内存泄漏。 Key使用弱引用：引用的ThreadLocal的对象被回收了，ThreadLocal的引用ThreadLocalMap的Key为弱引用，如果内存回收，那么将ThreadLocalMap的Key将会被回收，ThreadLocal也将被回收。value在ThreadLocalMap调用get、set、remove的时候就会被清除。 比较两种情况，我们可以发现：由于ThreadLocalMap的生命周期跟Thread一样长，如果都没有手动删除对应key，都会导致内存泄漏，但是使用弱引用可以多一层保障：弱引用ThreadLocal不会内存泄漏，对应的value在下一次ThreadLocalMap调用set,get,remove的时候会被清除。 那按你这么说，既然JVM有保障了，还有什么内存泄漏可言？ThreadLocalMap使用ThreadLocal对象作为弱引用，当垃圾回收的时候，ThreadLocalMap中Key将会被回收，也就是将Key设置为null的Entry。如果线程迟迟无法结束，也就是ThreadLocal对象将一直不会回收，回顾到上面存在很多线程+TheradLocal，那么也将导致内存泄漏。(内存泄露的重点) 其实，在ThreadLocal中，当调用remove、get、set方法的时候，会清除为null的弱引用，也就是回收ThreadLocal。 1ThreadLocal提供一个线程（Thread）局部变量，访问到某个变量的每一个线程都拥有自己的局部变量。说白了，ThreadLocal就是想在多线程环境下去保证成员变量的安全。 ThreadLocal提供的方法ThreadLocal API1对于ThreadLocal而言，常用的方法，就是get/set/initialValue方法。 我们先来看一个例子运行结果是你想象中的结果么？很显然，在这里，并没有通过ThreadLocal达到线程隔离的机制，可是ThreadLocal不是保证线程安全的么？这是什么鬼？虽然，ThreadLocal让访问某个变量的线程都拥有自己的局部变量，但是如果这个局部变量都指向同一个对象呢？这个时候ThreadLocal就失效了。仔细观察下图中的代码，你会发现，threadLocal在初始化时返回的都是同一个对象a！ 看一看ThreadLocal源码我们直接看最常用的set操作：set线程局部变量createMap 你会看到，set需要首先获得当前线程对象Thread； 然后取出当前线程对象的成员变量ThreadLocalMap； 如果ThreadLocalMap存在，那么进行KEY/VALUE设置，KEY就是ThreadLocal； 如果ThreadLocalMap没有，那么创建一个； 说白了，当前线程中存在一个Map变量，KEY是ThreadLocal，VALUE是你设置的值。 看一下get操作：get1这里其实揭示了ThreadLocalMap里面的数据存储结构，从上面的代码来看，ThreadLocalMap中存放的就是Entry，Entry的KEY就是ThreadLocal，VALUE就是值 ThreadLocalMap.Entry：弱引用？在JAVA里面，存在强引用、弱引用、软引用、虚引用。这里主要谈一下强引用和弱引用。强引用，就不必说了，类似于： A a = new A(); B b = new B(); 考虑这样的情况： C c = new C(b); b = null; 考虑下GC的情况。要知道b被置为null，那么是否意味着一段时间后GC工作可以回收b所分配的内存空间呢？答案是否定的，因为即便b被置为null，但是c仍然持有对b的引用，而且还是强引用，所以GC不会回收b原先所分配的空间！既不能回收利用，又不能使用，这就造成了内存泄露。那么如何处理呢？ 可以c = null;也可以使用弱引用！（WeakReference w = new WeakReference(b);） 分析到这里，我们可以得到：内存结构图这里我们思考一个问题：ThreadLocal使用到了弱引用，是否意味着不会存在内存泄露呢？ 首先来说，如果把ThreadLocal置为null，那么意味着Heap中的ThreadLocal实例不在有强引用指向，只有弱引用存在，因此GC是可以回收这部分空间的，也就是key是可以回收的。但是value却存在一条从Current Thread过来的强引用链。因此只有当Current Thread销毁时，value才能得到释放。 因此，只要这个线程对象被gc回收，就不会出现内存泄露，但在threadLocal设为null和线程结束这段时间内不会被回收的，就发生了我们认为的内存泄露。最要命的是线程对象不被回收的情况，比如使用线程池的时候，线程结束是不会销毁的，再次使用的，就可能出现内存泄露。 那么如何有效的避免呢？ 事实上，在ThreadLocalMap中的set/getEntry方法中，会对key为null（也即是ThreadLocal为null）进行判断，如果为null的话，那么是会对value置为null的。我们也可以通过调用ThreadLocal的remove方法进行释放！ 1来源：https://www.cnblogs.com/aspirant/p/8991010.html]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java并发系统学习番外篇</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[内存溢出&&栈溢出]]></title>
    <url>%2F2019%2F05%2F24%2F%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA-%E6%A0%88%E6%BA%A2%E5%87%BA%2F</url>
    <content type="text"><![CDATA[内存溢出&amp;&amp;栈溢出 内存溢出 内存溢出的原因是什么？内存溢出是由于没被引用的对象（垃圾）过多造成JVM没有及时回收，造成的内存溢出。如果出现这种现象可行代码排查： 是否应用中的类中和引用变量过多使用了Static修饰 如public staitc Student s；在类中的属性中使用 static修饰的最好只用基本类型或字符串。如public static int i = 0; //public static String str; 是否 应用 中使用了大量的递归或无限递归（递归中用到了大量的建新的对象） 是否App中使用了大量循环或死循环（循环中用到了大量的新建的对象） 检查 应用 中是否使用了向数据库查询所有记录的方法。即一次性全部查询的方法，如果数据量超过10万多条了，就可能会造成内存溢出。所以在查询时应采用“分页查询”。 检查是否有数组，List，Map中存放的是对象的引用而不是对象，因为这些引用会让对应的对象不能被释放。会大量存储在内存中。 检查是否使用了“非字面量字符串进行+”的操作。因为String类的内容是不可变的，每次运行”+”就会产生新的对象，如果过多会造成新String对象过多，从而导致JVM没有及时回收而出现内存溢出。 1234567891011如String s1 = &quot;My name&quot;;String s2 = &quot;is&quot;;String s3 = &quot;xuwei&quot;;String str = s1 + s2 + s3 +.........;这是会容易造成内存溢出的但是String str = &quot;My name&quot; + &quot; is &quot; + &quot; xuwei&quot; + &quot; nice &quot; + &quot; to &quot; + &quot; meet you&quot;; //但是这种就不会造成内存溢出。因为这是”字面量字符串“，在运行&quot;+&quot;时就会在编译期间运行好。不会按照JVM来执行的。在使用String,StringBuffer,StringBuilder时，如果是字面量字符串进行&quot;+&quot;时，应选用String性能更好；如果是String类进行&quot;+&quot;时，在不考虑线程安全时，应选用StringBuilder性能更好。 12345678910111213141516171819public class Test &#123; public void testHeap()&#123; for(;;)&#123; //死循环一直创建对象，堆溢出 ArrayList list = new ArrayList (2000); &#125; &#125; int num=1; public void testStack()&#123; //无出口的递归调用，栈溢出 num++; this.testStack(); &#125; public static void main(String[] args)&#123; Test t = new Test (); t.testHeap(); t.testStack(); &#125; &#125; 栈溢出的原因 是否有递归调用 是否有大量循环或死循环 全局变量是否过多 数组、List、map数据是否过大 使用DDMS工具进行查找大概出现栈溢出的位置 JVM系列之实战内存溢出异常对象的创建过程关于对象的创建，第一反应是new关键字，那么本文就主要讲解new关键字创建对象的过程。1Student stu =new Student(&quot;张三&quot;，&quot;18&quot;); 就拿上面这句代码来说，虚拟机首先会去检查Student这个类有没有被加载，如果没有，首先去加载这个类到方法区，然后根据加载的Class类对象创建stu实例对象，需要注意的是，stu对象所需的内存大小在Student类加载完成后便可完全确定。内存分配完成后，虚拟机需要将分配到的内存空间的实例数据部分初始化为零值,这也就是为什么我们在编写Java代码时创建一个变量不需要初始化。紧接着，虚拟机会对对象的对象头进行必要的设置，如这个对象属于哪个类，如何找到类的元数据(Class对象),对象的锁信息，GC分代年龄等。设置完对象头信息后，调用类的构造函数。其实讲实话，虚拟机创建对象的过程远不止这么简单，我这里只是把大致的脉络讲解了一下，方便大家理解。 对象的内存布局刚刚提到的实例数据，对象头，有些小伙伴也许有点陌生，这一小节就详细讲解一下对象的内存布局,对象创建完成后大致可以分为以下几个部分: 对象头 实例数据 对齐填充 对象头 : 对象头中包含了对象运行时一些必要的信息，如GC分代信息，锁信息，哈希码，指向Class类元信息的指针等，其中对Javaer比较有用的是锁信息与指向Class对象的指针，关于锁信息，后期有机会讲解并发编程JUC时再扩展，关于指向Class对象的指针其实很好理解。比如上面那个Student的例子，当我们拿到stu对象时，调用Class stuClass=stu.getClass();的时候，其实就是根据这个指针去拿到了stu对象所属的Student类在方法区存放的Class类对象。虽然说的有点拗口，但这句话我反复琢磨了好几遍，应该是说清楚了。^_^ 实例数据 :实例数据部分是对象真正存储的有效信息，就是程序代码中所定义的各种类型的字段内容。 对齐填充 :虚拟机规范要求对象大小必须是8字节的整数倍。对齐填充其实就是来补全对象大小的。 对象的访问定位谈到对象的访问，还拿上面学生的例子来说，当我们拿到stu对象时，直接调用stu.getName();时，其实就完成了对对象的访问。但这里要累赘说一下的是，stu虽然通常被认为是一个对象，其实准确来说是不准确的，stu只是一个变量，变量里存储的是指向对象的指针，(如果干过C或者C++的小伙伴应该比较清楚指针这个概念)，当我们调用stu.getName()时，虚拟机会根据指针找到堆里面的对象然后拿到实例数据name.需要注意的是，当我们调用stu.getClass()时，虚拟机会首先根据stu指针定位到堆里面的对象，然后根据对象头里面存储的指向Class类元信息的指针再次到方法区拿到Class对象，进行了两次指针寻找。具体讲解图如下: 实战内存异常内存异常是我们工作当中经常会遇到问题，但如果仅仅会通过加大内存参数来解决问题显然是不够的，应该通过一定的手段定位问题，到底是因为参数问题，还是程序问题(无限创建，内存泄露)。定位问题后才能采取合适的解决方案，而不是一内存溢出就查找相关参数加大。 123概念- 内存泄露:代码中的某个对象本应该被虚拟机回收，但因为拥有GCRoot引用而没有被回收。关于GCRoot概念，下一篇文章讲解。- 内存溢出: 虚拟机由于堆中拥有太多不可回收对象没有回收，导致无法继续创建新对象。 在分析问题之前先给大家讲一讲排查内存溢出问题的方法，内存溢出时JVM虚拟机会退出，那么我们怎么知道JVM运行时的各种信息呢，Dump机制会帮助我们，可以通过加上VM参数-XX:+HeapDumpOnOutOfMemoryError让虚拟机在出现内存溢出异常时生成dump文件，然后通过外部工具(作者使用的是VisualVM)来具体分析异常的原因。 下面从以下几个方面来配合代码实战演示内存溢出及如何定位: Java堆内存异常 Java栈内存异常 方法区内存异常 Java堆内存异常12345678910111213/** VM Args: //这两个参数保证了堆中的可分配内存固定为20M -Xms20m -Xmx20m //文件生成的位置，作则生成在桌面的一个目录 -XX:+HeapDumpOnOutOfMemoryError //文件生成的位置，作则生成在桌面的一个目录 //文件生成的位置，作则生成在桌面的一个目录 -XX:HeapDumpPath=/Users/zdy/Desktop/dump/ */public class HeapOOM &#123; //创建一个内部类用于创建对象使用 static class OOMObject &#123; &#125; public static void main(String[] args) &#123; List&lt;OOMObject&gt; list = new ArrayList&lt;OOMObject&gt;(); //无限创建对象，在堆中 while (true) &#123; list.add(new OOMObject()); &#125; &#125;&#125; Run起来代码后爆出异常如下: java.lang.OutOfMemoryError: Java heap spaceDumping heap to /Users/zdy/Desktop/dump/java_pid1099.hprof … 可以看到生成了dump文件到指定目录。并且爆出了OutOfMemoryError，还告诉了你是哪一片区域出的问题:heap space 打开VisualVM工具导入对应的heapDump文件(如何使用请读者自行查阅相关资料)，相应的说明见图:“类标签” 切换到”实例数”标签页“实例数标签” 分析dump文件后，我们可以知道，OOMObject这个类创建了810326个实例。所以它能不溢出吗？接下来就在代码里找这个类在哪new的。排查问题。(我们的样例代码就不用排查了，While循环太凶猛了) Java栈内存异常老实说，在栈中出现异常(StackOverFlowError)的概率小到和去苹果专卖店买手机，买回来后发现是Android系统的概率是一样的。因为作者确实没有在生产环境中遇到过，除了自己作死写样例代码测试。先说一下异常出现的情况，前面讲到过，方法调用的过程就是方法帧进虚拟机栈和出虚拟机栈的过程，那么有两种情况可以导致StackOverFlowError,当一个方法帧(比如需要2M内存)进入到虚拟机栈(比如还剩下1M内存)的时候，就会报出StackOverFlow.这里先说一个概念，栈深度:指目前虚拟机栈中没有出栈的方法帧。虚拟机栈容量通过参数-Xss来控制,下面通过一段代码，把栈容量人为的调小一点，然后通过递归调用触发异常。 12345678910111213141516171819/** * VM Args： //设置栈容量为160K，默认1M -Xss160k */public class JavaVMStackSOF &#123; private int stackLength = 1; public void stackLeak() &#123; stackLength++; //递归调用，触发异常 stackLeak(); &#125; public static void main(String[] args) throws Throwable &#123; JavaVMStackSOF oom = new JavaVMStackSOF(); try &#123; oom.stackLeak(); &#125; catch (Throwable e) &#123; System.out.println("stack length:" + oom.stackLength); throw e; &#125; &#125;&#125; 结果如下:stack length:751Exception in thread “main” java.lang.StackOverflowError 可以看到，递归调用了751次，栈容量不够用了。默认的栈容量在正常的方法调用时，栈深度可以达到1000-2000深度，所以，一般的递归是可以承受的住的。如果你的代码出现了StackOverflowError，首先检查代码，而不是改参数。 这里顺带提一下，很多人在做多线程开发时，当创建很多线程时，容易出现OOM(OutOfMemoryError),这时可以通过具体情况，减少最大堆容量，或者栈容量来解决问题，这是为什么呢。请看下面的公式: 线程数 乘以 (最大栈容量)+最大堆值+其他内存(忽略不计或者一般不改动)=机器最大内存 当线程数比较多时，且无法通过业务上削减线程数，那么再不换机器的情况下，你只能把最大栈容量设置小一点，或者把最大堆值设置小一点。 方法区内存异常写到这里时，作者本来想写一个无限创建动态代理对象的例子来演示方法区溢出，避开谈论JDK7与JDK8的内存区域变更的过渡，但细想一想，还是把这一块从始致终的说清楚。在上一篇文章中JVM系列之Java内存结构详解讲到方法区时提到，JDK7环境下方法区包括了(运行时常量池),其实这么说是不准确的。因为从JDK7开始，HotSpot团队就想到开始去”永久代”,大家首先明确一个概念，方法区和”永久代”(PermGen space)是两个概念，方法区是JVM虚拟机规范，任何虚拟机实现(J9等)都不能少这个区间，而”永久代”只是HotSpot对方法区的一个实现。为了把知识点列清楚，我还是才用列表的形式: JDK7之前(包括JDK7)拥有”永久代”(PermGen space),用来实现方法区。但在JDK7中已经逐渐在实现中把永久代中把很多东西移了出来，比如:符号引用(Symbols)转移到了native heap,运行时常量池(interned strings)转移到了java heap；类的静态变量(class statics)转移到了java heap.所以这就是为什么我说上一篇文章中说方法区中包含运行时常量池是不正确的，因为已经移动到了java heap; 在JDK7之前(包括7)可以通过-XX:PermSize -XX:MaxPermSize来控制永久代的大小. JDK8正式去除”永久代”,换成Metaspace(元空间)作为JVM虚拟机规范中方法区的实现。 元空间与永久代之间最大的区别在于：元空间并不在虚拟机中，而是使用本地内存。因此，默认情况下，元空间的大小仅受本地内存限制，但仍可以通过参数控制:-XX:MetaspaceSize与-XX:MaxMetaspaceSize来控制大小。 下面作者还是通过一段代码，来不停的创建Class对象，在JDK8中可以看到metaSpace内存溢出:1234567891011121314151617181920/** 作者准备在JDK8下测试方法区，所以设置了Metaspace的大小为固定的8M -XX:MetaspaceSize=8m -XX:MaxMetaspaceSize=8m */public class JavaMethodAreaOOM &#123; public static void main(String[] args) &#123; while (true) &#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(OOMObject.class); enhancer.setUseCache(false); enhancer.setCallback(new MethodInterceptor() &#123; public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable &#123; return proxy.invokeSuper(obj, args); &#125; &#125;); //无限创建动态代理，生成Class对象 enhancer.create(); &#125; &#125; static class OOMObject &#123; &#125;&#125; 在JDK8的环境下将报出异常:Exception in thread “main” java.lang.OutOfMemoryError: Metaspace这是因为在调用CGLib的创建代理时会生成动态代理类，即Class对象到Metaspace,所以While一下就出异常了。提醒一下:虽然我们日常叫”堆Dump”,但是dump技术不仅仅是对于”堆”区域才有效，而是针对OOM的，也就是说不管什么区域，凡是能够报出OOM错误的，都可以使用dump技术生成dump文件来分析。 在经常动态生成大量Class的应用中，需要特别注意类的回收状况，这类场景除了例子中的CGLib技术，常见的还有，大量JSP，反射，OSGI等。需要特别注意，当出现此类异常，应该知道是哪里出了问题，然后看是调整参数，还是在代码层面优化。 附加-直接内存异常直接内存异常非常少见，而且机制很特殊，因为直接内存不是直接向操作系统分配内存，而且通过计算得到的内存不够而手动抛出异常，所以当你发现你的dump文件很小，而且没有明显异常，只是告诉你OOM，你就可以考虑下你代码里面是不是直接或者间接使用了NIO而导致直接内存溢出。 1来源：https://my.oschina.net/u/2401092/blog/1621850]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java并发系统学习番外篇</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并发编程之线程安全性、安全发布对象]]></title>
    <url>%2F2019%2F05%2F23%2F%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E6%80%A7%E3%80%81%E5%AE%89%E5%85%A8%E5%8F%91%E5%B8%83%E5%AF%B9%E8%B1%A1%2F</url>
    <content type="text"><![CDATA[线程安全性当多个线程访问某个类时，不管运行时环境采用何种调度方式或者这些进程将如何交替执行，并且在主调代码中不需要任何额外的同步或协调，这个类都能表现出正确的行为，那么就称这个类是线程安全的。线程安全性主要体现： 原子性：提供了互斥访问，同一时刻只能有一个线程来对它进行操作 可见性：一个线程对主内存的修改可以及时的被其他线程观察到 有序性：一个线程观察其他线程中的指令执行顺序，由于指令重排序的存在，该观察结果一般是杂乱无序 原子性Atomic包位于java.util.concurrent.atomicAtomicXXX : CAS、Unsafe.compareAndSwapXXX CAS（Compare and swap）比较和替换是设计并发算法时用到的一种技术。简单来说，比较和替换是使用一个期望值和一个变量的当前值进行比较，如果当前变量的值与我们期望的值相等，就使用一个新值替换当前变量的值。 AtomicInteger123456789101112131415161718192021222324252627282930313233343536373839@Slf4j@ThreadSafepublic class CountExample2 &#123; // 请求总数 public static int clientTotal = 5000; // 同时并发执行的线程数 public static int threadTotal = 200; //从int类型换成了AtomicInteger public static AtomicInteger count = new AtomicInteger(0); public static void main(String[] args) throws Exception &#123; ExecutorService executorService = Executors.newCachedThreadPool(); final Semaphore semaphore = new Semaphore(threadTotal); final CountDownLatch countDownLatch = new CountDownLatch(clientTotal); for (int i = 0; i &lt; clientTotal ; i++) &#123; executorService.execute(() -&gt; &#123; try &#123; semaphore.acquire(); add(); semaphore.release(); &#125; catch (Exception e) &#123; log.error(&quot;exception&quot;, e); &#125; countDownLatch.countDown(); &#125;); &#125; countDownLatch.await(); executorService.shutdown(); log.info(&quot;count:&#123;&#125;&quot;, count.get()); &#125; private static void add() &#123; //调用了AtomicInteger方法 count.incrementAndGet(); // count.getAndIncrement(); &#125;&#125; 线程安全？源码分析AtomicInteger.java1234567891011121314151617private static final long serialVersionUID = 6214790243416807050L;// setup to use Unsafe.compareAndSwapInt for updatesprivate static final Unsafe unsafe = Unsafe.getUnsafe(); //通过反射获得private static final long valueOffset;static &#123; try &#123; valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField(&quot;value&quot;)); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125;&#125;private volatile int value;public final int incrementAndGet() &#123; //this 代表当前AtomicInteger对象 return unsafe.getAndAddInt(this, valueOffset, 1) + 1;&#125; Unsafe.java 123456789101112131415161718192021222324//本地方法，java底层方法/** * @param var1 对象 * @param var2 偏移量 * @param var3 期望值 * @param var5 修改值 */ public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5);/** * @param var1 当前对象 * @param var2 当前值 * @param var3 增量 */public final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; //底层值 do &#123; var5 = this.getIntVolatile(var1, var2); &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); // CAS核心 //当前值与底层值相同，则更新成var5 + var4 //不一样则不停的循环，直到值相同 return var5; &#125; AtomicInLong 与 LongAdder 1234567891011121314151617181920212223242526272829303132333435363738@Slf4j@ThreadSafepublic class AtomicExample2 &#123; // 请求总数 public static int clientTotal = 5000; // 同时并发执行的线程数 public static int threadTotal = 200; public static AtomicLong count = new AtomicLong(0); public static void main(String[] args) throws Exception &#123; ExecutorService executorService = Executors.newCachedThreadPool(); final Semaphore semaphore = new Semaphore(threadTotal); final CountDownLatch countDownLatch = new CountDownLatch(clientTotal); for (int i = 0; i &lt; clientTotal ; i++) &#123; executorService.execute(() -&gt; &#123; try &#123; semaphore.acquire(); add(); semaphore.release(); &#125; catch (Exception e) &#123; log.error(&quot;exception&quot;, e); &#125; countDownLatch.countDown(); &#125;); &#125; countDownLatch.await(); executorService.shutdown(); log.info(&quot;count:&#123;&#125;&quot;, count.get()); &#125; private static void add() &#123; count.incrementAndGet(); // count.getAndIncrement(); &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637@Slf4j@ThreadSafepublic class AtomicExample3 &#123; // 请求总数 public static int clientTotal = 5000; // 同时并发执行的线程数 public static int threadTotal = 200; public static LongAdder count = new LongAdder(); public static void main(String[] args) throws Exception &#123; ExecutorService executorService = Executors.newCachedThreadPool(); final Semaphore semaphore = new Semaphore(threadTotal); final CountDownLatch countDownLatch = new CountDownLatch(clientTotal); for (int i = 0; i &lt; clientTotal ; i++) &#123; executorService.execute(() -&gt; &#123; try &#123; semaphore.acquire(); add(); semaphore.release(); &#125; catch (Exception e) &#123; log.error(&quot;exception&quot;, e); &#125; countDownLatch.countDown(); &#125;); &#125; countDownLatch.await(); executorService.shutdown(); log.info(&quot;count:&#123;&#125;&quot;, count); &#125; private static void add() &#123; count.increment(); &#125;&#125; AtomicInLong 与 LongAdder 比较就像我们所知道的那样,AtomicLong的原理是依靠底层的cas来保障原子性的更新数据，在要添加或者减少的时候，会使用死循环不断地cas到特定的值，从而达到更新数据的目的。如果竞争不激烈，修改成功几率很高，否则失败概率很高，在失败几率很高的情况下，这些原子操作就会进行多次的循环操作尝试，因此性能会受到影响。 对于普通类型的Long和Doubble变量，JVM允许将64位的读操作或写操作拆成两个三十二位的操作。 LongAdder的核心是将热点数据分离，比如说它可以将AtomicLong内部核心数据value分离成一个数组，每个线程访问时，通过hash等算法，映射到其中一个数字进行计数，最终的计数结果则会这个数据的求和累加，其中热点数据value会被分离成多个cell，每个cell独自维护内部的值，当前对象实际值为所有cell累计合成，这样的话，热点就进行了有效的分离，并提高了并行度。 LongAdder在AtomicLong的基础上将单点的更新压力分散到各个节点，在低并发的时候通过对base的直接更新可以很好的保障和AtomicLong的性能基本保持一致，而在高并发的时候通过分散提高了性能。 ​缺点是LongAdder在统计的时候如果有并发更新，可能导致统计的数据有误差。 ​实际使用中，在处理高并发时，可以优先使用LongAdder，而不是继续使用AtomicLong，当然，在线程竞争很低的情况下，使用AtomicLong更简单更实际一些，并且效率会高些。其他情况下，比如序列号生成，这种情况下需要准确的数值，全局唯一的AtomicLong才是正确的选择，而不是LongAdder AtomicReference1The AtomicReference class provides reference objects that may be read and written atomically, so when multiple threads try to reach them at the same time, only one will be able to do so 原子性引用123456789101112131415@Slf4j@ThreadSafepublic class AtomicExample4 &#123; private static AtomicReference&lt;Integer&gt; count = new AtomicReference&lt;&gt;(0); public static void main(String[] args) &#123; count.compareAndSet(0, 2); // 2 count.compareAndSet(0, 1); // no count.compareAndSet(1, 3); // no count.compareAndSet(2, 4); // 4 count.compareAndSet(3, 5); // no log.info(&quot;count:&#123;&#125;&quot;, count.get()); &#125;&#125; 以上实例比较简单，我有个疑问？假如我们引用的是一个自定义的对象，并且对象里面有属性值，然后，修改对象中的属性值也是原子性的吗？还是只是对对象的引用是原子性操作。带着上面的疑问，进行源码分析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class AtomicReference&lt;V&gt; implements java.io.Serializable &#123; private static final long serialVersionUID = -1848883965231344442L; private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long valueOffset; static &#123; try &#123; valueOffset = unsafe.objectFieldOffset (AtomicReference.class.getDeclaredField(&quot;value&quot;)); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125; &#125; private volatile V value; /** * Creates a new AtomicReference with the given initial value. * * @param initialValue the initial value */ public AtomicReference(V initialValue) &#123; value = initialValue; &#125; /** * Creates a new AtomicReference with null initial value. */ public AtomicReference() &#123; &#125; /** * 不需要安全防护 */ public final V get() &#123; return value; &#125; /** * 设值值不需要进行对象安全防护 */ public final void set(V newValue) &#123; value = newValue; &#125; /** * 很明显调用的是csa操作 * 比较对象是否相同，进行设值 * 设值成功返回true，否则返回false */ public final boolean compareAndSet(V expect, V update) &#123; return unsafe.compareAndSwapObject(this, valueOffset, expect, update); &#125; /** * 设置新的值并且返回旧的值 * 原子操作 */ @SuppressWarnings(&quot;unchecked&quot;) public final V getAndSet(V newValue) &#123; return (V)unsafe.getAndSetObject(this, valueOffset, newValue); &#125;&#125; 通过源码分析，可以得出 AtomicReference 所提供的某些方法可以进行原子性操作，如compareAndSet、getAndSet，这仅仅是对引用进行原子性操作 AtomicReference 不能保证对象中若存在属性值修改是线程安全的，如假设引用对象是person，修改person中name和age，多个线程同时从引用中获得对象，并进行修改，会出现线程不安全情况。下面我们通过代码来验证一下这条结论。 1234567891011121314151617181920212223242526272829303132333435363738394041424344@Slf4j@NotThreadSafepublic class AtomicReferenceTest &#123; // 请求总数 public static int clientTotal = 1000; // 同时并发执行的线程数 public static int threadTotal = 500; public static Person person = new Person(0,0); public static AtomicReference&lt;Person&gt; personAtomicReference = new AtomicReference(person); public static void main(String[] args) throws Exception &#123; ExecutorService executorService = Executors.newCachedThreadPool(); final Semaphore semaphore = new Semaphore(threadTotal); final CountDownLatch countDownLatch = new CountDownLatch(clientTotal); for (int i = 0; i &lt; clientTotal ; i++) &#123; final int result = i; executorService.execute(() -&gt; &#123; try &#123; semaphore.acquire(); modify(result); semaphore.release(); &#125; catch (Exception e) &#123; log.error(&quot;exception&quot;, e); &#125; countDownLatch.countDown(); &#125;); &#125; countDownLatch.await(); executorService.shutdown(); log.info(&quot;name:&#123;&#125;,age:&#123;&#125;&quot;,personAtomicReference.get().getName(), personAtomicReference.get().getAge()); &#125; //如果线程安全的话，age的值和name的值是一致的 //如果线程不安全的话，age的值和name是不一样的。 private static void modify(int i) &#123; personAtomicReference.get().setAge(personAtomicReference.get().getAge() + i); personAtomicReference.get().setName(personAtomicReference.get().getName() + i); &#125;&#125; 在低并发的情况下，输出的结果是正确的，但是在高并发的情况下结果差距就很大了118:09:52.473 [main] INFO com.mmall.concurrency.example.atomic.AtomicReferenceTest - name:496592,age:496922 AtomicReferenceFieldUpdateratomic包中提供AtomicReferenceFieldUpdater、AtomicIntegerFieldUpdater、AtomicLongFieldUpdater，原子性的更新某一个类实例的指定的某一个字段 AtomicIntegerFieldUpdater123456789101112131415161718192021222324252627@Slf4j@ThreadSafepublic class AtomicExample5 &#123; //AtomicIntegerFieldUpdater 原子性的更新某一个类的实例的指定的某一个字段 //并且该字段由volatile进行修饰同时不能被static修饰 //有些网上说而且不能被private修饰？下文将进行验证 private static AtomicIntegerFieldUpdater&lt;AtomicExample5&gt; updater = AtomicIntegerFieldUpdater.newUpdater(AtomicExample5.class, "count"); @Getter public volatile int count = 100; public static void main(String[] args) &#123; AtomicExample5 example5 = new AtomicExample5(); if (updater.compareAndSet(example5, 100, 120)) &#123; log.info("update success 1, &#123;&#125;", example5.getCount()); &#125; if (updater.compareAndSet(example5, 100, 120)) &#123; log.info("update success 2, &#123;&#125;", example5.getCount()); &#125; else &#123; log.info("update failed, &#123;&#125;", example5.getCount()); &#125; &#125;&#125; 结果输出1218:48:27.815 [main] INFO com.mmall.concurrency.example.atomic.AtomicExample5 - update success 1, 12018:48:27.825 [main] INFO com.mmall.concurrency.example.atomic.AtomicExample5 - update failed, 120 源码分析12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576public abstract class AtomicIntegerFieldUpdater&lt;T&gt; &#123; /** * * @param tclass 持有某字段的类 * @param fieldName 字段名字 */ @CallerSensitive public static &lt;U&gt; AtomicIntegerFieldUpdater&lt;U&gt; newUpdater(Class&lt;U&gt; tclass, String fieldName) &#123; return new AtomicIntegerFieldUpdaterImpl&lt;U&gt; (tclass, fieldName, Reflection.getCallerClass()); &#125; /** * 原子性设置 */ public int getAndSet(T obj, int newValue) &#123; int prev; do &#123; prev = get(obj); &#125; while (!compareAndSet(obj, prev, newValue)); return prev; &#125; private static class AtomicIntegerFieldUpdaterImpl&lt;T&gt; extends AtomicIntegerFieldUpdater&lt;T&gt; &#123; private static final Unsafe unsafe = Unsafe.getUnsafe(); private final long offset; private final Class&lt;T&gt; tclass; private final Class&lt;?&gt; cclass; AtomicIntegerFieldUpdaterImpl(final Class&lt;T&gt; tclass, final String fieldName, final Class&lt;?&gt; caller) &#123; final Field field; final int modifiers; try &#123; field = AccessController.doPrivileged( new PrivilegedExceptionAction&lt;Field&gt;() &#123; public Field run() throws NoSuchFieldException &#123; //字段不存在会抛异常 return tclass.getDeclaredField(fieldName); &#125; &#125;); //检查访问级别 modifiers = field.getModifiers(); sun.reflect.misc.ReflectUtil.ensureMemberAccess( caller, tclass, null, modifiers); ClassLoader cl = tclass.getClassLoader(); ClassLoader ccl = caller.getClassLoader(); if ((ccl != null) &amp;&amp; (ccl != cl) &amp;&amp; ((cl == null) || !isAncestor(cl, ccl))) &#123; sun.reflect.misc.ReflectUtil.checkPackageAccess(tclass); &#125; &#125; catch (PrivilegedActionException pae) &#123; throw new RuntimeException(pae.getException()); &#125; catch (Exception ex) &#123; throw new RuntimeException(ex); &#125; Class&lt;?&gt; fieldt = field.getType(); //必须是int if (fieldt != int.class) throw new IllegalArgumentException("Must be integer type"); //必须用volatile修饰 if (!Modifier.isVolatile(modifiers)) throw new IllegalArgumentException("Must be volatile type"); this.cclass = (Modifier.isProtected(modifiers) &amp;&amp; caller != tclass) ? caller : null; this.tclass = tclass; //用Unsafe里的那一坨方法去原子更新 offset = unsafe.objectFieldOffset(field); &#125; &#125;&#125; 从源码分析中，可以看出没有要求不能被private修饰 AtomicStampReference 此类是要核心解决CAS的ABA问题 ​ ABA问题：指CAS操作的时候，线程将某个变量值由A修改为B，但是又改回了A，其他线程发现A并未改变，于是CAS将进行值交换操作，实际上该值已经被改变过，这与CAS的核心思想是不符合的 ​ 解决思路：每次变量更新的时候，把变量的版本号进行更新，如果某变量被某个线程修改过，那么版本号一定会递增更新，从而解决ABA问题 ​ J.U.C 提供了两个类解决ABA问题，一个是AtomicStampReference ，另一个是 AtomicMarkableReference AtomicLongArray AtomicLong是作用是对长整形进行原子操作。而AtomicLongArray的作用则是对”长整形数组”进行原子操作,根据索引，对数据中的指定位置的数据进行院子性的更新 AtomicBoolean 12345678910111213141516171819202122232425262728293031323334353637383940414243@Slf4j@ThreadSafepublic class AtomicExample6 &#123; private static AtomicBoolean isHappened = new AtomicBoolean(false); // 请求总数 public static int clientTotal = 5000; // 同时并发执行的线程数 public static int threadTotal = 200; public static void main(String[] args) throws Exception &#123; ExecutorService executorService = Executors.newCachedThreadPool(); final Semaphore semaphore = new Semaphore(threadTotal); final CountDownLatch countDownLatch = new CountDownLatch(clientTotal); for (int i = 0; i &lt; clientTotal ; i++) &#123; executorService.execute(() -&gt; &#123; try &#123; semaphore.acquire(); test(); semaphore.release(); &#125; catch (Exception e) &#123; log.error("exception", e); &#125; countDownLatch.countDown(); &#125;); &#125; countDownLatch.await(); executorService.shutdown(); log.info("isHappened:&#123;&#125;", isHappened.get()); &#125; /* * 演示如何让一段代码中的某个逻辑在高并发场景下只执行一次 */ private static void test() &#123; //原子性操作，保证从false 到 true 只会执行一次 if (isHappened.compareAndSet(false, true)) &#123; log.info("execute"); //只会执行一次 &#125; &#125;&#125; 锁JAVA中能保证同一时刻，只有一个线程来进行对其进行操作的，除了atomic包中所提供的类之外，还有jdk提供的锁，JAVA主要提供以下锁： synchronized : 关键字，并且依赖与JVM，作用对象的作用范围内都是同一时刻只能有一个线程对其操作的 Lock : 接口类，依赖特殊的CPU指定，使用代码实现，常用子类ReentrantLock synchronized 修饰代码块：大括号括起来的代码，也称同步代码块，作用与调用的对象 修饰方法：整个方法，也称同步方法，作用与调用的对象 修饰静态方法：整个静态方法，作用于类的所有对象 修饰类：括号括起来的部分，作用与类的所有对象 同步代码块与同步方法演示与解析123456789101112131415161718192021222324252627282930313233@Slf4jpublic class SynchronizedExample1 &#123; // 修饰一个代码块 public void test1(int j) &#123; //同步代码块 作用于调用的对象 synchronized (this) &#123; for (int i = 0; i &lt; 10; i++) &#123; log.info("test1 &#123;&#125; - &#123;&#125;", j, i); &#125; &#125; &#125; // 修饰一个方法 同步方法 作用于调用的对象 public synchronized void test2(int j) &#123; for (int i = 0; i &lt; 10; i++) &#123; log.info("test2 &#123;&#125; - &#123;&#125;", j, i); &#125; &#125; public static void main(String[] args) &#123; SynchronizedExample1 example1 = new SynchronizedExample1(); SynchronizedExample1 example2 = new SynchronizedExample1(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; &#123; example1.test2(1); &#125;); executorService.execute(() -&gt; &#123; //example1.test2(1) example2.test2(2); &#125;); &#125;&#125; 若线程池中开启两个线程： 使用同步方法进行验证： ​ 若两个线程中都使用同一个对象进行操作，那么他们是同步的,输出的结果都是先执行test2-1 0-9的输出后执行test2-2 0-9的输出或先执行test2-2 0-9的输出后执行test2-1 0-9的输出 1234567executorService.execute(() -&gt; &#123; example1.test2(1);&#125;);executorService.execute(() -&gt; &#123; example1.test2(2) //example2.test2(2);&#125;); 若两个线程中不使用同一个对象进行操作，那么他们输出即为交叉执行1234567executorService.execute(() -&gt; &#123; example1.test2(1);&#125;);executorService.execute(() -&gt; &#123; //example1.test2(2) example2.test2(2);&#125;); 注意：如果某个类为父类，并且存在同步方法，子类在继承这个类后，如果子类调用该父类的同步方法后，该方法是没有synchronized关键字的，原因是synchronized不属于方法声明的一部分 修饰静态方法与修饰类演示与解析 12345678910111213141516171819202122232425262728293031323334@Slf4j//作用于类的所有对象public class SynchronizedExample2 &#123; // 修饰一个类 public static void test1(int j) &#123; synchronized (SynchronizedExample2.class) &#123; for (int i = 0; i &lt; 10; i++) &#123; log.info("test1 &#123;&#125; - &#123;&#125;", j, i); &#125; &#125; &#125; // 修饰一个静态方法 public static synchronized void test2(int j) &#123; for (int i = 0; i &lt; 10; i++) &#123; log.info("test2 &#123;&#125; - &#123;&#125;", j, i); &#125; &#125; public static void main(String[] args) &#123; SynchronizedExample2 example1 = new SynchronizedExample2(); SynchronizedExample2 example2 = new SynchronizedExample2(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; &#123; example1.test1(1); //example1.test2(1); &#125;); executorService.execute(() -&gt; &#123; example2.test1(2); //example2.test2(2); &#125;); &#125;&#125; 从上面类的执行结果，同一个类的不同对象执行同步修饰的方法，执行的顺序是同步的 对比 synchronized ：不可中断锁，适合竞争不激烈，可读性较好 Lock：可中断锁，多样化同步，竞争激烈时能维持常态 Atomic：竞争激烈时能维持常态，比Lock性能好；只能同步一个值 可见性一个线程对主内存的修改可以及时的被其他线程观察到。导致共享变量在线程间不可见的原因： 线程交叉执行 重排序结合线程交叉执行 共享变量更新后的值没有在工作内存与主存间及时更新 对于可见性，JVM提供了 synchronized 和 volatile synchronized JMM关于synchronized的两条规定： 线程解锁前，必须把共享变量的最新值刷新到主内存 线程加锁时，将清空工作内存中共享变量的值，从而使用共享变量时需要从主内存中重新读取最新的值（注意：加锁与解锁是同一把锁） volatileIntroduction通过加入内存屏障和禁止重排序优化来实现 对volatile变量写操作时，会在写操作后加入一条store屏障指令，将本地内存中的共享变量值刷新到主内存中 对volatile变量读操作是，会在读操作前加入一条load屏障指令，从主内存中读取共享变量 通过上面两点，任何时候，不同的线程总能看到该变量的最新值。所有的指令操作都是CPU级别的 Verification1234567891011121314151617181920212223242526272829303132333435363738@Slf4j@NotThreadSafepublic class CountExample4 &#123; // 请求总数 public static int clientTotal = 5000; // 同时并发执行的线程数 public static int threadTotal = 200; public static volatile int count = 0; public static void main(String[] args) throws Exception &#123; ExecutorService executorService = Executors.newCachedThreadPool(); final Semaphore semaphore = new Semaphore(threadTotal); final CountDownLatch countDownLatch = new CountDownLatch(clientTotal); for (int i = 0; i &lt; clientTotal ; i++) &#123; executorService.execute(() -&gt; &#123; try &#123; semaphore.acquire(); add(); semaphore.release(); &#125; catch (Exception e) &#123; log.error("exception", e); &#125; countDownLatch.countDown(); &#125;); &#125; countDownLatch.await(); executorService.shutdown(); log.info("count:&#123;&#125;", count); &#125; //输出结果是线程不安全的。 private static void add() &#123; count++; &#125;&#125; 通过例子可以得知，即使通过volatile修饰变量，但依然无法保证线程安全 原因分析：123456private static void add() &#123; count++; //分3步 //1.取出当前count值 //2.count + 1 //3.count 重新写回主存&#125; 假设同时有两个线程进行操作，两个线程同时执行到第一步（从内存中读取最新值）得到一样的最新的结果，然后进入第二步（+1操作）并进行第三步（从新写回主存）。尽管第一步获取的值是一样的，但是同时将+1后的操作写回主存，这样就会丢掉某个+1的操作，这样就会出现线程不安全问题结论： volatile进行加操作线程不安全的，不适合计数场景 volatile关键字不具有原子性 使用场景 使用volatile必须具备两个条件 对变量的写操作，不依赖于当前值 该变量没有包含在具有其他变量的不变式子中 因此volatile适合作为状态的标记量 1234567891011volatile boolean inited = false;//线程1context = loadContext();inited = true;//线程2while(!inited)&#123; sleep();&#125;doSomethingWithConfig(context); 有序性JAVA内存模型中，允许编译器和处理器对指令进行重排序，但是重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性 volatile、synchronized、Lock：通过 volatile、synchronized、Lock 保证一定的有序性。显然，synchronized、Lock 保证每一个时刻只有一个线程可以执行被同步的代码，相当于让线程顺序执行同步代码，从而保证有序性。另外，JMM具备一些先天的有序性，即不需要额外的手段，就能保证有序性，即 Happens-before 原则，如果两个操作的执行次序，没有办法通过 Happens-before 原则推到出来，虚拟机进行随意的重排序，那么就不能保证有序行。 happens-before 程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作 (个人理解：一段程序代码的执行，在单个线程中看起来是有序的，程序看起来的执行是按照代码的顺序执行的，因为虚拟机可能会对指令进行重排序，虽然进行了重排序，但是最终结果是与程序顺序执行的结果是一致的，只会对不存在数据依赖的指令进行重排序，因此在单个线程中是有序执行的。这条规则是保证程序在单线程中执行结果的正确性，但无法保证多线程执行结果的正确性) 锁定规则：一个unLock操作先行发生于后面对同一个锁额lock操作； volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作； 传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C； 线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作； 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生； 线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行； 对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始； 安全发布对象安全发布对象的四种方法： 在静态初始化函数中初始化一个对象引用 将对象的引用保存到volatile类型域或者AtomicReference对象中 将对象的引用保存到某个正确构造对象的final类型域中 将对象的引用保存到一个由锁保护的域中 案例分析 Spring 框架中，Spring管理的类都是单例模式。如何保证一个实例只被初始化一次，且线程安全？通过不同单例的写法，具体描述安全发布对象的四种方法： 普通单例模式1234567891011121314151617181920212223242526/** * 懒汉模式 * 单例实例在第一次使用时进行创建 */@NotThreadSafepublic class SingletonExample1 &#123; // 私有构造函数 private SingletonExample1() &#123; //可能这里会存在很多的操作 //如资源加载、运算等 &#125; // 单例对象 private static SingletonExample1 instance = null; // 静态的工厂方法 // 单线毫无问题 public static SingletonExample1 getInstance() &#123; //多线程环境下存在线程安全问题 if (instance == null) &#123; instance = new SingletonExample1(); &#125; return instance; &#125;&#125; 1234567891011121314151617181920212223/** * 饿汉模式 * 单例实例在类装载时进行创建 * * 缺点：1.若构造方法中存在过多的处理、会导加载缓慢，从而引起性能问题 * 2.只进行加载，并无实际调用，导致资源浪费 */@ThreadSafepublic class SingletonExample2 &#123; // 私有构造函数 private SingletonExample2() &#123; &#125; // 单例对象 private static SingletonExample2 instance = new SingletonExample2(); // 静态的工厂方法 public static SingletonExample2 getInstance() &#123; return instance; &#125;&#125; 双重检测机制123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * 懒汉模式 -》 双重同步锁单例模式 * 单例实例在第一次使用时进行创建 */@NotThreadSafepublic class SingletonExample4 &#123; // 私有构造函数 private SingletonExample4() &#123; &#125; // 单例对象 private static SingletonExample4 instance = null; // 静态的工厂方法 public static SingletonExample4 getInstance() &#123; if (instance == null) &#123; // 双重检测机制 // B synchronized (SingletonExample4.class) &#123; // 同步锁 if (instance == null) &#123; instance = new SingletonExample4(); // A - 3 &#125; &#125; &#125; return instance; &#125; //这样的双重检测机制是线程不安全的 // 1、memory = allocate() 分配对象的内存空间 // 2、ctorInstance() 初始化对象 // 3、instance = memory 设置instance指向刚分配的内存 //多线程环境下 // JVM和cpu优化，发生了指令重排 // 1、memory = allocate() 分配对象的内存空间 // 3、instance = memory 设置instance指向刚分配的内存 // 2、ctorInstance() 初始化对象 //假设存在线程A、B同时进入双重检测机制 //当线程A执行到 instance = new SingletonExample4(); // A - 执行到指令的第三步进行内存分配，但是未初始化对象 //B执行到 if (instance == null) &#123; // 双重检测机制 //b发现instance不为空，直接返回对象，实上对象初始化并未开始&#125; 静态域初始化1234567891011121314151617181920212223242526272829303132/** * 饿汉模式 * 单例实例在类装载时进行创建 * * 静态域与静态代码块是顺序执行的，若将1 2 处位置进行交换则会出现空指针异常 */@ThreadSafepublic class SingletonExample6 &#123; // 私有构造函数 private SingletonExample6() &#123; &#125; //1. // 单例对象 private static SingletonExample6 instance = null; //2. static &#123; instance = new SingletonExample6(); &#125; // 静态的工厂方法 public static SingletonExample6 getInstance() &#123; return instance; &#125; public static void main(String[] args) &#123; System.out.println(getInstance().hashCode()); System.out.println(getInstance().hashCode()); &#125;&#125; 最安全的枚举模式12345678910111213141516171819202122232425262728293031/** * 枚举模式：最安全 */@ThreadSafe@Recommendpublic class SingletonExample7 &#123; // 私有构造函数 private SingletonExample7() &#123; &#125; public static SingletonExample7 getInstance() &#123; return Singleton.INSTANCE.getInstance(); &#125; private enum Singleton &#123; INSTANCE; private SingletonExample7 singleton; // JVM保证这个方法绝对只调用一次 Singleton() &#123; singleton = new SingletonExample7(); &#125; public SingletonExample7 getInstance() &#123; return singleton; &#125; &#125;&#125; 线程安全策略创建后状态不能被修改的对象叫作不可变对象。不可变对象天生就是线程安全的。它们的常量（变量）是在构造函数中创建的，既然它们的状态无法被修改，那么这些常量永远不会被改变——不可变对象永远是线程安全的。不可变对象需要满足的条件 对象创建以后其状态就不能修改 对象所有域都是final类型 对象是正确创建的（在对象创建期间，this引用没有逸出） finalfinal关键字：类、方法、变量 修饰类：不能被继承，final类中的成员属性可以根据需要设置为final，但final类中所有的成员方法都被隐式指定为final方法。一般不建议将类设置为final类型。可以参考String类。 修饰方法：1）锁定方法不被继承类修改；2）效率 修饰变量：1）基本数据类型变量，初始化后便不能进行修改；2）引用类型变量，初始化之后不能再指向别的引用 12345678910111213141516171819202122232425262728@Slf4j@NotThreadSafepublic class ImmutableExample1 &#123; private final static Integer a = 1; private final static String b = "2"; //引用类型不允许引用指向改变，但是对象值还是可以进行修改的 private final static Map&lt;Integer, Integer&gt; map = Maps.newHashMap(); static &#123; map.put(1, 2); map.put(3, 4); map.put(5, 6); &#125; public static void main(String[] args) &#123;// a = 2; //编译时报错// b = "3"; //编译时报错// map = Maps.newHashMap(); //编译时报错 map.put(1, 3); //容易引发线程安全问题 log.info("&#123;&#125;", map.get(1)); &#125; //可以修饰参数 private void test(final int a) &#123;// a = 1; &#125;&#125; Collectionsjava提供Collections工具类，在类中提供了多种不允许修改的方法 ​ Collections.unmodifiableXXX：Collection、List、Set、Map… 123456789101112131415161718192021Slf4j@ThreadSafepublic class ImmutableExample2 &#123; private static Map&lt;Integer, Integer&gt; map = Maps.newHashMap(); static &#123; map.put(1, 2); map.put(3, 4); map.put(5, 6); //处理过后的map是不可以再进行修改的 map = Collections.unmodifiableMap(map); &#125; public static void main(String[] args) &#123; //允许操作，但是操作会报错，扔出异常 map.put(1, 3); log.info(&quot;&#123;&#125;&quot;, map.get(1)); &#125;&#125; 12345678910111213141516public class Collections &#123; public static &lt;K,V&gt; Map&lt;K,V&gt; unmodifiableMap(Map&lt;? extends K, ? extends V&gt; m) &#123; return new UnmodifiableMap&lt;&gt;(m); &#125; private static class UnmodifiableMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Serializable &#123; @Override public boolean remove(Object key, Object value) &#123; throw new UnsupportedOperationException(); &#125; @Override public boolean replace(K key, V oldValue, V newValue) &#123; throw new UnsupportedOperationException(); &#125; &#125;&#125; Guava​ 谷歌的Guava提供类似Java中的Collections ​ ImmutableXXX：Collection、List、Set、Map… pom.xml 12345&lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;23.0&lt;/version&gt;&lt;/dependency&gt; 123456789101112131415161718@ThreadSafepublic class ImmutableExample3 &#123; private final static ImmutableList&lt;Integer&gt; list = ImmutableList.of(1, 2, 3); private final static List&lt;Integer&gt; lists = ImmutableList.of(1, 2, 3); private final static ImmutableSet set = ImmutableSet.copyOf(list); private final static ImmutableMap&lt;Integer, Integer&gt; map = ImmutableMap.of(1, 2, 3, 4); private final static ImmutableMap&lt;Integer, Integer&gt; map2 = ImmutableMap.&lt;Integer, Integer&gt;builder() .put(1, 2).put(3, 4).put(5, 6).build(); public static void main(String[] args) &#123; System.out.println(map2.get(3)); &#125;&#125; 1来源：https://www.jianshu.com/p/895950290179]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java并发系统学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CPU缓存一致性协议MESI]]></title>
    <url>%2F2019%2F05%2F23%2FCPU%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7%E5%8D%8F%E8%AE%AEMESI%2F</url>
    <content type="text"><![CDATA[CPU高速缓存（Cache Memory）CPU为何要有高速缓存CPU在摩尔定律的指导下以每18个月翻一番的速度在发展，然而内存和硬盘的发展速度远远不及CPU。这就造成了高性能能的内存和硬盘价格及其昂贵。然而CPU的高度运算需要高速的数据。为了解决这个问题，CPU厂商在CPU中内置了少量的高速缓存以解决I\O速度和CPU运算速度之间的不匹配问题。 在CPU访问存储设备时，无论是存取数据抑或存取指令，都趋于聚集在一片连续的区域中，这就被称为局部性原理。 1时间局部性（Temporal Locality）：如果一个信息项正在被访问，那么在近期它很可能还会被再次访问。 比如循环、递归、方法的反复调用等。 1空间局部性（Spatial Locality）：如果一个存储器的位置被引用，那么将来他附近的位置也会被引用。 比如顺序执行的代码、连续创建的两个对象、数组等。 带有高速缓存的CPU执行计算的流程 程序以及数据被加载到主内存 指令和数据被加载到CPU的高速缓存 CPU执行指令，把结果写到高速缓存 高速缓存中的数据写回主内存 目前流行的多级缓存结构由于CPU的运算速度超越了1级缓存的数据I\O能力，CPU厂商又引入了多级的缓存结构。 多级缓存结构 多核CPU多级缓存一致性协议MESI多核CPU的情况下有多个一级缓存，如何保证缓存内部数据的一致,不让系统数据混乱。这里就引出了一个一致性的协议MESI。 MESI协议缓存状态MESI 是指4中状态的首字母。每个Cache line有4个状态，可用2个bit表示，它们分别是： 1缓存行（Cache line）:缓存存储数据的单元。 注意： 对于M和E状态而言总是精确的，他们在和该缓存行的真正状态是一致的，而S状态可能是非一致的。如果一个缓存将处于S状态的缓存行作废了，而另一个缓存实际上可能已经独享了该缓存行，但是该缓存却不会将该缓存行升迁为E状态，这是因为其它缓存不会广播他们作废掉该缓存行的通知，同样由于缓存并没有保存该缓存行的copy的数量，因此（即使有这种通知）也没有办法确定自己是否已经独享了该缓存行。 从上面的意义看来E状态是一种投机性的优化：如果一个CPU想修改一个处于S状态的缓存行，总线事务需要将所有该缓存行的copy变成invalid状态，而修改E状态的缓存不需要使用总线事务。 MESI状态转换 理解该图的前置说明：1.触发事件 触发事件描述本地读取（Local read）本地cache读取本地cache数据本地写入（Local write）本地cache写入本地cache数据远端读取（Remote read）其他cache读取本地cache数据远端写入（Remote write）其他cache写入本地cache数据 2.cache分类：前提：所有的cache共同缓存了主内存中的某一条数据。 本地cache:指当前cpu的cache。触发cache:触发读写事件的cache。其他cache:指既除了以上两种之外的cache。注意：本地的事件触发 本地cache和触发cache为相同。 上图的切换解释： 状态触发本地读取触发本地写入触发远端读取触发远端写入M状态（修改）本地cache:M 触发cache:M其他cache:I本地cache:M 触发cache:M其他cache:I本地cache:M→E→S触发cache:I→S其他cache:I→S同步主内存后修改为E独享,同步触发、其他cache后本地、触发、其他cache修改为S共享本地cache:M→E→S→I触发cache:I→S→E→M其他cache:I→S→I同步和读取一样,同步完成后触发cache改为M，本地、其他cache改为IE状态（独享）本地cache:E触发cache:E其他cache:I本地cache:E→M触发cache:E→M其他cache:I本地cache变更为M,其他cache状态应当是I（无效）本地cache:E→S触发cache:I→S其他cache:I→S当其他cache要读取该数据时，其他、触发、本地cache都被设置为S(共享)本地cache:E→S→I触发cache:I→S→E→M其他cache:I→S→I当触发cache修改本地cache独享数据时时，将本地、触发、其他cache修改为S共享.然后触发cache修改为独享，其他、本地cache修改为I（无效），触发cache再修改为MS状态(共享)本地cache:S触发cache:S其他cache:S本地cache:S→E→M触发cache:S→E→M其他cache:S→I 当本地cache修改时，将本地cache修改为E,其他cache修改为I,然后再将本地cache为M状态本地cache:S触发cache:S其他cache:S本地cache:S→I触发cache：S→E→M其他cache:S→I当触发cache要修改本地共享数据时，触发cache修改为E（独享）,本地、其他cache修改为I（无效）,触发cache再次修改为M(修改)I状态（无效）本地cache:I→S或者I→E触发cache:I→S或者I →E其他cache:E、M、I→S、I本地、触发cache将从I无效修改为S共享或者E独享，其他cache将从E、M、I 变为S或者I本地cache:I→S→E→M触发cache:I→S→E→M其他cache:M、E、S→S→I既然是本cache是I，其他cache操作与它无关既然是本cache是I，其他cache操作与它无关 下图示意了，当一个cache line的调整的状态的时候，另外一个cache line 需要调整的状态。 MESIM×××√E×××√S××√√I√√√√ 举个栗子来说： 假设cache 1 中有一个变量x = 0的cache line 处于S状态(共享)。那么其他拥有x变量的cache 2、cache 3等x的cache line调整为S状态（共享）或者调整为 I 状态（无效）。 多核缓存协同操作假设有三个CPU A、B、C，对应三个缓存分别是cache a、b、 c。在主内存中定义了x的引用值为0。 单核读取那么执行流程是：CPU A发出了一条指令，从主内存中读取x。从主内存通过bus读取到缓存中（远端读取Remote read）,这是该Cache line修改为E状态（独享）. 双核读取那么执行流程是：CPU A发出了一条指令，从主内存中读取x。CPU A从主内存通过bus读取到 cache a中并将该cache line 设置为E状态。CPU B发出了一条指令，从主内存中读取x。CPU B试图从主内存中读取x时，CPU A检测到了地址冲突。这时CPU A对相关数据做出响应。此时x 存储于cache a和cache b中，x在chche a和cache b中都被设置为S状态(共享)。 修改数据那么执行流程是：CPU A 计算完成后发指令需要修改x.CPU A 将x设置为M状态（修改）并通知缓存了x的CPU B, CPU B将本地cache b中的x设置为I状态(无效)CPU A 对x进行赋值。 同步数据那么执行流程是： CPU B 发出了要读取x的指令。CPU B 通知CPU A,CPU A将修改后的数据同步到主内存时cache a 修改为E（独享）CPU A同步CPU B的x,将cache a和同步后cache b中的x设置为S状态（共享）。 MESI优化和他们引入的问题缓存的一致性消息传递是要时间的，这就使其切换时会产生延迟。当一个缓存被切换状态时其他缓存收到消息完成各自的切换并且发出回应消息这么一长串的时间中CPU都会等待所有缓存响应完成。可能出现的阻塞都会导致各种各样的性能问题和稳定性问题。 CPU切换状态阻塞解决-存储缓存（Store Bufferes）比如你需要修改本地缓存中的一条信息，那么你必须将I（无效）状态通知到其他拥有该缓存数据的CPU缓存中，并且等待确认。等待确认的过程会阻塞处理器，这会降低处理器的性能。应为这个等待远远比一个指令的执行时间长的多。 Store Bufferes为了避免这种CPU运算能力的浪费，Store Bufferes被引入使用。处理器把它想要写入到主存的值写到缓存，然后继续去处理其他事情。当所有失效确认（Invalidate Acknowledge）都接收到时，数据才会最终被提交。这么做有两个风险 Store Bufferes的风险第一、就是处理器会尝试从存储缓存（Store buffer）中读取值，但它还没有进行提交。这个的解决方案称为Store Forwarding，它使得加载的时候，如果存储缓存中存在，则进行返回。第二、保存什么时候会完成，这个并没有任何保证。 123456789101112value = 3；void exeToCPUA()&#123; value = 10; isFinsh = true;&#125;void exeToCPUB()&#123; if(isFinsh)&#123; //value一定等于10？！ assert value == 10; &#125;&#125; 试想一下开始执行时，CPU A保存着finished在E(独享)状态，而value并没有保存在它的缓存中。（例如，Invalid）。在这种情况下，value会比finished更迟地抛弃存储缓存。完全有可能CPU B读取finished的值为true，而value的值不等于10。 即isFinsh的赋值在value赋值之前。 这种在可识别的行为中发生的变化称为重排序（reordings）。注意，这不意味着你的指令的位置被恶意（或者好意）地更改。 它只是意味着其他的CPU会读到跟程序中写入的顺序不一样的结果。 顺便提一下NIO的设计和Store Bufferes的设计是非常相像的。 硬件内存模型执行失效也不是一个简单的操作，它需要处理器去处理。另外，存储缓存（Store Buffers）并不是无穷大的，所以处理器有时需要等待失效确认的返回。这两个操作都会使得性能大幅降低。为了应付这种情况，引入了失效队列。它们的约定如下： 对于所有的收到的Invalidate请求，Invalidate Acknowlege消息必须立刻发送 Invalidate并不真正执行，而是被放在一个特殊的队列中，在方便的时候才会去执行。 处理器不会发送任何消息给所处理的缓存条目，直到它处理Invalidate。 即便是这样处理器已然不知道什么时候优化是允许的，而什么时候并不允许。干脆处理器将这个任务丢给了写代码的人。这就是内存屏障（Memory Barriers）。 写屏障 Store Memory Barrier(a.k.a. ST, SMB, smp_wmb)是一条告诉处理器在执行这之后的指令之前，应用所有已经在存储缓存（store buffer）中的保存的指令。 1读屏障Load Memory Barrier (a.k.a. LD, RMB, smp_rmb)是一条告诉处理器在执行任何的加载前，先应用所有已经在失效队列中的失效操作的指令。 123456789101112void executedOnCpu0() &#123; value = 10; //在更新数据之前必须将所有存储缓存（store buffer）中的指令执行完毕。 storeMemoryBarrier(); finished = true;&#125;void executedOnCpu1() &#123; while(!finished); //在读取之前将所有失效队列中关于该数据的指令执行完毕。 loadMemoryBarrier(); assert value == 10;&#125; 现在确实安全了。完美无暇！ 后记然而，对于程序员来说简直是一个灾难。不想和平台耦合我们要跨平台。Write One,Run Everywhere!幸好java解决了这个问题，至于如何解决的请关注JMM(JavaMemoryMode)与物理内存相爱相杀。 1来源： https://www.cnblogs.com/yanlong300/p/8986041.html]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java并发系统学习番外篇</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[内存屏障]]></title>
    <url>%2F2019%2F05%2F23%2F%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C%2F</url>
    <content type="text"><![CDATA[为什么会有内存屏障 每个CPU都会有自己的缓存（有的甚至L1,L2,L3），缓存的目的就是为了提高性能，避免每次都要向内存取。但是这样的弊端也很明显：不能实时的和内存发生信息交换，分在不同CPU执行的不同线程对同一个变量的缓存值不同。 用volatile关键字修饰变量可以解决上述问题，那么volatile是如何做到这一点的呢？那就是内存屏障，内存屏障是硬件层的概念，不同的硬件平台实现内存屏障的手段并不是一样，java通过屏蔽这些差异，统一由jvm来生成内存屏障的指令。 内存屏障是什么 硬件层的内存屏障分为两种：Load Barrier 和 Store Barrier即读屏障和写屏障。 内存屏障有两个作用： 12阻止屏障两侧的指令重排序；强制把写缓冲区/高速缓存中的脏数据等写回主内存，让缓存中相应的数据失效。 对于Load Barrier来说，在指令前插入Load Barrier，可以让高速缓存中的数据失效，强制从新从主内存加载数据； 对于Store Barrier来说，在指令后插入Store Barrier，能让写入缓存中的最新数据更新写入主内存，让其他线程可见。 java内存屏障 java的内存屏障通常所谓的四种即LoadLoad,StoreStore,LoadStore,StoreLoad实际上也是上述两种的组合，完成一系列的屏障和数据同步功能。 LoadLoad屏障：对于这样的语句Load1; LoadLoad; Load2，在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。 StoreStore屏障：对于这样的语句Store1; StoreStore; Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。 LoadStore屏障：对于这样的语句Load1; LoadStore; Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。 StoreLoad屏障：对于这样的语句Store1; StoreLoad; Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。 它的开销是四种屏障中最大的。在大多数处理器的实现中，这个屏障是个万能屏障，兼具其它三种内存屏障的功能 volatile语义中的内存屏障 volatile的内存屏障策略非常严格保守，非常悲观且毫无安全感的心态： 12这里是列表文本在每个volatile写操作前插入StoreStore屏障，在写操作后插入StoreLoad屏障；在每个volatile读操作前插入LoadLoad屏障，在读操作后插入LoadStore屏障； 由于内存屏障的作用，避免了volatile变量和其它指令重排序、线程之间实现了通信，使得volatile表现出了锁的特性。 final语义中的内存屏障 对于final域，编译器和CPU会遵循两个排序规则： 12新建对象过程中，构造体中对final域的初始化写入和这个对象赋值给其他引用变量，这两个操作不能重排序；（废话嘛）初次读包含final域的对象引用和读取这个final域，这两个操作不能重排序；（晦涩，意思就是先赋值引用，再调用final值） 总之上面规则的意思可以这样理解，必需保证一个对象的所有final域被写入完毕后才能引用和读取。这也是内存屏障的起的作用： 写final域：在编译器写final域完毕，构造体结束之前，会插入一个StoreStore屏障，保证前面的对final写入对其他线程/CPU可见，并阻止重排序。 读final域：在上述规则2中，两步操作不能重排序的机理就是在读final域前插入了LoadLoad屏障。 X86处理器中，由于CPU不会对写-写操作进行重排序，所以StoreStore屏障会被省略；而X86也不会对逻辑上有先后依赖关系的操作进行重排序，所以LoadLoad也会变省略。 1原文链接：https://www.jianshu.com/p/2ab5e3d7e510]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java并发系统学习番外篇</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LongAdder解析]]></title>
    <url>%2F2019%2F05%2F23%2FLongAdder%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[LongAdder解析 1摘要： 对`LongAdder`的最初了解是从Coolshell上的一篇文章中获得的，但是一直都没有深入的了解过其实现，只知道它相较于`AtomicLong`来说，更加适合写多读少的并发情景。今天，我们就研究一下`LongAdder`的原理，探究一下它如此高效的原因。 对LongAdder的最初了解是从Coolshell上的一篇文章中获得的，但是一直都没有深入的了解过其实现，只知道它相较于AtomicLong来说，更加适合写多读少的并发情景。今天，我们就研究一下LongAdder的原理，探究一下它如此高效的原因。 基本原理和思想123456789Java有很多并发控制机制，比如说以AQS为基础的锁或者以CAS为原理的自旋锁。不了解AQS的朋友可以阅读我之前的AQS源码解析文章。一般来说，CAS适合轻量级的并发操作，也就是并发量并不多，而且等待时间不长的情况，否则就应该使用普通锁，进入阻塞状态，避免CPU空转。 所以，如果你有一个Long类型的值会被多线程修改，那么使用CAS进行并发控制比较好，但是如果你是需要锁住一些资源，然后进行数据库操作，那么还是使用阻塞锁比较好。 第一种情况下，我们一般都使用AtomicLong。AtomicLong是通过无限循环不停的采取CAS的方法去设置内部的value，直到成功为止。那么当并发数比较多或出现更新热点时，就会导致CAS的失败机率变高，重试次数更多，越多的线程重试，CAS失败的机率越高，形成恶性循环，从而降低了效率。 而LongAdder的原理就是降低对value更新的并发数，也就是将对单一value的变更压力分散到多个value值上，降低单个value的“热度”。 我们知道LongAdder的大致原理之后，再来详细的了解一下它的具体实现，其中也有很多值得借鉴的并发编程的技巧。 LongAdder的成员变量LongAdder是Striped64 的子类，其有三个比较重要的成员函数，在之后的函数分析中需要使用到，这里先说明一下。 12345678// CPU的数量static final int NCPU = Runtime.getRuntime().availableProcessors();// Cell对象的数组，长度一般是2的指数transient volatile Cell[] cells;// 基础value值，当并发较低时，只累加该值transient volatile long base;// 创建或者扩容Cells数组时使用的自旋锁变量transient volatile int cellsBusy; cells是LongAdder的父类Striped64中的Cell数组类型的成员变量。每个Cell对象中都包含一个value值，并提供对这个value值的CAS操作。1234567static final class Cell &#123; volatile long value; Cell(long x) &#123; value = x; &#125; final boolean cas(long cmp, long val) &#123; return UNSAFE.compareAndSwapLong(this, valueOffset, cmp, val); &#125;&#125; Add操作我们首先来看一下LongAdder的add函数，其会多次尝试CAS操作将值进行累加，如果成功了就直接返回，失败则继续执行。代码比较复杂，而且涉及的情况比较多，我们就以梳理历次尝试CAS操作为主线，讲清楚这些CAS操作的前提条件和场景。 1234567891011121314public void add(long x) &#123; Cell[] as; long b, v; int m; Cell a; // 当cells数组为null时，会进行第一次cas操作尝试。 if ((as = cells) != null || !casBase(b = base, b + x)) &#123; boolean uncontended = true; if (as == null || (m = as.length - 1) &lt; 0 || (a = as[getProbe() &amp; m]) == null || !(uncontended = a.cas(v = a.value, v + x))) // 当cells数组不为null，并且通过getProbe() &amp; m // 定位的Cell对象不为null时进行第二次CAS操作。 // 如果执行不成功，则进入longAccumulate函数。 longAccumulate(x, null, uncontended); &#125;&#125; 当并发量较少时，cell数组尚未初始化，所以只调用casBase函数，对base变量进行CAS累加。 我们来看一下casBase函数相关的源码吧。我们可以认为变量base就是第一个value值，也是基础value变量。先调用casBase函数来cas一下base变量，如果成功了，就不需要在进行下面比较复杂的算法， 123final boolean casBase(long cmp, long val) &#123; return UNSAFE.compareAndSwapLong(this, BASE, cmp, val);&#125; 当并发量逐渐提高时，casBase函数会失败。如果cells数组为null或为空,就直接调用longAccumulate方法。因为cells为null或在为空，说明cells未 初始化，所以调用longAccumulate进行初始化。否则继续判断。 如果cells中已经初始化，就继续进行后续判断。我们先来理解一下getProbe() &amp; m的这个操作吧，可以把这个操作当作一次计算”hash”值，然后将cells中这个位置的Cell对象赋值给变量a。如果变量a不为null，那么就调用该对象的cas方法去设置其value值。如果a为null，或在cas赋值发生冲突，那么调用longAccumulate方法。 LongAccumulate方法longAccumulate函数比较复杂，带有我的注释的代码已经贴在了文章后边，这里我们就只讲一下其中比较关键的一些技巧和思想。 首先，我们都知道只有当对base的cas操作失败之后，LongAdder才引入Cell数组．所以在longAccumulate中就是对Cell数组进行操作，分别涉及了数组的初始化，扩容和设置某个位置的Cell对象等操作。 在这段代码中，关于cellBusy的cas操作构成了一个SpinLock，这就是经典的SpinLock的编程技巧，大家可以学习一下。 我们先来看一下longAccumulate的主体代码，首先是一个无限for循环，然后根据cells数组的状态来判断是要进行cells数组的初始化，还是进行对象添加或者扩容。 12345678910111213141516171819202122232425262728final void longAccumulate(long x, LongBinaryOperator fn, boolean wasUncontended) &#123; int h; if ((h = getProbe()) == 0) &#123; //获取PROBE变量，探针变量，与当前运行的线程相关，不同线程不同 ThreadLocalRandom.current(); //初始化PROBE变量，和getProbe都使用Unsafe类提供的原子性操作。 h = getProbe(); wasUncontended = true; &#125; boolean collide = false; for (;;) &#123; //cas经典无限循环，不断尝试 Cell[] as; Cell a; int n; long v; if ((as = cells) != null &amp;&amp; (n = as.length) &gt; 0) &#123; // cells不为null,并且数组size大于0,表示cells已经初始化了 // 初始化Cell对象并设置到数组中或者进行数组扩容 &#125; else if (cellsBusy == 0 &amp;&amp; cells == as &amp;&amp; casCellsBusy()) &#123; //cells数组未初始化，获得cellsBusy lock,进行cells数组的初始化 // cells数组初始化操作 &#125; //如果初始化数组失败了，那就再次尝试一下直接cas base变量， // 如果成功了就直接返回，这是最后一个进行CAS操作的地方。 else if (casBase(v = base, ((fn == null) ? v + x : fn.applyAsLong(v, x)))) break; &#125; &#125; 进行Cell数组代码如下所示，它首先调用casCellsBusy函数获取了cellsBusy‘锁’，然后进行数组的初始化操作，最后将cellBusy’锁’释放掉。 1234567891011121314// 注意在进入这段代码之前已经casCellsBusy获得cellsBusy这个锁变量了。boolean init = false;try &#123; if (cells == as) &#123; Cell[] rs = new Cell[2]; rs[h &amp; 1] = new Cell(x); //设置x的值为cell对象的value值 cells = rs; init = true; &#125;&#125; finally &#123; cellsBusy = 0;&#125;if (init) break; 如果Cell数组已经初始化过了，那么就进行Cell数组的设置或者扩容。这部分代码有一系列的if else的判断，如果前一个条件不成立，才会进入下一条判断。 首先，当Cell数组中对应位置的cell对象为null时，表明该位置的Cell对象需要进行初始化，所以使用casCellsBusy函数获取’锁’，然后初始化Cell对象，并且设置进cells数组，最后释放掉’锁’。 当Cell数组中对应位置的cell对象不为null，则直接调用其cas操作进行累加。 当上述操作都失败后，认为多个线程在对同一个位置的Cell对象进行操作，这个Cell对象是一个“热点”，所以Cell数组需要进行扩容，将热点分散。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758if ((a = as[(n - 1) &amp; h]) == null) &#123; //通过与操作计算出来需要操作的Cell对象的坐标 if (cellsBusy == 0) &#123; //volatile 变量，用来实现spinLock,来在初始化和resize cells数组时使用。 //当cellsBusy为0时，表示当前可以对cells数组进行操作。 Cell r = new Cell(x);//将x值直接赋值给Cell对象 if (cellsBusy == 0 &amp;&amp; casCellsBusy()) &#123;//如果这个时候cellsBusy还是0 //就cas将其设置为非０，如果成功了就是获得了spinLock的锁．可以对cells数组进行操作． //如果失败了，就会再次执行一次循环 boolean created = false; try &#123; Cell[] rs; int m, j; //判断cells是否已经初始化，并且要操作的位置上没有cell对象． if ((rs = cells) != null &amp;&amp; (m = rs.length) &gt; 0 &amp;&amp; rs[j = (m - 1) &amp; h] == null) &#123; rs[j] = r; //将之前创建的值为x的cell对象赋值到cells数组的响应位置． created = true; &#125; &#125; finally &#123; //经典的spinLock编程技巧，先获得锁，然后try finally将锁释放掉 //将cellBusy设置为0就是释放锁． cellsBusy = 0; &#125; if (created) break; //如果创建成功了，就是使用x创建了新的cell对象，也就是新创建了一个分担热点的value continue; &#125; &#125; collide = false; //未发生碰撞&#125;else if (!wasUncontended)//是否已经发生过一次cas操作失败 wasUncontended = true; //设置成true,以便第二次进入下一个else if 判断else if (a.cas(v = a.value, ((fn == null) ? v + x : fn.applyAsLong(v, x)))) //fn是操作类型，如果是空，就是相加，所以让a这个cell对象中的value值和x相加，然后在cas设置，如果成果 //就直接返回 break;else if (n &gt;= NCPU || cells != as) //如果cells数组的大小大于系统的可获得处理器数量或在as不再和cells相等． collide = false;else if (!collide) collide = true;else if (cellsBusy == 0 &amp;&amp; casCellsBusy()) &#123; //再次获得cellsBusy这个spinLock,对数组进行resize try &#123; if (cells == as) &#123;//要再次检测as是否等于cells以免其他线程已经对cells进行了操作． Cell[] rs = new Cell[n &lt;&lt; 1]; //扩容一倍 for (int i = 0; i &lt; n; ++i) rs[i] = as[i]; cells = rs;//赋予cells一个新的数组对象 &#125; &#125; finally &#123; cellsBusy = 0; &#125; collide = false; continue;&#125;h = advanceProbe(h);//由于使用当前探针变量无法操作成功，所以重新设置一个,再次尝试 后记 本篇文章写的不是很好，我写完之后又看了一遍coolshell上的关于LongAdder的文章，感觉自己没有人家写的那么简洁明了。我对代码细节的注释和投入太多了。其实很多代码大家都可以看懂，并不需要大量的代码片段加注释。以后要注意一下。之后会接着研究一下JUC包中的其他类，希望大家多多关注。 1文章来源： https://yq.aliyun.com/articles/688822]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java并发系统学习番外篇</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java并发计数器分析]]></title>
    <url>%2F2019%2F05%2F22%2Fjava%E5%B9%B6%E5%8F%91%E8%AE%A1%E6%95%B0%E5%99%A8%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[前言一提到线程安全的并发计数器，AtomicLong 必然是第一个被联想到的工具。Atomic* 一系列的原子类以及它们背后的 CAS 无锁算法，常常是高性能，高并发的代名词。本文将会阐释，在并发场景下，使用 AtomicLong 来充当并发计数器将会是一个糟糕的设计，实际上存在不少 AtomicLong 之外的计数器方案。近期我研究了一些 Jdk1.8 以及 JCTools 的优化方案，并将它们的对比与实现细节整理于此。 AtomicLong 的前世今生在 Java 中，Atomic* 是高效的，这得益于 sun.misc.Unsafe 提供的一系列底层 API，使得 Java 这样的高级语言能够直接和硬件层面的 CPU 指令打交道。并且在 Jdk1.7 中，这样的底层指令可以配合 CAS 操作，达到 Lock-Free。 在 Jdk1.7 中，AtomicLong 的关键代码如下： 123456789101112public final long getAndIncrement() &#123; while (true) &#123; long current = get(); long next = current + 1; if (compareAndSet(current, next)) return current; &#125;&#125;public final boolean compareAndSet(long expect, long update) &#123; return unsafe.compareAndSwapLong(this, valueOffset, expect, update);&#125; 1. get() 方法 volatile 读当前 long 值 2. 自增 3. 自旋判断新值与当前值 4. 自旋成功，返回；否则返回 1 我们特别留意到 Jdk1.7 中 unsafe 使用的方法是 compareAndSwapLong，它与 x86 CPU 上的 LOCK CMPXCHG 指令对应，并且在应用层使用 while(true) 完成自 旋，这个细节在 Jdk1.8 中发生了变化。 在 Jdk1.8 中，AtomicLong 的关键代码如下： 123public final long getAndIncrement() &#123; return unsafe.getAndAddLong(this, valueOffset, 1L);&#125; Jdk1.7 的 CAS 操作已经不复存在了，转而使用了 getAndAddLong 方法，它与 x86 CPU 上的 LOCK XADD 指令对应，以原子方式返回当前值并递增（fetch and add）。 Atomic* 高效的原因，回答 CAS 是不够全面且不够严谨的，Jdk1.7 的 unsafe.compareAndSwapLong 以及 Jdk1.8 的 unsafe.getAndAddLong 才是关键，且 Jdk1.8 中不存在 CAS。 ```123456Jdk1.8 AtomicLong 相比 Jdk1.7 AtomicLong 的表现是要优秀的，这点我们将在后续的测评中见证。#### Jdk1.8 AtomicLong 相比 Jdk1.7 AtomicLong 的表现是要优秀的，这点我们将在后续的测评中见证。无论在 Jdk1.7 还是 Jdk1.8 中，Atomic* 的开销都是很大的，主要体现在： 高并发下，CAS 操作可能会频繁失败，真正更新成功的线程占少数。(Jdk1.7 独有的问题) 我之前的文章中介绍过“伪共享” (false sharing) 问题，但在 CAS 中，问题则表现的更为直接，这是“真共享”，与”伪共享“存在相同的问题：缓存行失效，缓存一致性开销变大。 底层指令的开销不见得很低，无论是 LOCK XADD 还是 LOCK CMPXCHG，想深究的朋友可以参考 instruction_tables ，（这一点可能有点钻牛角尖，但不失为一个角度去分析高并发下可行的优化） Atomic 所做的，比我们的诉求可能更大，有时候我们只需要计数器具备线程安全地递增这样的特性，但 Atomic 的相关操作每一次都伴随着值的返回。他是个带返回值的方法，而不是 void 方法，而多做了活大概率意味着额外的开销。 12抛开上述导致 AtomicLong 慢的原因，AtomicLong 仍然具备优势： 上述的第 4 点换一个角度也是 AtomicLong 的有点，相比下面要介绍的其他计数器方案，AtomicLong 能够保证每次操作都精确的返回真实的递增值。你可以借助 AtomicLong 来做并发场景下的递增序列号方案，注意，本文主要讨论的是计数器方案，而不是序列号方案。 实现简单，回到那句话：“简单的架构通常性能不高，高性能的架构通常复杂度很高”，AtomicLong 属于性能相对较高，但实现极其简单的那种方案，因为大部分的复杂性，由 JMM 和 JNI 方法屏蔽了。相比下面要介绍的其他计数器实现，AtomicLong 真的太“简易”了。 12![upload successful](http://47.103.200.134/image/AtomicLongSpeet.png) 横向对比，写的性能相比读的性能要差很多，在 20 个线程下写性能比读性能差距了 4~5 倍。 纵向对比，主要关注并发写，线程竞争激烈的情况下，单次自增耗时从 22 ns 增长为了 488 ns，有明显的性能下降。 实际场景中，我们需要统计系统的 qps、接口调用次数，都需要使用到计数的功能，写才是关键，并不是每时每刻都需要关注自增后的返回值，而 AtomicLong 恰恰在核心的写性能上有所欠缺。由此引出其他计数器方案。 123#### 认识 LongAdderDoug Lea 在 JDK1.8 中找到了一个上述问题的解决方案，他实现了一个 LongAdder 类。 @since 1.8@author Doug Leapublic class LongAdder extends Striped64 implements Serializable {}123456789101112131415LongAdder 的 API 如下![upload successful](http://47.103.200.134/image/longAddr.png)你应当发现，LongAdder 和 AtomicLong 明显的区别在于，increment 是一个 void 方法。直接来看看 LongAdder 的性能表现如何。(LA = LongAdder, AL = AtomicLong, 单位 ns/op)![upload successful](http://47.103.200.134/image/longAddrSpett.png)我们从中可以发现一些有意思的现象，网上不少很多文章没有从读写上对比二者，直接宣称 LongAdder 性能优于 AtomicLong，其实不太严谨。在单线程下，并发问题没有暴露，两者没有体现出差距；随着并发量加大，LongAdder 的 increment 操作更加优秀，而 AtomicLong 的 get 操作则更加优秀。鉴于在计数器场景下的特点—写多读少，所以写性能更高的 LongAdder 更加适合。#### LongAdder 写速度快的背后网上分析 LongAdder 源码的文章并不少，我不打算详细分析源码，而是挑选了一些必要的细节以及多数文章没有提及但我认为值得分析的内容。![upload successful](http://47.103.200.134/image/cell.png) Cell 设计减少并发修改时的冲突在 LongAdder 的父类 Striped64 中存在一个 volatile Cell[] cells; 数组，其长度是 2 的幂次方，每个 Cell 都填充了一个 @Contended 的 Long 字段，为了避免伪共享问题。 123456``` @sun.misc.Contended static final class Cell &#123; volatile long value; Cell(long x) &#123; value = x; &#125; // ... ignore&#125; 通过一系列算法，将计数结果分散在了多个 Cell 中，Cell 会随着并发量升高时发生扩容，最坏情况下 Cell 123456789101112```public long sum() &#123; Cell[] as = cells; Cell a; long sum = base; if (as != null) &#123; for (int i = 0; i &lt; as.length; ++i) &#123; if ((a = as[i]) != null) sum += a.value; &#125; &#125; return sum;&#125; ConcurrentHashMap 中的 size() 中也存在，毕竟他们的作者都是 Doug Lea。```12 并发场景下高效获取随机数 LongAdder 内部算法需要获取随机数，而 Random 类在并发场景下也是可以优化的。12 ThreadLocalRandom random = ThreadLocalRandom.current();random.nextInt(5);12```使用 ThreadLocalRandom 替代 Random，同样出现在了 LongAdder 的代码中。 123. longAccumulatelongAccumulate 方法是 LongAdder 的核心方法，内部存在大量的分支判断。首先和 Jdk1.7 的 AtomicLong 一样，它使用的是 UNSAFE.compareAndSwapLong 来完成自旋，不同之处在于，其在初次 cas 方式失败的情况下(说明多个线程同时想更新这个值)，尝试将这个值分隔成多个 Cell，让这些竞争的线程只负责更新自己所属的 Cell，这样将竞争压力分散开。 LongAdder 的前世今生1其实在 Jdk1.7 时代，LongAdder 还未诞生时，就有一些人想着自己去实现一个高性能的计数器了，比如一款 Java 性能监控框架 dropwizard/metrics 就做了这样事，在早期版本中，其优化手段并没有 Jdk1.8 的 LongAdder 丰富，而在 metrics 的最新版本中，其已经使用 Jdk1.8 的 LongAdder 替换掉了自己的轮子。在最后的测评中，我们将 metrics 版本的 LongAdder 也作为一个参考对象。 JCTools 中的 ConcurrentAutoTable1并非只有 LongAdder 考虑到了并发场景下计数器的优化，大名鼎鼎的并发容器框架 JCTool 中也提供了和今天主题相关的实现，虽然其名称和 Counter 看似没有关系，但通过其 Java 文档和 API ，可以发现其设计意图考虑到了计数器的场景。 1在最后的测评中，我们将 JCTools 的 ConcurrentAutoTable 也作为一个参考对象。 最终测评1Jdk1.7 的 AtomicLong，Jdk1.8 的 AtomicLong，Jdk 1.8 的 LongAdder，Metrics 的 LongAdder，JCTools 的 ConcurrentAutoTable，我对这五种类型的计数器使用 JMH 进行基准测试。 1234public interface Counter &#123; void inc(); long get();&#125; 1将 5 个类都适配成 Counter 接口的实现类，采用 @State(Scope.Group)，@Group 将各组测试用例进行隔离，尽可能地排除了互相之间的干扰，由于计数器场景的特性，我安排了 20 个线程进行并发写，1 个线程与之前的写线程共存，进行并发读。Mode=avgt 代表测试的是方法的耗时，越低代表性能越高。 12345如果我们只关注 inc 即写性能，可以发现 jdk1.8 的 LongAdder 表现的最为优秀，ConcurrentAutoTable 以及两个版本的 LongAdder 在一个数量级之上；1.8 的 AtomicLong 相比 1.7 的 AtomicLong 优秀很多，可以得出这样的结论，1.7 的 CAS+LOCK CMPXCHG 方案的确不如 1.8 的 LOCK XADD 来的优秀，但如果与特地优化过的其他计数器方案来进行比较，便相形见绌了。如果关注 get 性能，虽然这意义不大，但可以见得，AtomicLong 的 get 性能在高并发下表现依旧优秀，而 LongAdder 组合求值的特性，导致其性能必然存在一定下降，位列第二梯队，而 ConcurrentAutoTable 的并发读性能最差。关注整体性能，CounterBenchmark.rw 是对一组场景的整合打分，可以发现，在我们模拟的高并发计数器场景下，1.8 的 LongAdder 获得整体最低的延迟 98 ns，相比性能最差的 Jdk1.7 AtomicLong 实现，高了整整 10 倍有余，并且，随着并发度提升，这个数值还会增大。 AtomicLong 可以被废弃吗？既然 LongAdder 的性能高出 AtomicLong 这么多，我们还有理由使用 AtomicLong 吗？ 1本文重点讨论的角度还是比较局限的：单机场景下并发计数器的高效实现。AtomicLong 依然在很多场景下有其存在的价值，例如一个内存中的序列号生成器，AtomicLong 可以满足每次递增之后都精准的返回其递增值，而 LongAdder 并不具备这样的特性。LongAdder 为了性能而丧失了一部分功能，这体现了计算机的哲学，无处不在的 trade off。 高性能计数器总结 AtomicLong ：并发场景下读性能优秀，写性能急剧下降，不适合作为高性能的计数器方案。内存需求量少。 LongAdder ：并发场景下写性能优秀，读性能由于组合求值的原因，不如直接读值的方案，但由于计数器场景写多读少的缘故，整体性能在几个方案中最优，是高性能计数器的首选方案。由于 Cells 数组以及缓存行填充的缘故，占用内存较大。 ConcurrentAutoTable ：拥有和 LongAdder 相近的写入性能，读性能则更加不如 LongAdder。它的使用需要引入 JCTools 依赖，相比 Jdk 自带的 LongAdder 并没有优势。但额外说明一点，ConcurrentAutoTable 的使用并非局限于计数器场景，其仍然存在很大的价值。 在前面提到的性能监控框架 Metrics，以及著名的熔断框架 Hystrix 中，都存在 LongAdder 的使用场景，有兴趣的朋友快去实践一下 LongAdder 吧。 12345678910111213本文所有的 JMH 测试代码，均可在我的 github 中获得：https://github.com/lexburner/JMH-samples.git微信不支持外部超链接，文中相关仓库附录：Netflix/Hystrix : https://github.com/Netflix/HystrixMetrics : https://github.com/dropwizard/metricsJCTools : https://github.com/JCTools/JCToolsinstruction_tables : https://www.agner.org/optimize/instruction_tables.pdf本文转载于：https://mp.weixin.qq.com/s/yAvJFZWxfKb38IDMjQd5zg?spm=a2c4e.11153940.blogcont651530.11.303e7bebu6FTOM]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java并发系统学习番外篇</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并发编程之基础知识]]></title>
    <url>%2F2019%2F05%2F21%2F%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[Lombox 简介Lombok项目是一个java库，可以自动插入到您的编辑器和构建工具中，让您的java变得更加精彩。切勿再次写入另一个getter或equals方法。提前访问未来的Java功能val，等等。 除了官方介绍中，并不多相关文章，特意挑了 一篇文章中相关内容 lombok 提供了简单的注解的形式来帮助我们简化消除一些必须有但显得很臃肿的 java 代码。特别是相对于 POJO。 简单来说，比如我们新建了一个类，然后在其中写了几个字段，然后通常情况下我们需要手动去建立getter和setter方法啊，构造函数啊之类的，lombok的作用就是为了省去我们手动创建这些代码的麻烦，它能够在我们编译源码的时候自动帮我们生成这些方法。 lombok能够达到的效果就是在源码中不需要写一些通用的方法，但是在编译生成的字节码文件中会帮我们生成这些方法，这就是lombok的神奇作用。 虽然有人可能会说IDE里面都自带自动生成这些方法的功能，但是使用lombok会使你的代码看起来更加简洁，写起来也更加方便。 常用的注解@slf4j、@Setter、@Getter、@NoArgsConstructor(注解在类上：为类提供一个无参的构造方法)、@AllArgsConstructor(注解在类上；为类提供一个全参的构造方法) @NoArgsConstructor //注解在类上：为类提供一个无参的构造方法 @AllArgsConstructor//注解在类上；为类提供一个全参的构造方法 public class Person { //@Getter @Setter 注解在属性上；为属性提供 setting 方法 getting方法 @Setter @Getter private int pid; @Setter @Getter private String pname; @Setter @Getter private int sage; } 基础知识讲解与核心知识准备并发与高并发基本概念概念并发：同时拥有两个或者多个线程，如果程序在单核处理器运行，多个线程将交替地换入或者换出内存，这些线程是同时&quot;存在&quot;的，每个线程都处于执行过程中的某个状态，如果运行在多核处理器上，此时，程序中的每个线程都将会分配到一个处理器核上，因此可以同时运行 并行：系统中有多个任务同时存在可称之为“并发”，系统内有多个任务同时执行可称之为“并行”；并发是并行的子集。如果说并发就是在一台处理器上&quot;同时&quot;处理多个任务，那么并行就是在多台处理器上同时处理多个任务；个人理解是，在单核CPU系统上，并行是无法实现的，只可能存在并发而不可能存在并行。 高并发：高并发（High Concurrency）是互联网分布式系统架构设计中必须考虑的因素之一，它通常指，通过设计保证系统能够同时并行处理很多请求。 对比：并发：多个线程操作相同的资源，保证线程安全，合理使用资源 高并发：服务能同时处理很多请求，提高程序性能；如系统集中收到大量的请求（12306的抢票系统），导致系统在某段时间类执行大量的操作，包括对资源的请求、数据库的操作等等，如果高并发处理不好，不仅仅降低用户的体验度，请求时间变长，同时也可能导致系统宕机，甚至导致OOM（Out Of Memory）异常，如果想要系统适应高并发状态，就要有多个方面进行系统优化，包括硬件、网络、系统架构、开发语言的选取、数据结构的应用、算法的优化等等，这个时候谈论的是如何提供现有程序的性能，对高并发场景提供一些解决方案、手段等等 CPU多级缓存在多线程并发环境下，如果不采取特殊手段，普通的累加结果很可能是错的。错的原因可能涉及到计算机原理以及JAVA方面的一些知识。 Main Memory : 主存 Cache : 高速缓存，数据的读取和存储都经过此高速缓存 CPU Core : CPU核心 Bus : 系统总线 CUP Core 与 Cache 之间有一条快速通道，Main Memory 与 Cache 关联在 Bus 上，同时 Bus 还用于其他组件 的通信，在Cache出现不久后，系统变得更加复杂，Cache与Main Memory中速度的差异拉大，直到加入另一级的Cache，新加入的Cache 比 一级 Cache 更大，但是更慢，由于从加大一级Cache的做法，从经济上是行不通的，所以有了二级Cache，甚至已经有三级 Cache 为什么需要CPU CACHE?CPU的频率太快了，快到主存跟不上，这样在处理器时钟周期内，CPU常常需要等待主存，浪费资源，这样会使CPU花费很长时间等待数据到来或把数据写入内存。所以Cache的出现，是为了缓解CPU和内存之间速度的不匹配问题（结构：CPU - &gt; CACHE - &gt; MEMORY） CPU CACHE 意义缓存的容量远远小于主存，因此出现缓存不命中的情况在所难免，既然缓存不能包含CPU所需要的所有数据，那么Cache的存在真的有意义吗? CPU缓存存在的意义分两点（局部性原理）： 时间局部性：如果某个数据被访问，那么在不久的将来它很可能被再次访问 空间局限性：如果某个数据被访问，那么与它相邻的数据很快也可能被访问 缓存的工作原理是当CPU要读取一个数据时，首先从缓存中查找，如果找到就立即读取并运送给CPU处理；如果没有找到，就用相对慢的速度内存中读取并运送给CPU处理，同时把这个数据所在的数据块调入缓存中，可以使得以后对整块数据的读取都从缓存中进行，不必再调用内存。 正是这样的读取机制使CPU读取缓存的命中率非常高（大多数CPU可达90%左右），也就是说CPU下一次要读取的数据90%都在缓存中，大约10%需要从内存读取。 缓存一致性（MESI）缓存一致性用于保证多个CPU Cache之间缓存共享数据的一致性，定义了Cache Line四种状态，而CPU对Cache的四种操作，可能会产生不一致的状态，因此缓存控制器监听到本地操作和远程操作的时候 ，需要对Cache Line作出相应的修改，从而保证数据在多个缓存之间的一致性 Cache Line ： 是cache与内存数据交换的最小单位，根据操作系统一般是32byte或64byte。在MESI协议中，状态可以是M、E、S、I，地址则是cache line中映射的内存地址，数据则是从内存中读取的数据。 MESI其实是四种状态的缩写：M（modify）修改、E（exclusive）独占、S（shared）共享、I（invalid）失效。 Cache 操作： MESI协议中，每个cache的控制器不仅知道自己的操作（local read和local write），通过监听也知道其他CPU中cache的操作（remote read和remote write）。对于自己本地缓存有的数据，CPU仅需要发起local操作，否则发起remote操作，从主存中读取数据，cache控制器通过总线监听，仅能够知道其他CPU发起的remote操作，但是如果local操作会导致数据不一致性，cache控制器会通知其他CPU的cache控制器修改状态。 乱序执行优化处理器为提高运算速度而做出违背代码原有顺序的优化 举个例子： 计算 a * b ，a =10 ，b = 200 ，则 result = a * b = 2000 代码编写顺序：a=10 -&gt; b=200 -&gt; result = a * b CPU乱序执行优化可能会发生执行顺序为：b=200 -&gt; a=10 -&gt; result = a * b CPU乱序执行优化不会对结果造成影响，在单核时代，处理器保证做出的优化，不会导致执行的结果远离预期的目标，但是在多核环境下并非如此。首先在多核环境中，同时会有多个核执行指令，每个核的指定都可能会被乱序优化，另外，处理器还引用了L1、L2等缓存机制，每个核都有自己的缓存，这就导致了逻辑次序上后写入内存的数据，未必真的最后写入，最终带来了这样的一个问题：如果我们不做任何防护措施，处理器最终得到的结果和我们逻辑得出的结果大不相同。比如我们在其中的一个核中执行数据写入操作，并在最后写一个标记，用来标记数据已经准备好了，然后从另外一个核上，通过那个标志，来判断数据是否已经就绪，这种做法它就存在一定的风险，标记位先被写入，但数据操作并未完成（可能是计算为完成、也可能是数据没有从缓存刷新到主存当中）， 最终导致另外的核使用了错误的数据。 Java 内存模型（Java Memory Model，JMM）CPU缓存一致性和乱序执行优化，在多核多并发下，需要额外做很多的事情，才能保证程序的执行，符合我们的预期。那么JVM（Java Virtual Machine (Java虚拟机)）是如何解决这些问题的?为了屏蔽掉各种硬件和操作系统的内存访问差异，实现让Java程序在各种平台下都能达到一致的并发效果，JMV规范中定义了JMM （Java Memory Model (Java 内存模型)）。 JMM是一种规范，它规范了JVM与计算机内存是如何协同工作的，它规定一个线程如何和何时可以看到其他线程修改过的共享变量的值，以及在必须时如何同步的访问共享变量。 JVM内存分配概念 JVM内存分配的两个概念：Stack（栈）和Heap（堆）。 Java中的Heap是运行时数据区，由垃圾回收负责，它的优势是动态的分配内存大小，生存期也不必事先告诉编译器，在运行时动态分配内存，Java的垃圾收集器，会自动回收不再使用的数据。但是也有缺点，由于是要在运行时动态分配内存，因此存取速度相对较慢。 Java中的Stack优势是存取速度比Heap要快，仅次于计算机中的寄存器，栈中的数据是可以共享的，但是它的缺点是，存在栈中数据的大小和生存期必须是确定的，缺乏灵活性，主要存放一些基本类型的变量。 JMM要求调用栈和本地变量存放在线程栈中，对象存放在堆上。一个本地变量可能指向一个对象的引用，引用这个本地变量是存放在线程栈上，而对象本身是存放在堆上的。一个对象可能包含方法，这些方法可能包含本地变量，这些本地变量还是存放在线程栈中，即使这些方法所属的对象存放在堆上。一个对象的成员变量可能会随着这个对象自身存放在堆上，不管这个成员对象是原始类型还是引用类型，静态成员变量跟随着类的定义一起存放在堆上。存放在堆上的对象，可以被所持有对这个对象引用线程的访问。 当一个线程可以访问一个对象的时候，它也可以访问该对象的成员变量，如果两个线程同时调用同一个对象的同一个方法，将会都访问该对象的成员变量，但是每一个线程都拥有了这个成员变量的私有拷贝。 计算机内存硬件架构 CPU，一台现代计算机拥有两个或多个CPU，其中一些CPU还有多核，从这一点可以看出，在一个有两个或多个CPU的现代计算机上，同时运行多个线程是非常有可能的，而且每个CPU在某一个时刻，运行一个线程是肯定没有问题的，这意味着，如果Java程序是多线程的，在Java程序中，每个CPU上一个线程是可能同时并发执行的。 CPU Refisters（寄存器），每个CPU都包含一系列的寄存器，它们是CPU内存的基础，CPU在寄存器中执行操作的速度远大于在主存上执行的速度，这是因为CPU访问寄存器的速度远大于主存。 Cache（高速缓存），由于计算机的存储设备与处理器运算速度之间有着几个数量级的差距，所以现代计算机系统都不得不加入一层读写速度尽可能接近处理器运算速度的高级缓存来作为内存与处理器之间的缓冲，将运算需要使用到的数据复制到缓存中，让运算能快速的进行，当运算结束后，在从缓存同步到内存中。这样处理器就无需等待缓慢的内存读写，CPU访问缓存层的速度快于访问主存的速度，但通常比访问内部寄存器的速度要慢。 Main Memory（主存），随机存取存储器（random access memory，RAM）又称作“随机存储器&quot;，一个计算机包含一个主存，所有的CPU都可以访问主存，主存通常比CPU中的缓存大得多。 JVM 与 Computer JVM 与 Computer 内存架构存在差异，硬件内存并无区分栈与堆，对于硬件而言，所有的栈和堆都分布在主内存中，可能会出现在高速缓存、寄存器中。 内存模型抽象结构 Java内存模型 - 同步八种操作 lock（锁定）：作用于主内存的变量，把一个变量标识为一条线程独占状态 unlock（解锁）：作用于主内存的变量，把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定 read（读取）：作用于主内存的变量，把一个变量值从主内存传输到线程的工作内存中，以便随后的load动作使用 load（载入）：作用于工作内存的变量，它把read操作从主内存中得到的变量值存放工作内存的变量副本中 use（使用）：作用于工作内存的变量，把工作内存中的一个变量值传递给执行引擎 assign（赋值）：作用于工作内存的变量，它把一个从执行引擎接收到的值赋值给工作内存的变量 store（存储）：作用于工作内存的变量，把工作内存中的一个变量的值传递到主内存中，以便随后的write的操作 write（写入）：作用于主内存的变量，它把store操作从工作内存中的一个变量的值传送到主内存的变量中 Java内存模型 - 同步规则 如果要把一个变量从主内存中复制到工作内存，就需要按顺序地执行read和load操作，如果把变量从工作内存中同步回主内存中，就要按顺序地执行store和write操作，但Java内存模型只要求上述操作必须按顺序执行，而没有保证是连续执行 不允许read和load、store和write操作之一单独出现 不允许一个线程丢弃它的最近assign的操作，即变量在工作内存中改变了之后必须同步到主内存中 不允许一个线程无原因地（没有发生过任何assign操作）把数据从工作内存同步回主内存中 一个新的变量只能在主内存中诞生，不允许在工作内存中直接使用一个未被初始化（load或assign）的变量。即就是对一个变量实施use和store操作之前，必须先执行过了assign和load操作 一个变量在同一时刻只允许一条线程对其进行lock操作，但lock操作可以被同一条线程重复执行多次，多次与执行lock后，只有执行相同次数的unlock，变量才会被解锁。lock和unlock必须成对出现 如果一个变量执行lock操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量前需要重新执行load或assign操作初始化变量的值 如果一个变量事先没有被lock操作锁定，则不允许对它执行unlock操作；也不允许去unlock一个被其他线程锁定的变量 对一个变量执行unlock操作之前，必须先把变量同步到主内存中（执行store和write操作） Java 内存模型 - 同步操作与规则 并发的优势与风险 并发编程与线程安全代码所在的进程，有多个线程同时运行，而这些线程可能会同时运行同一段代码，如果每次运行结果和单线程预期结果一致，变量值也和预期一致，则认为这是线程安全的。简单的说，就是并发环境下，得到我们期望正确的结果。对应的一个概念就是线程不安全，就是不提供数据访问保护，有可能出现多个线程，先后更改数据，造成所得到的数据是脏数据，也可能是计算错误。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java并发系统学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[时光荏苒，蹉跎了谁的年华]]></title>
    <url>%2F2019%2F05%2F18%2F%E6%97%B6%E5%85%89%E8%8D%8F%E8%8B%92%EF%BC%8C%E8%B9%89%E8%B7%8E%E4%BA%86%E8%B0%81%E7%9A%84%E5%B9%B4%E5%8D%8E%2F</url>
    <content type="text"><![CDATA[当清晨的一缕阳光透过窗帘上的空隙映照在沉睡的脸庞时，微微张开的双眼朦胧地注视着周遭的一切，新的一天悄然而至。 ——题记 时光的单车飞快驶去，岁月的倒影也将消失，白天与黑夜不停的交替，轮回的四季斑驳了谁的岁月，蹉跎了谁的年华。一个人静静地与岁月交错，于平淡之中细细体会生活的深意，去注视，去聆听，去感受那些带着希望的别离以及那些经受沧桑的相逢，不论时光如何飞转，那些落花一样的往事，依然鲜活地存在于我的脑海之中。当岁月和美丽的回忆已成为风中的叹息，我们伤感的眼里也许依然残存旧时的泪痕，模糊了视线，不敢轻易触碰。 生活的列车慢慢的前进，有些人下去，也有人上去，不慌不忙的过着行云流水的日子，有的人知道自己的前方在哪里停靠，生活充实而安逸，有些人庸庸碌碌的过着不起波澜的日子，每天无头鸟似的瞎忙，朦胧的眼神向世界宣告着昏暗思想，一个个皮囊悬浮在空气中，没有生机的灵魂过着糜烂的时间。没有归属，无处生根。有时我们在迷茫青春的时候，日子也慢慢地溜走，不留一点痕迹。 时光不可阻挡，岁月交错中总要有些思量。人生只有在不短的思考中才会有所进步，有所追求，有了目标的人生才不会孤独和无助，只有让自己的心静下来时一些前方的东西才会明朗的展现在我们的面前。让我们不再迷惑于为所谓的挣扎中，谁的年华没有色彩，谁的青春没有耀眼的光芒，只是在岁月的长河里我们的选择不同，所得到的结局就不同，每个人都需要努力才会得到一切自己所要追求的东西和梦想。 生命无常，人生苦短，记忆的时光中我们匆匆走过，走过喧嚣，走过孤寂，时光无情地带走了我们的青春年少，还好我们都在坚持着内心的宁静，岁月的年轮缓缓的从我们身边碾过，往事一幕幕铺陈，让我的生活回忆不至于那么的枯燥，一些美好的记忆还依然鲜活地根植在我的脑海之中。消逝不去，本不该怀旧的年纪，可是我们学不会遗忘，日日夜夜的想念，带着些许的小寂寞，心有不甘常常在无人的街角大声的长啸，发泄着内心的声音，有时候我们会选择相信宿命，认为人与人之间的相遇，就像是上天早已做了安排，人谁也逃不过岁月时光刻下的印迹。 时光荏苒，蹉跎了谁的年华，匆匆行走的岁月长河中，有些人只顾着追寻他人的脚步，忘记了自己的方向，忘记了自己的目标和理想，有些人几顾思量不敢走出自己的道路，因而迷失了方向。迷失了自己。有些人默默坚守，把青春的岁月包裹在温热的怀里，载着它踏上梦想的征途，不留一丝遗憾。不留一点别人靠近的距离，就像是陈孝正为自己规划的一厘米的差距，人生没有从头来过的权利。亦没有后悔的权利，做过的事情，不管有些怎样的结局都会成为过往，我们纵使一味的活在过去的时光里也不会改变一点点发生的故事，向着远方，努力的看看前方的路才是对我们自己的肯定，只有心存希望，才会有拼搏的勇气，才有希望去走更远的路，因为值得，所以一路前行， 那一路上的心酸往事，慢慢的沉淀在内心平和的深处！]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>生活</tag>
      </tags>
  </entry>
</search>
