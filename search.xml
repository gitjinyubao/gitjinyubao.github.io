<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[内存屏障]]></title>
    <url>%2F2019%2F05%2F23%2F%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C%2F</url>
    <content type="text"><![CDATA[为什么会有内存屏障 每个CPU都会有自己的缓存（有的甚至L1,L2,L3），缓存的目的就是为了提高性能，避免每次都要向内存取。但是这样的弊端也很明显：不能实时的和内存发生信息交换，分在不同CPU执行的不同线程对同一个变量的缓存值不同。 用volatile关键字修饰变量可以解决上述问题，那么volatile是如何做到这一点的呢？那就是内存屏障，内存屏障是硬件层的概念，不同的硬件平台实现内存屏障的手段并不是一样，java通过屏蔽这些差异，统一由jvm来生成内存屏障的指令。 内存屏障是什么 硬件层的内存屏障分为两种：Load Barrier 和 Store Barrier即读屏障和写屏障。 内存屏障有两个作用： 12阻止屏障两侧的指令重排序；强制把写缓冲区/高速缓存中的脏数据等写回主内存，让缓存中相应的数据失效。 对于Load Barrier来说，在指令前插入Load Barrier，可以让高速缓存中的数据失效，强制从新从主内存加载数据； 对于Store Barrier来说，在指令后插入Store Barrier，能让写入缓存中的最新数据更新写入主内存，让其他线程可见。 java内存屏障 java的内存屏障通常所谓的四种即LoadLoad,StoreStore,LoadStore,StoreLoad实际上也是上述两种的组合，完成一系列的屏障和数据同步功能。 LoadLoad屏障：对于这样的语句Load1; LoadLoad; Load2，在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。 StoreStore屏障：对于这样的语句Store1; StoreStore; Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。 LoadStore屏障：对于这样的语句Load1; LoadStore; Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。 StoreLoad屏障：对于这样的语句Store1; StoreLoad; Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。 它的开销是四种屏障中最大的。在大多数处理器的实现中，这个屏障是个万能屏障，兼具其它三种内存屏障的功能 volatile语义中的内存屏障 volatile的内存屏障策略非常严格保守，非常悲观且毫无安全感的心态： 12这里是列表文本在每个volatile写操作前插入StoreStore屏障，在写操作后插入StoreLoad屏障；在每个volatile读操作前插入LoadLoad屏障，在读操作后插入LoadStore屏障； 由于内存屏障的作用，避免了volatile变量和其它指令重排序、线程之间实现了通信，使得volatile表现出了锁的特性。 final语义中的内存屏障 对于final域，编译器和CPU会遵循两个排序规则： 12新建对象过程中，构造体中对final域的初始化写入和这个对象赋值给其他引用变量，这两个操作不能重排序；（废话嘛）初次读包含final域的对象引用和读取这个final域，这两个操作不能重排序；（晦涩，意思就是先赋值引用，再调用final值） 总之上面规则的意思可以这样理解，必需保证一个对象的所有final域被写入完毕后才能引用和读取。这也是内存屏障的起的作用： 写final域：在编译器写final域完毕，构造体结束之前，会插入一个StoreStore屏障，保证前面的对final写入对其他线程/CPU可见，并阻止重排序。 读final域：在上述规则2中，两步操作不能重排序的机理就是在读final域前插入了LoadLoad屏障。 X86处理器中，由于CPU不会对写-写操作进行重排序，所以StoreStore屏障会被省略；而X86也不会对逻辑上有先后依赖关系的操作进行重排序，所以LoadLoad也会变省略。 1原文链接：https://www.jianshu.com/p/2ab5e3d7e510]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java并发系统学习番外篇</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LongAdder解析]]></title>
    <url>%2F2019%2F05%2F23%2FLongAdder%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[LongAdder解析 1摘要： 对`LongAdder`的最初了解是从Coolshell上的一篇文章中获得的，但是一直都没有深入的了解过其实现，只知道它相较于`AtomicLong`来说，更加适合写多读少的并发情景。今天，我们就研究一下`LongAdder`的原理，探究一下它如此高效的原因。 对LongAdder的最初了解是从Coolshell上的一篇文章中获得的，但是一直都没有深入的了解过其实现，只知道它相较于AtomicLong来说，更加适合写多读少的并发情景。今天，我们就研究一下LongAdder的原理，探究一下它如此高效的原因。 基本原理和思想123456789Java有很多并发控制机制，比如说以AQS为基础的锁或者以CAS为原理的自旋锁。不了解AQS的朋友可以阅读我之前的AQS源码解析文章。一般来说，CAS适合轻量级的并发操作，也就是并发量并不多，而且等待时间不长的情况，否则就应该使用普通锁，进入阻塞状态，避免CPU空转。 所以，如果你有一个Long类型的值会被多线程修改，那么使用CAS进行并发控制比较好，但是如果你是需要锁住一些资源，然后进行数据库操作，那么还是使用阻塞锁比较好。 第一种情况下，我们一般都使用AtomicLong。AtomicLong是通过无限循环不停的采取CAS的方法去设置内部的value，直到成功为止。那么当并发数比较多或出现更新热点时，就会导致CAS的失败机率变高，重试次数更多，越多的线程重试，CAS失败的机率越高，形成恶性循环，从而降低了效率。 而LongAdder的原理就是降低对value更新的并发数，也就是将对单一value的变更压力分散到多个value值上，降低单个value的“热度”。 我们知道LongAdder的大致原理之后，再来详细的了解一下它的具体实现，其中也有很多值得借鉴的并发编程的技巧。 LongAdder的成员变量LongAdder是Striped64 的子类，其有三个比较重要的成员函数，在之后的函数分析中需要使用到，这里先说明一下。 12345678// CPU的数量static final int NCPU = Runtime.getRuntime().availableProcessors();// Cell对象的数组，长度一般是2的指数transient volatile Cell[] cells;// 基础value值，当并发较低时，只累加该值transient volatile long base;// 创建或者扩容Cells数组时使用的自旋锁变量transient volatile int cellsBusy; cells是LongAdder的父类Striped64中的Cell数组类型的成员变量。每个Cell对象中都包含一个value值，并提供对这个value值的CAS操作。1234567static final class Cell &#123; volatile long value; Cell(long x) &#123; value = x; &#125; final boolean cas(long cmp, long val) &#123; return UNSAFE.compareAndSwapLong(this, valueOffset, cmp, val); &#125;&#125; Add操作我们首先来看一下LongAdder的add函数，其会多次尝试CAS操作将值进行累加，如果成功了就直接返回，失败则继续执行。代码比较复杂，而且涉及的情况比较多，我们就以梳理历次尝试CAS操作为主线，讲清楚这些CAS操作的前提条件和场景。 1234567891011121314public void add(long x) &#123; Cell[] as; long b, v; int m; Cell a; // 当cells数组为null时，会进行第一次cas操作尝试。 if ((as = cells) != null || !casBase(b = base, b + x)) &#123; boolean uncontended = true; if (as == null || (m = as.length - 1) &lt; 0 || (a = as[getProbe() &amp; m]) == null || !(uncontended = a.cas(v = a.value, v + x))) // 当cells数组不为null，并且通过getProbe() &amp; m // 定位的Cell对象不为null时进行第二次CAS操作。 // 如果执行不成功，则进入longAccumulate函数。 longAccumulate(x, null, uncontended); &#125;&#125; 当并发量较少时，cell数组尚未初始化，所以只调用casBase函数，对base变量进行CAS累加。 我们来看一下casBase函数相关的源码吧。我们可以认为变量base就是第一个value值，也是基础value变量。先调用casBase函数来cas一下base变量，如果成功了，就不需要在进行下面比较复杂的算法， 123final boolean casBase(long cmp, long val) &#123; return UNSAFE.compareAndSwapLong(this, BASE, cmp, val);&#125; 当并发量逐渐提高时，casBase函数会失败。如果cells数组为null或为空,就直接调用longAccumulate方法。因为cells为null或在为空，说明cells未 初始化，所以调用longAccumulate进行初始化。否则继续判断。 如果cells中已经初始化，就继续进行后续判断。我们先来理解一下getProbe() &amp; m的这个操作吧，可以把这个操作当作一次计算”hash”值，然后将cells中这个位置的Cell对象赋值给变量a。如果变量a不为null，那么就调用该对象的cas方法去设置其value值。如果a为null，或在cas赋值发生冲突，那么调用longAccumulate方法。 LongAccumulate方法longAccumulate函数比较复杂，带有我的注释的代码已经贴在了文章后边，这里我们就只讲一下其中比较关键的一些技巧和思想。 首先，我们都知道只有当对base的cas操作失败之后，LongAdder才引入Cell数组．所以在longAccumulate中就是对Cell数组进行操作，分别涉及了数组的初始化，扩容和设置某个位置的Cell对象等操作。 在这段代码中，关于cellBusy的cas操作构成了一个SpinLock，这就是经典的SpinLock的编程技巧，大家可以学习一下。 我们先来看一下longAccumulate的主体代码，首先是一个无限for循环，然后根据cells数组的状态来判断是要进行cells数组的初始化，还是进行对象添加或者扩容。 12345678910111213141516171819202122232425262728final void longAccumulate(long x, LongBinaryOperator fn, boolean wasUncontended) &#123; int h; if ((h = getProbe()) == 0) &#123; //获取PROBE变量，探针变量，与当前运行的线程相关，不同线程不同 ThreadLocalRandom.current(); //初始化PROBE变量，和getProbe都使用Unsafe类提供的原子性操作。 h = getProbe(); wasUncontended = true; &#125; boolean collide = false; for (;;) &#123; //cas经典无限循环，不断尝试 Cell[] as; Cell a; int n; long v; if ((as = cells) != null &amp;&amp; (n = as.length) &gt; 0) &#123; // cells不为null,并且数组size大于0,表示cells已经初始化了 // 初始化Cell对象并设置到数组中或者进行数组扩容 &#125; else if (cellsBusy == 0 &amp;&amp; cells == as &amp;&amp; casCellsBusy()) &#123; //cells数组未初始化，获得cellsBusy lock,进行cells数组的初始化 // cells数组初始化操作 &#125; //如果初始化数组失败了，那就再次尝试一下直接cas base变量， // 如果成功了就直接返回，这是最后一个进行CAS操作的地方。 else if (casBase(v = base, ((fn == null) ? v + x : fn.applyAsLong(v, x)))) break; &#125; &#125; 进行Cell数组代码如下所示，它首先调用casCellsBusy函数获取了cellsBusy‘锁’，然后进行数组的初始化操作，最后将cellBusy’锁’释放掉。 1234567891011121314// 注意在进入这段代码之前已经casCellsBusy获得cellsBusy这个锁变量了。boolean init = false;try &#123; if (cells == as) &#123; Cell[] rs = new Cell[2]; rs[h &amp; 1] = new Cell(x); //设置x的值为cell对象的value值 cells = rs; init = true; &#125;&#125; finally &#123; cellsBusy = 0;&#125;if (init) break; 如果Cell数组已经初始化过了，那么就进行Cell数组的设置或者扩容。这部分代码有一系列的if else的判断，如果前一个条件不成立，才会进入下一条判断。 首先，当Cell数组中对应位置的cell对象为null时，表明该位置的Cell对象需要进行初始化，所以使用casCellsBusy函数获取’锁’，然后初始化Cell对象，并且设置进cells数组，最后释放掉’锁’。 当Cell数组中对应位置的cell对象不为null，则直接调用其cas操作进行累加。 当上述操作都失败后，认为多个线程在对同一个位置的Cell对象进行操作，这个Cell对象是一个“热点”，所以Cell数组需要进行扩容，将热点分散。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758if ((a = as[(n - 1) &amp; h]) == null) &#123; //通过与操作计算出来需要操作的Cell对象的坐标 if (cellsBusy == 0) &#123; //volatile 变量，用来实现spinLock,来在初始化和resize cells数组时使用。 //当cellsBusy为0时，表示当前可以对cells数组进行操作。 Cell r = new Cell(x);//将x值直接赋值给Cell对象 if (cellsBusy == 0 &amp;&amp; casCellsBusy()) &#123;//如果这个时候cellsBusy还是0 //就cas将其设置为非０，如果成功了就是获得了spinLock的锁．可以对cells数组进行操作． //如果失败了，就会再次执行一次循环 boolean created = false; try &#123; Cell[] rs; int m, j; //判断cells是否已经初始化，并且要操作的位置上没有cell对象． if ((rs = cells) != null &amp;&amp; (m = rs.length) &gt; 0 &amp;&amp; rs[j = (m - 1) &amp; h] == null) &#123; rs[j] = r; //将之前创建的值为x的cell对象赋值到cells数组的响应位置． created = true; &#125; &#125; finally &#123; //经典的spinLock编程技巧，先获得锁，然后try finally将锁释放掉 //将cellBusy设置为0就是释放锁． cellsBusy = 0; &#125; if (created) break; //如果创建成功了，就是使用x创建了新的cell对象，也就是新创建了一个分担热点的value continue; &#125; &#125; collide = false; //未发生碰撞&#125;else if (!wasUncontended)//是否已经发生过一次cas操作失败 wasUncontended = true; //设置成true,以便第二次进入下一个else if 判断else if (a.cas(v = a.value, ((fn == null) ? v + x : fn.applyAsLong(v, x)))) //fn是操作类型，如果是空，就是相加，所以让a这个cell对象中的value值和x相加，然后在cas设置，如果成果 //就直接返回 break;else if (n &gt;= NCPU || cells != as) //如果cells数组的大小大于系统的可获得处理器数量或在as不再和cells相等． collide = false;else if (!collide) collide = true;else if (cellsBusy == 0 &amp;&amp; casCellsBusy()) &#123; //再次获得cellsBusy这个spinLock,对数组进行resize try &#123; if (cells == as) &#123;//要再次检测as是否等于cells以免其他线程已经对cells进行了操作． Cell[] rs = new Cell[n &lt;&lt; 1]; //扩容一倍 for (int i = 0; i &lt; n; ++i) rs[i] = as[i]; cells = rs;//赋予cells一个新的数组对象 &#125; &#125; finally &#123; cellsBusy = 0; &#125; collide = false; continue;&#125;h = advanceProbe(h);//由于使用当前探针变量无法操作成功，所以重新设置一个,再次尝试 后记 本篇文章写的不是很好，我写完之后又看了一遍coolshell上的关于LongAdder的文章，感觉自己没有人家写的那么简洁明了。我对代码细节的注释和投入太多了。其实很多代码大家都可以看懂，并不需要大量的代码片段加注释。以后要注意一下。之后会接着研究一下JUC包中的其他类，希望大家多多关注。 1文章来源： https://yq.aliyun.com/articles/688822]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java并发系统学习番外篇</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java并发计数器分析]]></title>
    <url>%2F2019%2F05%2F22%2Fjava%E5%B9%B6%E5%8F%91%E8%AE%A1%E6%95%B0%E5%99%A8%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[前言一提到线程安全的并发计数器，AtomicLong 必然是第一个被联想到的工具。Atomic* 一系列的原子类以及它们背后的 CAS 无锁算法，常常是高性能，高并发的代名词。本文将会阐释，在并发场景下，使用 AtomicLong 来充当并发计数器将会是一个糟糕的设计，实际上存在不少 AtomicLong 之外的计数器方案。近期我研究了一些 Jdk1.8 以及 JCTools 的优化方案，并将它们的对比与实现细节整理于此。 AtomicLong 的前世今生在 Java 中，Atomic* 是高效的，这得益于 sun.misc.Unsafe 提供的一系列底层 API，使得 Java 这样的高级语言能够直接和硬件层面的 CPU 指令打交道。并且在 Jdk1.7 中，这样的底层指令可以配合 CAS 操作，达到 Lock-Free。 在 Jdk1.7 中，AtomicLong 的关键代码如下： 123456789101112public final long getAndIncrement() &#123; while (true) &#123; long current = get(); long next = current + 1; if (compareAndSet(current, next)) return current; &#125;&#125;public final boolean compareAndSet(long expect, long update) &#123; return unsafe.compareAndSwapLong(this, valueOffset, expect, update);&#125; 1. get() 方法 volatile 读当前 long 值 2. 自增 3. 自旋判断新值与当前值 4. 自旋成功，返回；否则返回 1 我们特别留意到 Jdk1.7 中 unsafe 使用的方法是 compareAndSwapLong，它与 x86 CPU 上的 LOCK CMPXCHG 指令对应，并且在应用层使用 while(true) 完成自 旋，这个细节在 Jdk1.8 中发生了变化。 在 Jdk1.8 中，AtomicLong 的关键代码如下： 123public final long getAndIncrement() &#123; return unsafe.getAndAddLong(this, valueOffset, 1L);&#125; Jdk1.7 的 CAS 操作已经不复存在了，转而使用了 getAndAddLong 方法，它与 x86 CPU 上的 LOCK XADD 指令对应，以原子方式返回当前值并递增（fetch and add）。 Atomic* 高效的原因，回答 CAS 是不够全面且不够严谨的，Jdk1.7 的 unsafe.compareAndSwapLong 以及 Jdk1.8 的 unsafe.getAndAddLong 才是关键，且 Jdk1.8 中不存在 CAS。 ```123456Jdk1.8 AtomicLong 相比 Jdk1.7 AtomicLong 的表现是要优秀的，这点我们将在后续的测评中见证。#### Jdk1.8 AtomicLong 相比 Jdk1.7 AtomicLong 的表现是要优秀的，这点我们将在后续的测评中见证。无论在 Jdk1.7 还是 Jdk1.8 中，Atomic* 的开销都是很大的，主要体现在： 高并发下，CAS 操作可能会频繁失败，真正更新成功的线程占少数。(Jdk1.7 独有的问题) 我之前的文章中介绍过“伪共享” (false sharing) 问题，但在 CAS 中，问题则表现的更为直接，这是“真共享”，与”伪共享“存在相同的问题：缓存行失效，缓存一致性开销变大。 底层指令的开销不见得很低，无论是 LOCK XADD 还是 LOCK CMPXCHG，想深究的朋友可以参考 instruction_tables ，（这一点可能有点钻牛角尖，但不失为一个角度去分析高并发下可行的优化） Atomic 所做的，比我们的诉求可能更大，有时候我们只需要计数器具备线程安全地递增这样的特性，但 Atomic 的相关操作每一次都伴随着值的返回。他是个带返回值的方法，而不是 void 方法，而多做了活大概率意味着额外的开销。 12抛开上述导致 AtomicLong 慢的原因，AtomicLong 仍然具备优势： 上述的第 4 点换一个角度也是 AtomicLong 的有点，相比下面要介绍的其他计数器方案，AtomicLong 能够保证每次操作都精确的返回真实的递增值。你可以借助 AtomicLong 来做并发场景下的递增序列号方案，注意，本文主要讨论的是计数器方案，而不是序列号方案。 实现简单，回到那句话：“简单的架构通常性能不高，高性能的架构通常复杂度很高”，AtomicLong 属于性能相对较高，但实现极其简单的那种方案，因为大部分的复杂性，由 JMM 和 JNI 方法屏蔽了。相比下面要介绍的其他计数器实现，AtomicLong 真的太“简易”了。 12![upload successful](http://prl6c63q7.bkt.clouddn.com/AtomicLongSpeet.png) 横向对比，写的性能相比读的性能要差很多，在 20 个线程下写性能比读性能差距了 4~5 倍。 纵向对比，主要关注并发写，线程竞争激烈的情况下，单次自增耗时从 22 ns 增长为了 488 ns，有明显的性能下降。 实际场景中，我们需要统计系统的 qps、接口调用次数，都需要使用到计数的功能，写才是关键，并不是每时每刻都需要关注自增后的返回值，而 AtomicLong 恰恰在核心的写性能上有所欠缺。由此引出其他计数器方案。 123#### 认识 LongAdderDoug Lea 在 JDK1.8 中找到了一个上述问题的解决方案，他实现了一个 LongAdder 类。 @since 1.8@author Doug Leapublic class LongAdder extends Striped64 implements Serializable {}123456789101112131415LongAdder 的 API 如下![upload successful](http://prl6c63q7.bkt.clouddn.com/longAddr.png)你应当发现，LongAdder 和 AtomicLong 明显的区别在于，increment 是一个 void 方法。直接来看看 LongAdder 的性能表现如何。(LA = LongAdder, AL = AtomicLong, 单位 ns/op)![upload successful](http://prl6c63q7.bkt.clouddn.com/longAddrSpett.png)我们从中可以发现一些有意思的现象，网上不少很多文章没有从读写上对比二者，直接宣称 LongAdder 性能优于 AtomicLong，其实不太严谨。在单线程下，并发问题没有暴露，两者没有体现出差距；随着并发量加大，LongAdder 的 increment 操作更加优秀，而 AtomicLong 的 get 操作则更加优秀。鉴于在计数器场景下的特点—写多读少，所以写性能更高的 LongAdder 更加适合。#### LongAdder 写速度快的背后网上分析 LongAdder 源码的文章并不少，我不打算详细分析源码，而是挑选了一些必要的细节以及多数文章没有提及但我认为值得分析的内容。![upload successful](http://prl6c63q7.bkt.clouddn.com/cell.png) Cell 设计减少并发修改时的冲突在 LongAdder 的父类 Striped64 中存在一个 volatile Cell[] cells; 数组，其长度是 2 的幂次方，每个 Cell 都填充了一个 @Contended 的 Long 字段，为了避免伪共享问题。 123456``` @sun.misc.Contended static final class Cell &#123; volatile long value; Cell(long x) &#123; value = x; &#125; // ... ignore&#125; 通过一系列算法，将计数结果分散在了多个 Cell 中，Cell 会随着并发量升高时发生扩容，最坏情况下 Cell 123456789101112```public long sum() &#123; Cell[] as = cells; Cell a; long sum = base; if (as != null) &#123; for (int i = 0; i &lt; as.length; ++i) &#123; if ((a = as[i]) != null) sum += a.value; &#125; &#125; return sum;&#125; ConcurrentHashMap 中的 size() 中也存在，毕竟他们的作者都是 Doug Lea。```12 并发场景下高效获取随机数 LongAdder 内部算法需要获取随机数，而 Random 类在并发场景下也是可以优化的。12 ThreadLocalRandom random = ThreadLocalRandom.current();random.nextInt(5);12```使用 ThreadLocalRandom 替代 Random，同样出现在了 LongAdder 的代码中。 123. longAccumulatelongAccumulate 方法是 LongAdder 的核心方法，内部存在大量的分支判断。首先和 Jdk1.7 的 AtomicLong 一样，它使用的是 UNSAFE.compareAndSwapLong 来完成自旋，不同之处在于，其在初次 cas 方式失败的情况下(说明多个线程同时想更新这个值)，尝试将这个值分隔成多个 Cell，让这些竞争的线程只负责更新自己所属的 Cell，这样将竞争压力分散开。 LongAdder 的前世今生1其实在 Jdk1.7 时代，LongAdder 还未诞生时，就有一些人想着自己去实现一个高性能的计数器了，比如一款 Java 性能监控框架 dropwizard/metrics 就做了这样事，在早期版本中，其优化手段并没有 Jdk1.8 的 LongAdder 丰富，而在 metrics 的最新版本中，其已经使用 Jdk1.8 的 LongAdder 替换掉了自己的轮子。在最后的测评中，我们将 metrics 版本的 LongAdder 也作为一个参考对象。 JCTools 中的 ConcurrentAutoTable1并非只有 LongAdder 考虑到了并发场景下计数器的优化，大名鼎鼎的并发容器框架 JCTool 中也提供了和今天主题相关的实现，虽然其名称和 Counter 看似没有关系，但通过其 Java 文档和 API ，可以发现其设计意图考虑到了计数器的场景。 1在最后的测评中，我们将 JCTools 的 ConcurrentAutoTable 也作为一个参考对象。 最终测评1Jdk1.7 的 AtomicLong，Jdk1.8 的 AtomicLong，Jdk 1.8 的 LongAdder，Metrics 的 LongAdder，JCTools 的 ConcurrentAutoTable，我对这五种类型的计数器使用 JMH 进行基准测试。 1234public interface Counter &#123; void inc(); long get();&#125; 1将 5 个类都适配成 Counter 接口的实现类，采用 @State(Scope.Group)，@Group 将各组测试用例进行隔离，尽可能地排除了互相之间的干扰，由于计数器场景的特性，我安排了 20 个线程进行并发写，1 个线程与之前的写线程共存，进行并发读。Mode=avgt 代表测试的是方法的耗时，越低代表性能越高。 12345如果我们只关注 inc 即写性能，可以发现 jdk1.8 的 LongAdder 表现的最为优秀，ConcurrentAutoTable 以及两个版本的 LongAdder 在一个数量级之上；1.8 的 AtomicLong 相比 1.7 的 AtomicLong 优秀很多，可以得出这样的结论，1.7 的 CAS+LOCK CMPXCHG 方案的确不如 1.8 的 LOCK XADD 来的优秀，但如果与特地优化过的其他计数器方案来进行比较，便相形见绌了。如果关注 get 性能，虽然这意义不大，但可以见得，AtomicLong 的 get 性能在高并发下表现依旧优秀，而 LongAdder 组合求值的特性，导致其性能必然存在一定下降，位列第二梯队，而 ConcurrentAutoTable 的并发读性能最差。关注整体性能，CounterBenchmark.rw 是对一组场景的整合打分，可以发现，在我们模拟的高并发计数器场景下，1.8 的 LongAdder 获得整体最低的延迟 98 ns，相比性能最差的 Jdk1.7 AtomicLong 实现，高了整整 10 倍有余，并且，随着并发度提升，这个数值还会增大。 AtomicLong 可以被废弃吗？既然 LongAdder 的性能高出 AtomicLong 这么多，我们还有理由使用 AtomicLong 吗？ 1本文重点讨论的角度还是比较局限的：单机场景下并发计数器的高效实现。AtomicLong 依然在很多场景下有其存在的价值，例如一个内存中的序列号生成器，AtomicLong 可以满足每次递增之后都精准的返回其递增值，而 LongAdder 并不具备这样的特性。LongAdder 为了性能而丧失了一部分功能，这体现了计算机的哲学，无处不在的 trade off。 高性能计数器总结 AtomicLong ：并发场景下读性能优秀，写性能急剧下降，不适合作为高性能的计数器方案。内存需求量少。 LongAdder ：并发场景下写性能优秀，读性能由于组合求值的原因，不如直接读值的方案，但由于计数器场景写多读少的缘故，整体性能在几个方案中最优，是高性能计数器的首选方案。由于 Cells 数组以及缓存行填充的缘故，占用内存较大。 ConcurrentAutoTable ：拥有和 LongAdder 相近的写入性能，读性能则更加不如 LongAdder。它的使用需要引入 JCTools 依赖，相比 Jdk 自带的 LongAdder 并没有优势。但额外说明一点，ConcurrentAutoTable 的使用并非局限于计数器场景，其仍然存在很大的价值。 在前面提到的性能监控框架 Metrics，以及著名的熔断框架 Hystrix 中，都存在 LongAdder 的使用场景，有兴趣的朋友快去实践一下 LongAdder 吧。 12345678910111213本文所有的 JMH 测试代码，均可在我的 github 中获得：https://github.com/lexburner/JMH-samples.git微信不支持外部超链接，文中相关仓库附录：Netflix/Hystrix : https://github.com/Netflix/HystrixMetrics : https://github.com/dropwizard/metricsJCTools : https://github.com/JCTools/JCToolsinstruction_tables : https://www.agner.org/optimize/instruction_tables.pdf本文转载于：https://mp.weixin.qq.com/s/yAvJFZWxfKb38IDMjQd5zg?spm=a2c4e.11153940.blogcont651530.11.303e7bebu6FTOM]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java并发系统学习番外篇</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并发编程之基础知识]]></title>
    <url>%2F2019%2F05%2F21%2F%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[Lombox简介Lombok项目是一个java库，可以自动插入到您的编辑器和构建工具中，让您的java变得更加精彩。切勿再次写入另一个getter或equals方法。提前访问未来的Java功能val，等等。 除了官方介绍中，并不多相关文章，特意挑了 一篇文章中相关内容 lombok 提供了简单的注解的形式来帮助我们简化消除一些必须有但显得很臃肿的 java 代码。特别是相对于 POJO。 简单来说，比如我们新建了一个类，然后在其中写了几个字段，然后通常情况下我们需要手动去建立getter和setter方法啊，构造函数啊之类的，lombok的作用就是为了省去我们手动创建这些代码的麻烦，它能够在我们编译源码的时候自动帮我们生成这些方法。 lombok能够达到的效果就是在源码中不需要写一些通用的方法，但是在编译生成的字节码文件中会帮我们生成这些方法，这就是lombok的神奇作用。 虽然有人可能会说IDE里面都自带自动生成这些方法的功能，但是使用lombok会使你的代码看起来更加简洁，写起来也更加方便。 常用的注解@slf4j、@Setter、@Getter、@NoArgsConstructor(注解在类上：为类提供一个无参的构造方法)、@AllArgsConstructor(注解在类上；为类提供一个全参的构造方法) @NoArgsConstructor //注解在类上：为类提供一个无参的构造方法 @AllArgsConstructor//注解在类上；为类提供一个全参的构造方法 public class Person { //@Getter @Setter 注解在属性上；为属性提供 setting 方法 getting方法 @Setter @Getter private int pid; @Setter @Getter private String pname; @Setter @Getter private int sage; } 基础知识讲解与核心知识准备并发与高并发基本概念概念并发：同时拥有两个或者多个线程，如果程序在单核处理器运行，多个线程将交替地换入或者换出内存，这些线程是同时&quot;存在&quot;的，每个线程都处于执行过程中的某个状态，如果运行在多核处理器上，此时，程序中的每个线程都将会分配到一个处理器核上，因此可以同时运行 并行：系统中有多个任务同时存在可称之为“并发”，系统内有多个任务同时执行可称之为“并行”；并发是并行的子集。如果说并发就是在一台处理器上&quot;同时&quot;处理多个任务，那么并行就是在多台处理器上同时处理多个任务；个人理解是，在单核CPU系统上，并行是无法实现的，只可能存在并发而不可能存在并行。 高并发：高并发（High Concurrency）是互联网分布式系统架构设计中必须考虑的因素之一，它通常指，通过设计保证系统能够同时并行处理很多请求。 对比：并发：多个线程操作相同的资源，保证线程安全，合理使用资源 高并发：服务能同时处理很多请求，提高程序性能；如系统集中收到大量的请求（12306的抢票系统），导致系统在某段时间类执行大量的操作，包括对资源的请求、数据库的操作等等，如果高并发处理不好，不仅仅降低用户的体验度，请求时间变长，同时也可能导致系统宕机，甚至导致OOM（Out Of Memory）异常，如果想要系统适应高并发状态，就要有多个方面进行系统优化，包括硬件、网络、系统架构、开发语言的选取、数据结构的应用、算法的优化等等，这个时候谈论的是如何提供现有程序的性能，对高并发场景提供一些解决方案、手段等等 CPU多级缓存在多线程并发环境下，如果不采取特殊手段，普通的累加结果很可能是错的。错的原因可能涉及到计算机原理以及JAVA方面的一些知识。 Main Memory : 主存 Cache : 高速缓存，数据的读取和存储都经过此高速缓存 CPU Core : CPU核心 Bus : 系统总线 CUP Core 与 Cache 之间有一条快速通道，Main Memory 与 Cache 关联在 Bus 上，同时 Bus 还用于其他组件 的通信，在Cache出现不久后，系统变得更加复杂，Cache与Main Memory中速度的差异拉大，直到加入另一级的Cache，新加入的Cache 比 一级 Cache 更大，但是更慢，由于从加大一级Cache的做法，从经济上是行不通的，所以有了二级Cache，甚至已经有三级 Cache 为什么需要CPU CACHE?CPU的频率太快了，快到主存跟不上，这样在处理器时钟周期内，CPU常常需要等待主存，浪费资源，这样会使CPU花费很长时间等待数据到来或把数据写入内存。所以Cache的出现，是为了缓解CPU和内存之间速度的不匹配问题（结构：CPU - &gt; CACHE - &gt; MEMORY） CPU CACHE 意义缓存的容量远远小于主存，因此出现缓存不命中的情况在所难免，既然缓存不能包含CPU所需要的所有数据，那么Cache的存在真的有意义吗? CPU缓存存在的意义分两点（局部性原理）： 时间局部性：如果某个数据被访问，那么在不久的将来它很可能被再次访问 空间局限性：如果某个数据被访问，那么与它相邻的数据很快也可能被访问 缓存的工作原理是当CPU要读取一个数据时，首先从缓存中查找，如果找到就立即读取并运送给CPU处理；如果没有找到，就用相对慢的速度内存中读取并运送给CPU处理，同时把这个数据所在的数据块调入缓存中，可以使得以后对整块数据的读取都从缓存中进行，不必再调用内存。 正是这样的读取机制使CPU读取缓存的命中率非常高（大多数CPU可达90%左右），也就是说CPU下一次要读取的数据90%都在缓存中，大约10%需要从内存读取。 缓存一致性（MESI）缓存一致性用于保证多个CPU Cache之间缓存共享数据的一致性，定义了Cache Line四种状态，而CPU对Cache的四种操作，可能会产生不一致的状态，因此缓存控制器监听到本地操作和远程操作的时候 ，需要对Cache Line作出相应的修改，从而保证数据在多个缓存之间的一致性 Cache Line ： 是cache与内存数据交换的最小单位，根据操作系统一般是32byte或64byte。在MESI协议中，状态可以是M、E、S、I，地址则是cache line中映射的内存地址，数据则是从内存中读取的数据。 MESI其实是四种状态的缩写：M（modify）修改、E（exclusive）独占、S（shared）共享、I（invalid）失效。 Cache 操作： MESI协议中，每个cache的控制器不仅知道自己的操作（local read和local write），通过监听也知道其他CPU中cache的操作（remote read和remote write）。对于自己本地缓存有的数据，CPU仅需要发起local操作，否则发起remote操作，从主存中读取数据，cache控制器通过总线监听，仅能够知道其他CPU发起的remote操作，但是如果local操作会导致数据不一致性，cache控制器会通知其他CPU的cache控制器修改状态。 乱序执行优化处理器为提高运算速度而做出违背代码原有顺序的优化 举个例子： 计算 a * b ，a =10 ，b = 200 ，则 result = a * b = 2000 代码编写顺序：a=10 -&gt; b=200 -&gt; result = a * b CPU乱序执行优化可能会发生执行顺序为：b=200 -&gt; a=10 -&gt; result = a * b CPU乱序执行优化不会对结果造成影响，在单核时代，处理器保证做出的优化，不会导致执行的结果远离预期的目标，但是在多核环境下并非如此。首先在多核环境中，同时会有多个核执行指令，每个核的指定都可能会被乱序优化，另外，处理器还引用了L1、L2等缓存机制，每个核都有自己的缓存，这就导致了逻辑次序上后写入内存的数据，未必真的最后写入，最终带来了这样的一个问题：如果我们不做任何防护措施，处理器最终得到的结果和我们逻辑得出的结果大不相同。比如我们在其中的一个核中执行数据写入操作，并在最后写一个标记，用来标记数据已经准备好了，然后从另外一个核上，通过那个标志，来判断数据是否已经就绪，这种做法它就存在一定的风险，标记位先被写入，但数据操作并未完成（可能是计算为完成、也可能是数据没有从缓存刷新到主存当中）， 最终导致另外的核使用了错误的数据。 Java 内存模型（Java Memory Model，JMM）CPU缓存一致性和乱序执行优化，在多核多并发下，需要额外做很多的事情，才能保证程序的执行，符合我们的预期。那么JVM（Java Virtual Machine (Java虚拟机)）是如何解决这些问题的?为了屏蔽掉各种硬件和操作系统的内存访问差异，实现让Java程序在各种平台下都能达到一致的并发效果，JMV规范中定义了JMM （Java Memory Model (Java 内存模型)）。 JMM是一种规范，它规范了JVM与计算机内存是如何协同工作的，它规定一个线程如何和何时可以看到其他线程修改过的共享变量的值，以及在必须时如何同步的访问共享变量。 JVM内存分配概念 JVM内存分配的两个概念：Stack（栈）和Heap（堆）。 Java中的Heap是运行时数据区，由垃圾回收负责，它的优势是动态的分配内存大小，生存期也不必事先告诉编译器，在运行时动态分配内存，Java的垃圾收集器，会自动回收不再使用的数据。但是也有缺点，由于是要在运行时动态分配内存，因此存取速度相对较慢。 Java中的Stack优势是存取速度比Heap要快，仅次于计算机中的寄存器，栈中的数据是可以共享的，但是它的缺点是，存在栈中数据的大小和生存期必须是确定的，缺乏灵活性，主要存放一些基本类型的变量。 JMM要求调用栈和本地变量存放在线程栈中，对象存放在堆上。一个本地变量可能指向一个对象的引用，引用这个本地变量是存放在线程栈上，而对象本身是存放在堆上的。一个对象可能包含方法，这些方法可能包含本地变量，这些本地变量还是存放在线程栈中，即使这些方法所属的对象存放在堆上。一个对象的成员变量可能会随着这个对象自身存放在堆上，不管这个成员对象是原始类型还是引用类型，静态成员变量跟随着类的定义一起存放在堆上。存放在堆上的对象，可以被所持有对这个对象引用线程的访问。 当一个线程可以访问一个对象的时候，它也可以访问该对象的成员变量，如果两个线程同时调用同一个对象的同一个方法，将会都访问该对象的成员变量，但是每一个线程都拥有了这个成员变量的私有拷贝。 计算机内存硬件架构 CPU，一台现代计算机拥有两个或多个CPU，其中一些CPU还有多核，从这一点可以看出，在一个有两个或多个CPU的现代计算机上，同时运行多个线程是非常有可能的，而且每个CPU在某一个时刻，运行一个线程是肯定没有问题的，这意味着，如果Java程序是多线程的，在Java程序中，每个CPU上一个线程是可能同时并发执行的。 CPU Refisters（寄存器），每个CPU都包含一系列的寄存器，它们是CPU内存的基础，CPU在寄存器中执行操作的速度远大于在主存上执行的速度，这是因为CPU访问寄存器的速度远大于主存。 Cache（高速缓存），由于计算机的存储设备与处理器运算速度之间有着几个数量级的差距，所以现代计算机系统都不得不加入一层读写速度尽可能接近处理器运算速度的高级缓存来作为内存与处理器之间的缓冲，将运算需要使用到的数据复制到缓存中，让运算能快速的进行，当运算结束后，在从缓存同步到内存中。这样处理器就无需等待缓慢的内存读写，CPU访问缓存层的速度快于访问主存的速度，但通常比访问内部寄存器的速度要慢。 Main Memory（主存），随机存取存储器（random access memory，RAM）又称作“随机存储器&quot;，一个计算机包含一个主存，所有的CPU都可以访问主存，主存通常比CPU中的缓存大得多。 JVM 与 Computer JVM 与 Computer 内存架构存在差异，硬件内存并无区分栈与堆，对于硬件而言，所有的栈和堆都分布在主内存中，可能会出现在高速缓存、寄存器中。 内存模型抽象结构 Java内存模型 - 同步八种操作 lock（锁定）：作用于主内存的变量，把一个变量标识为一条线程独占状态 unlock（解锁）：作用于主内存的变量，把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定 read（读取）：作用于主内存的变量，把一个变量值从主内存传输到线程的工作内存中，以便随后的load动作使用 load（载入）：作用于工作内存的变量，它把read操作从主内存中得到的变量值存放工作内存的变量副本中 use（使用）：作用于工作内存的变量，把工作内存中的一个变量值传递给执行引擎 assign（赋值）：作用于工作内存的变量，它把一个从执行引擎接收到的值赋值给工作内存的变量 store（存储）：作用于工作内存的变量，把工作内存中的一个变量的值传递到主内存中，以便随后的write的操作 write（写入）：作用于主内存的变量，它把store操作从工作内存中的一个变量的值传送到主内存的变量中 Java内存模型 - 同步规则 如果要把一个变量从主内存中复制到工作内存，就需要按顺序地执行read和load操作，如果把变量从工作内存中同步回主内存中，就要按顺序地执行store和write操作，但Java内存模型只要求上述操作必须按顺序执行，而没有保证是连续执行 不允许read和load、store和write操作之一单独出现 不允许一个线程丢弃它的最近assign的操作，即变量在工作内存中改变了之后必须同步到主内存中 不允许一个线程无原因地（没有发生过任何assign操作）把数据从工作内存同步回主内存中 一个新的变量只能在主内存中诞生，不允许在工作内存中直接使用一个未被初始化（load或assign）的变量。即就是对一个变量实施use和store操作之前，必须先执行过了assign和load操作 一个变量在同一时刻只允许一条线程对其进行lock操作，但lock操作可以被同一条线程重复执行多次，多次与执行lock后，只有执行相同次数的unlock，变量才会被解锁。lock和unlock必须成对出现 如果一个变量执行lock操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量前需要重新执行load或assign操作初始化变量的值 如果一个变量事先没有被lock操作锁定，则不允许对它执行unlock操作；也不允许去unlock一个被其他线程锁定的变量 对一个变量执行unlock操作之前，必须先把变量同步到主内存中（执行store和write操作） Java 内存模型 - 同步操作与规则 并发的优势与风险 并发编程与线程安全代码所在的进程，有多个线程同时运行，而这些线程可能会同时运行同一段代码，如果每次运行结果和单线程预期结果一致，变量值也和预期一致，则认为这是线程安全的。简单的说，就是并发环境下，得到我们期望正确的结果。对应的一个概念就是线程不安全，就是不提供数据访问保护，有可能出现多个线程，先后更改数据，造成所得到的数据是脏数据，也可能是计算错误。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java并发系统学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[时光荏苒，蹉跎了谁的年华]]></title>
    <url>%2F2019%2F05%2F18%2F%E6%97%B6%E5%85%89%E8%8D%8F%E8%8B%92%EF%BC%8C%E8%B9%89%E8%B7%8E%E4%BA%86%E8%B0%81%E7%9A%84%E5%B9%B4%E5%8D%8E%2F</url>
    <content type="text"><![CDATA[当清晨的一缕阳光透过窗帘上的空隙映照在沉睡的脸庞时，微微张开的双眼朦胧地注视着周遭的一切，新的一天悄然而至。 ——题记 时光的单车飞快驶去，岁月的倒影也将消失，白天与黑夜不停的交替，轮回的四季斑驳了谁的岁月，蹉跎了谁的年华。一个人静静地与岁月交错，于平淡之中细细体会生活的深意，去注视，去聆听，去感受那些带着希望的别离以及那些经受沧桑的相逢，不论时光如何飞转，那些落花一样的往事，依然鲜活地存在于我的脑海之中。当岁月和美丽的回忆已成为风中的叹息，我们伤感的眼里也许依然残存旧时的泪痕，模糊了视线，不敢轻易触碰。 生活的列车慢慢的前进，有些人下去，也有人上去，不慌不忙的过着行云流水的日子，有的人知道自己的前方在哪里停靠，生活充实而安逸，有些人庸庸碌碌的过着不起波澜的日子，每天无头鸟似的瞎忙，朦胧的眼神向世界宣告着昏暗思想，一个个皮囊悬浮在空气中，没有生机的灵魂过着糜烂的时间。没有归属，无处生根。有时我们在迷茫青春的时候，日子也慢慢地溜走，不留一点痕迹。 时光不可阻挡，岁月交错中总要有些思量。人生只有在不短的思考中才会有所进步，有所追求，有了目标的人生才不会孤独和无助，只有让自己的心静下来时一些前方的东西才会明朗的展现在我们的面前。让我们不再迷惑于为所谓的挣扎中，谁的年华没有色彩，谁的青春没有耀眼的光芒，只是在岁月的长河里我们的选择不同，所得到的结局就不同，每个人都需要努力才会得到一切自己所要追求的东西和梦想。 生命无常，人生苦短，记忆的时光中我们匆匆走过，走过喧嚣，走过孤寂，时光无情地带走了我们的青春年少，还好我们都在坚持着内心的宁静，岁月的年轮缓缓的从我们身边碾过，往事一幕幕铺陈，让我的生活回忆不至于那么的枯燥，一些美好的记忆还依然鲜活地根植在我的脑海之中。消逝不去，本不该怀旧的年纪，可是我们学不会遗忘，日日夜夜的想念，带着些许的小寂寞，心有不甘常常在无人的街角大声的长啸，发泄着内心的声音，有时候我们会选择相信宿命，认为人与人之间的相遇，就像是上天早已做了安排，人谁也逃不过岁月时光刻下的印迹。 时光荏苒，蹉跎了谁的年华，匆匆行走的岁月长河中，有些人只顾着追寻他人的脚步，忘记了自己的方向，忘记了自己的目标和理想，有些人几顾思量不敢走出自己的道路，因而迷失了方向。迷失了自己。有些人默默坚守，把青春的岁月包裹在温热的怀里，载着它踏上梦想的征途，不留一丝遗憾。不留一点别人靠近的距离，就像是陈孝正为自己规划的一厘米的差距，人生没有从头来过的权利。亦没有后悔的权利，做过的事情，不管有些怎样的结局都会成为过往，我们纵使一味的活在过去的时光里也不会改变一点点发生的故事，向着远方，努力的看看前方的路才是对我们自己的肯定，只有心存希望，才会有拼搏的勇气，才有希望去走更远的路，因为值得，所以一路前行， 那一路上的心酸往事，慢慢的沉淀在内心平和的深处！]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>生活</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F05%2F18%2Fhello-world%2F</url>
    <content type="text"><![CDATA[welcome here !]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>生活</tag>
      </tags>
  </entry>
</search>
